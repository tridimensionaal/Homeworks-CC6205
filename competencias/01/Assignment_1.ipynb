{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:49:08.174519Z",
     "start_time": "2020-03-31T13:49:08.165989Z"
    },
    "id": "gpbvNOH0zvIi"
   },
   "source": [
    "# **Competencia 1 - CC6205 Natural Language Processing 📚**\n",
    "\n",
    "**Integrantes:** Nicolas Lemuñir y Matías Seda\n",
    "\n",
    "**Usuario del equipo en CodaLab:** nice_try\n",
    "\n",
    "**Fecha límite de entrega 📆:** Jueves 14 de Abril.\n",
    "\n",
    "**Tiempo estimado de dedicación:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxlNrNf_p0ZY"
   },
   "source": [
    "## **Objetivo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrtvsKf2p3A4"
   },
   "source": [
    "En esta tarea grupal participarán de una competencia estilo [Kaggle](https://www.kaggle.com/) pero utilizando la página [CodaLab](https://codalab.org/). El objetivo es trabajar en la clasificación de tweets  según su intensidad de emoción, esto corresponde a la task de clasificación de texto. \n",
    "\n",
    "Tendrán a su disposición 4 datasets de tweets con distintas emociones: `anger`, `fear`, `sadness` y `joy`. Deberán crear un clasificador para cada uno de estos datasets que indique la intensidad de dicha emoción en sus tweets (`low`, `medium`, `high`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6lhhfl2zvIk"
   },
   "source": [
    "## **Instrucciones**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T14:34:38.796217Z",
     "start_time": "2020-04-07T14:34:38.782255Z"
    },
    "id": "7wTyult1zvIl"
   },
   "source": [
    "- La competencia consiste en resolver 4 problemas de clasificación **distintos**, cada uno con tres clases posibles. Por cada problema deberán crear un clasificador distinto. La evaluación de la competencia se realiza en base a 3 métricas: `AUC`, `Kappa` y `Accuracy`. Los mejores puntajes en cada una de estas métricas serán quienes ganen la competencia.\n",
    "\n",
    "- Para comenzar se les entregará en este notebook la estructura del informe a entregar y el código de un baseline con el cuál pueden comparar los resultados de sus experimentos. Este baseline consiste en la creación de features y una clasificación simple siguiendo el paradigma de Machine Learning empírico. Los puntajes obtenidos por el baseline los pueden visualizar en el link de CodaLab buscando al usuario **cc6205**. Esperamos que los superen fácilmente 😉\n",
    "\n",
    "- Para participar, deben registrarse en CodaLab y luego ingresar a la competencia usando el siguiente [link](https://competitions.codalab.org/competitions/30330?secret_key=b2ed0be7-bf23-42a1-9400-f85fa1b7bae7). \n",
    "\n",
    "- Está permitido hacer grupos de máximo 4 alumnos. Cada grupo debe tener un nombre de equipo, para ello en CodaLab pueden dirigirse a settings y luego cambiar el Team Name. Sólo una persona debe administrar la cuenta del grupo y se verificará que no se hayan creado múltiples cuentas por grupo.\n",
    "\n",
    "- En total pueden hacer un **máximo de 4 submissions**, hagan muchos experimentos probando en el conjunto de test antes de realizar el envío.\n",
    "\n",
    "- Es importante que hagan varios experimentos incorporando técnicas como [cross-validation](https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada#:~:text=La%20validaci%C3%B3n%20cruzada%20o%20cross,datos%20de%20entrenamiento%20y%20prueba.) o [random sampling](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c) antes de enviar sus predicciones a CodaLab, ya que les puede dar un mejor indicio del nivel de generalización de sus modelos. \n",
    "\n",
    "- Asegúrense que la distribución de las clases sea balanceada en las particiones de training y testing debido a que existe un desbalanceo. \n",
    "\n",
    "- Verificar que el formato de la submission coincida con el de la competencia. De lo contrario, se les será evaluado incorrectamente ya que el Script de evaluación espera como input dicho formato. En el código de las métricas pueden verificar cómo son los inputs.\n",
    "\n",
    "- No se limiten a los contenidos vistos ni a scikit ni a este baseline. No tienen restricciones entre utilizar Deep Learning o Machine Learning empírico. Si reutilizan gran cantidad de código de alguna página por favor mostrar la referencia en su código. ¡Usen todo su conocimiento e ingenio en mejorar sus sistemas para poder ganar la competencia! \n",
    "\n",
    "- **Es requisito entregar el reporte con el código y haber participado en la competencia para ser evaluado. Un código sin reporte o un reporte sin código serán evaluados con la nota mínima.**\n",
    "\n",
    "- Todas las dudas escríbanlas en el canal de Discord de competencias. Los emails que lleguen al equipo docente serán remitidos a ese medio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:25:19.677190Z",
     "start_time": "2020-04-07T15:25:19.671206Z"
    },
    "id": "jiDISxa-zvIn"
   },
   "source": [
    "**Importante**: Recuerden poner su nombre y el de su usuario o de equipo (en caso de que aplique) en el reporte. NO serán evaluados Notebooks sin nombre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igf7TBfSzvIo"
   },
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6moqxkEwCe-"
   },
   "source": [
    "## **Reporte a entregar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo7vfXV4wD8s"
   },
   "source": [
    "Uno de los puntos claves en la evaluación de esta competencia es elaborar un informe claro y preciso, argumentando las decisiones tomadas al momento de crear sus modelos para que el cuerpo docente pueda entenderlos. La estructura que debe contener es la siguiente:\n",
    "\n",
    "1.\t**Introducción**: Presentar brevemente el problema a resolver, incluyendo la formalización de la task (cómo son los inputs y outputs del problema) y los desafíos que ven al analizar el corpus entregado. (**0.5 puntos**)\n",
    "2.\t**Representaciones**: Describir los atributos y representaciones usadas como entrada de los clasificadores, **recordar** que para entrenar modelos el input debe tener su representación numérica. Si bien, con Bag of Words (**baseline**) ya se comienzan a percibir buenos resultados, pueden mejorar su evaluación agregando más atributos y representaciones diseñadas a mano, sean lo más creativos posible. Más abajo encontrarán una lista de estos posibles atributos que les podrá ser de utilidad. (**1 punto**)\n",
    "3.\t**Algoritmos**: Describir **brevemente** los algoritmos de clasificación usados, tanto si fueron algoritmos ya vistos en clases o bien arquitecturas de Deep Learning. (**0.5 puntos**)\n",
    "4.\t**Métricas de evaluación**: Describir brevemente las métricas utilizadas en la evaluación, indicando qué miden y su interpretación. (**0.5 puntos**)\n",
    "\n",
    "5.  **Diseño experimental**: Esta es una de las secciones más importantes del reporte. Deben describir minuciosamente los experimentos que realizarán en la siguiente sección. Describir las variables de control que manejarán, algunos ejemplos pueden ser: Los parámetros de los clasificadores, parámetros en las funciones con que procesan los textos y los transforman, parámetros para el cross-validation, particiones de datos utilizadas, etc. En caso que utilicen redes neuronales, ser claros con el conjunto de hiperparámetros que probarán, la decisión en las funciones de optimización, función de pérdida,  regulación, etc. Básicamente explicar qué es lo que veremos en la siguiente sección.\n",
    "(**1 punto**)\n",
    "\n",
    "6.\t**Experimentos**: Incluyan todo el código de sus experimentos aquí. ¡Es vital haber realizado varios experimentos para sacar una buena nota! (**1.5 puntos**)\n",
    "\n",
    "7. **Resultados**: Comparar los resultados obtenidos utilizando diferentes algoritmos y representaciones.  Pueden mostrar los resultados sobre la partición de validación en caso que la generen o sobre los resultados del conjunto de testing. Mostrar los resultados en alguna tabla, pueden poner aquí también los resultados obtenidos al realizar la submission. (**0.5 puntos**)\n",
    "\n",
    "8. **Conclusiones**:  Discutir resultados, proponer trabajo futuro. (**0.5 puntos**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMSn_tDYwOb1"
   },
   "source": [
    "## **Descripción Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T19:18:43.301002Z",
     "start_time": "2019-08-21T19:18:43.298037Z"
    },
    "id": "30fPWG5pzvIm"
   },
   "source": [
    "` `\n",
    "El baseline de la sección **Experimentos** contiene un código básico que resuelve la task y es el modelo subido por **cc6205-baseline** a la competencia. Pueden modificar el código como quieran siempre y cuando no cambien las funciones de las métricas y el formato en que se suben los archivos a la competencia, ya que ese es el formato en que realizamos la evaluación. En concretro, el baseline hace lo siguiente:\n",
    "` `\n",
    "\n",
    "- Obtiene los datasets desde el repositorio del curso.\n",
    "- Divide los datasets en train (datos que están etiquetados) y target set (datos no etiquetados para la competencia). Además, por cada dataset en train, se divide en un conjunto de entrenamiento y uno de prueba. Aquí la mejor práctica sería cambiar el código para obtener un conjunto de entrenamiento, validación y prueba.\n",
    "\n",
    "- Crea un Pipeline que: \n",
    "    - Crea features personalizados para la representación numérica.\n",
    "    - Transforma los dataset a bag of words (BoW).  \n",
    "    - Entrena un clasificador usando cada train set.\n",
    "- Clasifica y evalua el sistema creado usando el test set.\n",
    "- Clasifica el target set.\n",
    "- Genera una submission con el target en formato zip en el directorio en donde se está ejecutando el notebook. \n",
    "\n",
    "` `\n",
    "\n",
    "Algunas pistas sobre como mejorar el rendimiento de los sistemas que creen. (Esto tendrá mas sentido cuando vean el código)\n",
    "\n",
    "- **Vectorizador**: Investigar los modulos de `nltk`, en particular, `TweetTokenizer`, `mark_negation` para reemplazar los tokenizadores. También, el parámetro `ngram_range` (Ojo que el clf naive bayes no debería usarse con n-gramas, ya que rompe el supuesto de independencia). Además, implementar los atributos que crean útiles desde el listado del enunciado. Investigar también el vectorizador tf-idf.\n",
    "\n",
    "- **Clasificador**: Investigar otros clasificadores más efectivos que naive bayes. Estos deben poder retornar la probabilidad de pertenecia de las clases (ie: implementar la función `predict_proba`).\n",
    "\n",
    "- **Features**: Recuerden que pueden implementar todas las features que se les ocurra! Aquí les adjuntamos algunos ejemplos:\n",
    "    -\tWord n-grams.\n",
    "    -\tCharacter n-grams. \n",
    "    -\tPart-of-speech tags.\n",
    "    -\tSentiment Lexicons (Lexicon = A set of words with a label or associated value.).\n",
    "        - Count the number of positive and negative words within a sentence.\n",
    "        - If the lexicon has associated intensity of feeling (for example in a decimal), then take the average of the intensity of the sentence according to the feeling, the sum, etc.\n",
    "        -\tA good lexicon of sentiment: [Bing Liu](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar) \n",
    "        - A reference with a lot of [sentiment lexicons](https://medium.com/@datamonsters/sentiment-analysis-tools-overview-part-1-positive-and-negative-words-databases-ae35431a470c). \n",
    "    -\tThe number of elongated words (words with one character repeated more than two times).\n",
    "    -\tThe number of words with all characters in uppercase.\n",
    "    -\tThe presence and the number of positive or negative emoticons.\n",
    "    -\tThe number of individual negations.\n",
    "    -\tThe number of contiguous sequences of dots, question marks and exclamation marks.\n",
    "    -\tWord Embeddings: Here are some good ideas on how to use them.\n",
    "    https://stats.stackexchange.com/questions/221715/apply-word-embeddings-to-entire-document-to-get-a-feature-vector\n",
    "\n",
    "- **Reducción de dimensionalidad**: También puede serles de ayuda. Referencias [aquí](https://scikit-learn.org/stable/modules/unsupervised_reduction.html).\n",
    "\n",
    "- Por último, pueden encontrar mas referencias de cómo mejorar sus features, el vectorizador y el clasificador [aquí](https://affectivetweets.cms.waikato.ac.nz/benchmark/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT7ZpVRuzGAF"
   },
   "source": [
    "# **Entregable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:34:25.683540Z",
     "start_time": "2020-03-31T13:34:25.673430Z"
    },
    "id": "E29LEMZ9zvIo"
   },
   "source": [
    "## **1. Introducción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W20NnoduzvIo"
   },
   "source": [
    "El siguiente trabajo consiste en clasificar tweets para una competencia estilo *kaggle*. Más en particular, se tiene 4 datasets de tweets de con distintos sentimientos: anger (enojo), fear (miedo), joy (alegría), sadness (tristeza). Cada tweet de cada dataset puede ser 3 clases distintas que representan la intensidad de los sentimientos asociados a cada dataset. \n",
    "\n",
    "Para resolver cada problema asociado a cada dataset se construirá un clasificador para cada problema. Los clasificadores que resuelven los problemas son basados en el paradigma Machine Learning empírico, es decir, son clasificadores que se entrenan con datasets que contienen representaciones de tweets y sus respectivas clases. Luego, para precedir un nuevo tweet sin clase, se *pasa* la representación del tweet al clasificador para que entregue como output una clase que representa la clase predicha para el input dado. En el trabajo se experimentará con los clasificadores y, por ende, se probarán los clasificadores en todos los datasets y se estudiará el poder de generalización de cada clasificador. Así, se crearán *pipelines* que permitirán testear combinaciones de representaciones de tweets y clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:47:13.474238Z",
     "start_time": "2020-03-31T13:47:13.454068Z"
    },
    "id": "OTAIEnSJzvIp"
   },
   "source": [
    "## **2. Representaciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:47:17.719268Z",
     "start_time": "2020-03-31T13:47:17.709207Z"
    },
    "id": "EV1qBv-MzvIp"
   },
   "source": [
    "Los tweets son representandos como la unión de distintos features. Todos los tweets tienen una base de representación que consiste en un vector td-idf de 1-grama o 2-grama generado a partir de un vocabulario creado a partir de cada dataset. Luego, a cada representación incial de un tweet se le asigna uno o algunos de los siguientes features:\n",
    "\n",
    "- *Lexicon* : Dado un lexico que define palabras positivas y palabras negativas, se cuenta las palabras positivas y negativas que posee un tweet.\n",
    "- *Emoji Lexicon*: Dado un lexico que define emojis positivos y emojis negativos, se cuenta las emojis positivas y negativos.\n",
    "- *CharsCount* : Para cada de los símbolos \\!, ¡, \\#, \\@, \\? y ¿, se cuenta la cantidad de dicho símbolo.\n",
    "- *UperCounts* : Se cuenta la cantidad de palabras en mayúsculas presentes.\n",
    "- *ElongatedWords* : Se cuenta la cantidad de palabras con elongaciones. Por ejemplo, la palabra *hoooooola* es la palabra *hola* con una elongación en la letra *o*.\n",
    "- *Polarity Scores* : Se calcula la *polaridad* en el texto. Nótese que este feature es el único que utiliza una *herramienta* externa.\n",
    "\n",
    "La representación escogida depende del pipeline: los cuatros pipelines tienen distintas representaciones para los tweets. Lo anteriormente mencionado se realiza de dicha forma ya que como no se conoce la mejor representación para cada problema, se buca generar cuatro representaciones distintas y probar dichas representaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMOjYSQezvIq"
   },
   "source": [
    "## **3. Algoritmos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bPiFs33zilS"
   },
   "source": [
    "Para clasificar los tweets dada las representaciones descritas en la sección anterior (sección 2), se utilizaron los siguientes algoritmos:\n",
    "\n",
    "- *Random Forest*: Es un algoritmo de clasificación que consiste en crear variados *Decision trees*, clasificar el input en cada árbol de decisión y, dado los resultados obtenidos a partir de las distintas clasifaciones con los árboles de decisiones creados, elegir la clasificación más *común*, es decir, se escoge la clase más predecida por los árboles de decisión.\n",
    "- *Logistic Regression*: Método estadístico para clasificar objetos. Más en particular, es un método de clasificación lineal que genera un resultado binario (el objeto pertenece o no a la clase). Sin embargo, permite generar predicciones para problemas multiclase.\n",
    "\n",
    "Del mismo modo que las representaciones, el algoritmo escogido depende del pipeline: los cuatros pipelines tienen distintos algoritmos para los tweets. Lo anteriormente mencionado se realiza de dicha forma ya que como no se conoce el mejor algoritmo para la clasificaciones, se buca generar cuatro combinaciones de representaciones y algoritmos de representación y escoger la que entregue mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:47:52.064631Z",
     "start_time": "2020-03-31T13:47:52.044451Z"
    },
    "id": "ECjkdgdwzvIq"
   },
   "source": [
    "## **4. Métricas de Evaluación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6eHJdHBzvIr"
   },
   "source": [
    "- **AUC**: Mide el área bajo la curva ROC producida por el clasificador. Esta curva se logra ploteando la tasa de verdaderos positivos (TPR) contra la tasa de falsos positivos (FPR), obteniendo así una métrica de *recall* versus *fall-out*. De esta manera, AUC-ROC permite saber qué tanto mejora la performance del clasificador al variar el umbral de discriminación.\n",
    "\n",
    "\n",
    "- **Kappa**: Mide la performance del clasificador comparado a un clasificador aleatorio correspondiente con la distribución esperada de los datos. Para esto compara la *Accuracy esperada* (del clasificador aleatorio) con la *Accuracy observada* (del clasificador a evaluar) computando\n",
    "\n",
    "$$\n",
    "\\frac{Acc_o - Acc_e}{1 - Acc_e}\n",
    "$$\n",
    "\n",
    "\n",
    "- **Accuracy**: Mide la cantidad de predicciones correctas respecto a la totalidad de los casos. De acuerdo a la fórmula\n",
    "\n",
    "$$\n",
    "\\frac{VP + VN}{VP + FP + VN + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJyTrr2onLOo"
   },
   "source": [
    "## **5. Diseño experimental**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnhEwjh_nP9M"
   },
   "source": [
    "Inicialmente, se revisó algunos ejemplos de tweet de algún dataset. Así, se revisó la estructura y forma de los tweet y posibles atributos para crear features para representar los tweet. En particular, se encontraron atributos verbales (como palabras que expresan sentimientos) y no verbales (emojis, mayúsculas, etcétera).\n",
    "\n",
    "Luego, se definieron 4 combinaciones de representaciones y clasificadores. De esa forma, se crearon los siguientes pipelines\n",
    "- **Pipeline 1**: \n",
    "  -  Representación: Tf-idf + Non verbal custom features (ElongatedWords, CharsCount, UpperCount y EmojiLexicon)\n",
    "  - Clasificador: RandomForest\n",
    "- **Pipeline 2**: \n",
    "  -  Representación: Tf-idf 2-gram + verbal custom features (Lexicon y Polarity)\n",
    "  - Clasificador: LogisticRegresion\n",
    "- **Pipeline 3**: \n",
    "  -  Representación: Tf-idf  + all custom features (ElongatedWords, CharsCount, UpperCount, EmojiLexicon, Lexicon y Polarity)\n",
    "  - Clasificador: RandomForest\n",
    "- **Pipeline 4**: \n",
    "  -  Representación: Tf-idf 2-gram más all custom features (ElongatedWords, CharsCount, UpperCount, EmojiLexicon, Lexicon y Polarity)\n",
    "  - Clasificador: LogisticRegression\n",
    "\n",
    "Con los pipelines ya establecidos, se realizó el siguiente experimento:\n",
    "- Para cada dataset y por cada pipeline, se *corre* una cantidad de *n* veces el pipeline en el dataset. Es decir, se toma el dataset, se realiza un split aleatorio del dataset en datos de entrenamiento y datos de testeo. Luego, se representan los datos de entrenamiento con la representación asociada al pipeline actual y se entrena el clasificador. Luego, se clasifica el dataset de testos y se calculan métricas de evaluación dado la clase original y la clase predicha de cada tweet del conjunto de testeo. Así, se calculó el promedio de las métricas de evaluación para el pipeline en cada dataset y el promedio general del pipeline para cada métrica.\n",
    "\n",
    "El experimento anterior permite medir el poder de generalización que entrega cada pipeline. Nótese que en el baseline se corría una vez cada pipeline en cada dataset. Dicho experimento inicial se mantuvo, es decir, está presente en el informe. Sin embargo, fue necesario generar un experimento más robusto para probar las representaciones y clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OX5Ib_pCzvIr"
   },
   "source": [
    "## **6. Experimentos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T13:31:40.023344Z",
     "start_time": "2020-03-31T13:31:40.003541Z"
    },
    "id": "aK24MJ8jzvIr"
   },
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:20.587160Z",
     "start_time": "2020-04-07T15:44:19.319386Z"
    },
    "id": "FukgFUTUzvIs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /home/tridimensional/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/tridimensional/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/tridimensional/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import codecs\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "nltk.download('opinion_lexicon')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import opinion_lexicon, stopwords\n",
    "from nltk import TweetTokenizer, download\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FevBPus0zvIs"
   },
   "source": [
    "### Definir métodos de evaluación (**NO tocar este código**)\n",
    "\n",
    "Estas funciones están a cargo de evaluar los resultados de la tarea. No deberían cambiarlas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:20.604066Z",
     "start_time": "2020-04-07T15:44:20.589106Z"
    },
    "id": "9wlllV7PzvIs"
   },
   "outputs": [],
   "source": [
    "def auc_score(test_set, predicted_set):\n",
    "    high_predicted = np.array([prediction[2] for prediction in predicted_set])\n",
    "    medium_predicted = np.array(\n",
    "        [prediction[1] for prediction in predicted_set])\n",
    "    low_predicted = np.array([prediction[0] for prediction in predicted_set])\n",
    "    high_test = np.where(test_set == 'high', 1.0, 0.0)\n",
    "    medium_test = np.where(test_set == 'medium', 1.0, 0.0)\n",
    "    low_test = np.where(test_set == 'low', 1.0, 0.0)\n",
    "    auc_high = roc_auc_score(high_test, high_predicted)\n",
    "    auc_med = roc_auc_score(medium_test, medium_predicted)\n",
    "    auc_low = roc_auc_score(low_test, low_predicted)\n",
    "    auc_w = (low_test.sum() * auc_low + medium_test.sum() * auc_med +\n",
    "             high_test.sum() * auc_high) / (\n",
    "                 low_test.sum() + medium_test.sum() + high_test.sum())\n",
    "    return auc_w\n",
    "\n",
    "\n",
    "def evaluate(predicted_probabilities, y_test, labels, dataset_name):\n",
    "    # Importante: al transformar los arreglos de probabilidad a clases,\n",
    "    # entregar el arreglo de clases aprendido por el clasificador.\n",
    "    # (que comunmente, es distinto a ['low', 'medium', 'high'])\n",
    "    predicted_labels = [\n",
    "        labels[np.argmax(item)] for item in predicted_probabilities\n",
    "    ]\n",
    "\n",
    "    print('Confusion Matrix for {}:\\n'.format(dataset_name))\n",
    "    print(\n",
    "        confusion_matrix(y_test,\n",
    "                         predicted_labels,\n",
    "                         labels=['low', 'medium', 'high']))\n",
    "\n",
    "    print('\\nClassification Report:\\n')\n",
    "    print(\n",
    "        classification_report(y_test,\n",
    "                              predicted_labels,\n",
    "                              labels=['low', 'medium', 'high']))\n",
    "    # Reorder predicted probabilities array.\n",
    "    labels = labels.tolist()\n",
    "    \n",
    "    predicted_probabilities = predicted_probabilities[:, [\n",
    "        labels.index('low'),\n",
    "        labels.index('medium'),\n",
    "        labels.index('high')\n",
    "    ]]\n",
    "    \n",
    "    \n",
    "    auc = round(auc_score(y_test, predicted_probabilities), 3)\n",
    "    print(\"Scores:\\n\\nAUC: \", auc, end='\\t')\n",
    "    kappa = round(cohen_kappa_score(y_test, predicted_labels), 3)\n",
    "    print(\"Kappa:\", kappa, end='\\t')\n",
    "    accuracy = round(accuracy_score(y_test, predicted_labels), 3)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print('------------------------------------------------------\\n')\n",
    "    return np.array([auc, kappa, accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkOP6ugwzvIt"
   },
   "source": [
    "### Datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.068137Z",
     "start_time": "2020-04-07T15:44:20.606061Z"
    },
    "id": "D1XhFPhrzvIt"
   },
   "outputs": [],
   "source": [
    "# Datasets de entrenamiento.\n",
    "train = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/anger-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/fear-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/joy-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/train/sadness-train.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'])\n",
    "}\n",
    "# Datasets que deberán predecir para la competencia.\n",
    "target = {\n",
    "    'anger': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/anger-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'fear': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/fear-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'joy': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/joy-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE']),\n",
    "    'sadness': pd.read_csv('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/assignment_1/data/target/sadness-target.txt', sep='\\t', names=['id', 'tweet', 'class', 'sentiment_intensity'], na_values=['NONE'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.088707Z",
     "start_time": "2020-04-07T15:44:21.069757Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1647890199751,
     "user": {
      "displayName": "Gabriel Iturra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghe-mqbWbrqQ1gVhaBhwEAK5Uu5cfHEnENzwLJUGA=s64",
      "userId": "02319919045117626989"
     },
     "user_tz": 180
    },
    "id": "flg2Zw2mzvIt",
    "outputId": "1444867d-5d1f-4ba8-de05-6e13a5c1e113"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>10288</td>\n",
       "      <td>luv seeing a man with a scowl on his face walk...</td>\n",
       "      <td>anger</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10065</td>\n",
       "      <td>In 2016, Black people are STILL fighting to be...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10040</td>\n",
       "      <td>Still can't log into my fucking Snapchat#Snapc...</td>\n",
       "      <td>anger</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>10644</td>\n",
       "      <td>Time wounds all heels.\\n\\n #DrunkJesus #rt #lo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>10460</td>\n",
       "      <td>Brendan Rodgers looks fuming 😭</td>\n",
       "      <td>anger</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet  class  \\\n",
       "288  10288  luv seeing a man with a scowl on his face walk...  anger   \n",
       "65   10065  In 2016, Black people are STILL fighting to be...  anger   \n",
       "40   10040  Still can't log into my fucking Snapchat#Snapc...  anger   \n",
       "644  10644  Time wounds all heels.\\n\\n #DrunkJesus #rt #lo...  anger   \n",
       "460  10460                     Brendan Rodgers looks fuming 😭  anger   \n",
       "\n",
       "    sentiment_intensity  \n",
       "288              medium  \n",
       "65                 high  \n",
       "40                 high  \n",
       "644              medium  \n",
       "460              medium  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de algunas filas aleatorias del dataset etiquetado:\n",
    "train['anger'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1647890201421,
     "user": {
      "displayName": "Gabriel Iturra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghe-mqbWbrqQ1gVhaBhwEAK5Uu5cfHEnENzwLJUGA=s64",
      "userId": "02319919045117626989"
     },
     "user_tz": 180
    },
    "id": "XB7hb7KH2DFK",
    "outputId": "4c3397ce-471d-45d8-a944-fcde1abdf2cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>sentiment_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>11313</td>\n",
       "      <td>my dogs making the most RIDICULOUS sounds righ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>11473</td>\n",
       "      <td>@SaraLuvvXXX : Whaaaat?!? Oh hell no. I was je...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>11150</td>\n",
       "      <td>Every dancers dream song #snap #worldpower</td>\n",
       "      <td>anger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>11297</td>\n",
       "      <td>The side effects of #fighting and #disrespect....</td>\n",
       "      <td>anger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>11189</td>\n",
       "      <td>@loueezecee I don't know how much more of that...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet  class  \\\n",
       "372  11313  my dogs making the most RIDICULOUS sounds righ...  anger   \n",
       "532  11473  @SaraLuvvXXX : Whaaaat?!? Oh hell no. I was je...  anger   \n",
       "209  11150         Every dancers dream song #snap #worldpower  anger   \n",
       "356  11297  The side effects of #fighting and #disrespect....  anger   \n",
       "248  11189  @loueezecee I don't know how much more of that...  anger   \n",
       "\n",
       "     sentiment_intensity  \n",
       "372                  NaN  \n",
       "532                  NaN  \n",
       "209                  NaN  \n",
       "356                  NaN  \n",
       "248                  NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de algunas filas aleatorias del dataset no etiquetado\n",
    "target['anger'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5aNqEfVzvIv"
   },
   "source": [
    "### Analizar los datos \n",
    "\n",
    "En esta sección analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.117633Z",
     "start_time": "2020-04-07T15:44:21.090703Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1647890204981,
     "user": {
      "displayName": "Gabriel Iturra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghe-mqbWbrqQ1gVhaBhwEAK5Uu5cfHEnENzwLJUGA=s64",
      "userId": "02319919045117626989"
     },
     "user_tz": 180
    },
    "id": "u5007JRgzvIv",
    "outputId": "f8af2406-ea94-4716-9414-1b6d7e2450a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: anger \n",
      " sentiment_intensity\n",
      "high      163\n",
      "low       161\n",
      "medium    617\n",
      "dtype: int64\n",
      "----------------------------------------------------------\n",
      "\n",
      "Dataset: fear \n",
      " sentiment_intensity\n",
      "high      270\n",
      "low       288\n",
      "medium    699\n",
      "dtype: int64\n",
      "----------------------------------------------------------\n",
      "\n",
      "Dataset: joy \n",
      " sentiment_intensity\n",
      "high      195\n",
      "low       219\n",
      "medium    488\n",
      "dtype: int64\n",
      "----------------------------------------------------------\n",
      "\n",
      "Dataset: sadness \n",
      " sentiment_intensity\n",
      "high      197\n",
      "low       210\n",
      "medium    453\n",
      "dtype: int64\n",
      "----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in train:\n",
    "    print(f'Dataset: {dataset_name} \\n', train[dataset_name].groupby(['sentiment_intensity']).size())\n",
    "    print('----------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stZ6ig5hzvIv"
   },
   "source": [
    "### Custom Features \n",
    "\n",
    "Para crear features personalizadas implementaremos nuestros propios Transformers (estandar de scikit para crear nuevas features entre otras cosas). Para esto:\n",
    "\n",
    "1. Creamos nuestra clase Transformer extendiendo BaseEstimator y TransformerMixin. En este ejemplo, definiremos `CharsCountTransformer` que cuenta caracteres relevantes ('!', '?', '#', '@') en los tweets.\n",
    "2. Definimos una función cómo `get_relevant_chars` que opera por cada tweet y retorna un arreglo.\n",
    "3. Hacemos un override de la función `transform` en donde iteramos por cada tweet, llamamos a la función que hicimos antes y agregamos sus resultados a un arreglo. Finalmente lo retornamos.\n",
    "\n",
    "Esto nos facilitará el trabajo mas adelante. Una Guia completa de las transformaciones predefinidas en scikit pueden encontrarla [aquí](https://scikit-learn.org/stable/data_transforms.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.128600Z",
     "start_time": "2020-04-07T15:44:21.119624Z"
    },
    "id": "tNPB8zc9zvIw"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class CustomTokenizer:\n",
    "    def __init__(self):\n",
    "        self.tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "    def tokenizer_tweet(self, tweet):\n",
    "        return self.tweet_tokenizer.tokenize(tweet)\n",
    "    \n",
    "    def tokenizer_with_stemming_doc(self, doc):\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        doc_tokenize = list(map(lambda x: self.tweet_tokenizer.tokenize(x), doc))\n",
    "        doc_tokenize = reduce(lambda x,y: x + y, doc_tokenize, [])\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tweet = list(filter(lambda x: x not in stop_words, doc_tokenize))\n",
    "        return [stemmer.stem(word) for word in doc_tokenize]\n",
    "    \n",
    "    def tokenizer_with_lemmatization_tweet(self, tweet):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tweet = self.tweet_tokenizer.tokenize(tweet)\n",
    "        tweet = reduce(lambda l, el: l + re.split(r\"(\\w+)\", el), tweet, [])\n",
    "        tweet = list(filter(lambda x: x != '', tweet))\n",
    "        \n",
    "        return [lemmatizer.lemmatize(word) for word in tweet]\n",
    "\n",
    "\n",
    "class Feature(ABC):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = CustomTokenizer()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_feature(self, tweet: list):\n",
    "        pass\n",
    "\n",
    "class Polarity(Feature):\n",
    "    # override\n",
    "    def get_feature(self, tweet: str):\n",
    "        values = list(SentimentIntensityAnalyzer().polarity_scores(tweet).values())\n",
    "        values = list(map(lambda x: x if x > 0 else 0, values))\n",
    "        return list(map(lambda x: int(x*10), values))\n",
    "    \n",
    "                    \n",
    "class Lexicon(Feature):\n",
    "    # override\n",
    "    def get_feature(self, tweet: str):\n",
    "        negative_words = set(opinion_lexicon.negative())\n",
    "        positive_words = set(opinion_lexicon.positive())\n",
    "        \n",
    "        negatives = 0\n",
    "        positives = 0\n",
    "        \n",
    "        tweet = self.tokenizer.tokenizer_with_lemmatization_tweet(tweet)\n",
    "        for word in tweet:\n",
    "            if word in negative_words:\n",
    "                negatives += 1\n",
    "            if word in positive_words:\n",
    "                positives += 1\n",
    "\n",
    "        return [positives, negatives]\n",
    "\n",
    "\n",
    "class ElongatedWords(Feature):\n",
    "    # override\n",
    "    def get_feature(self, tweet: str):\n",
    "\n",
    "        elongated_words = 0\n",
    "        tweet = self.tokenizer.tokenizer_tweet(tweet)\n",
    "        for word in tweet:\n",
    "            current_letter = word[0]\n",
    "            count = -1\n",
    "            for letter in word:\n",
    "                if letter == current_letter:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    if count >= 4:\n",
    "                        elongated_words += 1\n",
    "                        current_letter = letter\n",
    "                        count = 0\n",
    "\n",
    "        return [elongated_words]\n",
    "\n",
    "    \n",
    "class EmojiLexicon(Feature):\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_csv(\n",
    "            \"emoji-sentiment-ranking/emoji-sentiment-data.csv\",\n",
    "            index_col='Emoji'\n",
    "        )\n",
    "        self.df['sentiment-score'] = (self.df.Positive - self.df.Negative) / self.df.Occurrences\n",
    "        self.df['neut-score'] = (self.df.Neutral) / self.df.Occurrences\n",
    "        self.df = self.df.loc[self.df['neut-score'] <= 0.3]\n",
    "        \n",
    "    def get_feature(self, tweet: str):\n",
    "        positives = 0\n",
    "        negatives = 0\n",
    "        positive_score = 0\n",
    "        negative_score = 0\n",
    "        for word in tweet:\n",
    "            if word in self.df.index:\n",
    "                score = self.df.loc[word, 'sentiment-score']\n",
    "                positives += 1 if score >= 0.01 else 0\n",
    "                negatives += 1 if score <= -0.01 else 0\n",
    "                positive_score += score if score >= 0.01 else 0\n",
    "                negative_score += abs(score) if score <= -0.01 else 0\n",
    "        return [positives, negatives, positive_score, negative_score]\n",
    "\n",
    "class CharsCount(Feature):\n",
    "    # override\n",
    "    def get_feature(self, tweet: str):\n",
    "        chars = ['#', '!', '¡', '?', '¿', '@', '.', '.']\n",
    "        return list(map(lambda x: tweet.count(x), chars))\n",
    "\n",
    "\n",
    "class UpperCount(Feature):\n",
    "    # override\n",
    "    def get_feature(self, tweet: str):\n",
    "        \n",
    "        tweet = self.tokenizer.tokenizer_tweet(tweet)\n",
    "        upper_count = 0\n",
    "        for word in tweet:\n",
    "            word_list = list(map(lambda x: x.isupper(), word))\n",
    "            word_list = list(map(lambda x: 1 if x else 0, word_list))\n",
    "            upper_count = reduce(lambda x,y: x+y, word_list, 0)\n",
    "        return [upper_count]\n",
    "\n",
    "\n",
    "class CustomTransformer(ABC, BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X, y=None):\n",
    "        chars = []\n",
    "\n",
    "        for tweet in X:\n",
    "            features = []\n",
    "\n",
    "            for class_ in self.classes:\n",
    "                feature = class_().get_feature(tweet)\n",
    "                features += feature\n",
    "\n",
    "            chars.append(features)\n",
    "\n",
    "        return np.array(chars)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "class FirstTransformer(CustomTransformer):\n",
    "    \"\"\"\n",
    "    Custom non verbal features\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.classes = [\n",
    "            ElongatedWords,\n",
    "            CharsCount, \n",
    "            UpperCount,\n",
    "            EmojiLexicon\n",
    "        ]\n",
    "\n",
    "class SecondTransformer(CustomTransformer):\n",
    "    \"\"\"\n",
    "    Custom verbal features\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.classes = [\n",
    "            Lexicon,\n",
    "            Polarity\n",
    "        ]\n",
    "\n",
    "class ThirdTransformer(CustomTransformer):\n",
    "    \"\"\"\n",
    "    All custom features\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.classes = [\n",
    "            Lexicon,\n",
    "            ElongatedWords,\n",
    "            CharsCount, \n",
    "            UpperCount,\n",
    "            Polarity,\n",
    "            EmojiLexicon\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.145564Z",
     "start_time": "2020-04-07T15:44:21.131593Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647890207937,
     "user": {
      "displayName": "Gabriel Iturra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghe-mqbWbrqQ1gVhaBhwEAK5Uu5cfHEnENzwLJUGA=s64",
      "userId": "02319919045117626989"
     },
     "user_tz": 180
    },
    "id": "lCQzsuAbzvIw",
    "outputId": "6c10a7d9-6289-445e-aa2d-d61a08d4f0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet original: @cineworld 'Congratulations your Free 1 month has been activated' Then charges £34.80 the same month. Absolutely furious 😡\n",
      "Features creados: [0.         0.         0.         0.         0.         0.\n",
      " 1.         2.         2.         0.         0.         1.\n",
      " 0.         0.17328042]\n"
     ]
    }
   ],
   "source": [
    "# Veamos que sucede si ejecutamos el transformer\n",
    "sample = train['anger'].sample(5, random_state = 22).tweet\n",
    "sample_features = FirstTransformer().transform(sample)\n",
    "\n",
    "# Se puede verificar que el conteo de símbolos es consistente con el transformer creado.\n",
    "print(f'Tweet original: {sample.iloc[0]}')\n",
    "print(f'Features creados: {sample_features[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO_yIepczvIx"
   },
   "source": [
    "### Definir la representación y el clasificador\n",
    "\n",
    "Para esto, definiremos Pipelines. Un `Pipeline` es una lista de transformaciones y un estimador(clasificador) ubicado al final el cual define el flujo que seguiran nuestros datos dentro del sistema que creemos. Nos permite ejecutar facilmente el mismo proceso sobre todos los datasets que usemos, simplificando así nuestra programación.\n",
    "\n",
    "El pipeline más básico que podemos hacer es transformar el dataset a Bag of Words y después usar clasificar el BoW usando NaiveBayes:\n",
    "\n",
    "```python\n",
    "    Pipeline([('bow', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "```\n",
    "\n",
    "\n",
    "Ahora, si queremos usar nuestra transformación para agregar las features que creamos, usaremos `FeatureUnion`. Esta simplemente concatenará los vectores resultantes de ejecutar BoW y los Transformer en un solo vector.\n",
    "\n",
    "```python\n",
    "    Pipeline([('features',FeatureUnion([('bow', CountVectorizer()),\n",
    "                                        ('chars_count',CharsCountTransformer())])),\n",
    "              ('clf', MultinomialNB())])\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDbHjXv-zvIx"
   },
   "source": [
    "Recuerden que cada pipeline representa un sistema de clasificación distinto. Por lo mismo, deben instanciar uno por cada problema que resuelvan. De lo contrario, podrían solapar resultados.  Para esto, les recomendamos crear los pipeline en distintas funciones, como la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.155528Z",
     "start_time": "2020-04-07T15:44:21.149545Z"
    },
    "id": "z_R6tyMCzvIy"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_experiment_1_pipeline():\n",
    "    \"\"\"\n",
    "    Non verbal features\n",
    "    \"\"\"\n",
    "    features = (\n",
    "        'features', \n",
    "        FeatureUnion([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=CustomTokenizer().tokenizer_with_stemming_doc)),\n",
    "            ('non_verbal', FirstTransformer())\n",
    "        ])\n",
    "    )\n",
    "    clf = ('clf', RandomForestClassifier())\n",
    "    \n",
    "    return Pipeline([features, clf])\n",
    "\n",
    "def get_experiment_2_pipeline():\n",
    "    \"\"\"\n",
    "    Verbal features\n",
    "    \"\"\"\n",
    "    features = (\n",
    "        'features', \n",
    "        FeatureUnion([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=CustomTokenizer().tokenizer_with_stemming_doc, ngram_range=(1,2))),\n",
    "            ('verbal_features', SecondTransformer())\n",
    "        ])\n",
    "    )\n",
    "    clf = ('clf', LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 10000))\n",
    "\n",
    "    return Pipeline([features, clf])\n",
    "\n",
    "def get_experiment_3_pipeline():\n",
    "    \"\"\"\n",
    "    All features\n",
    "    \"\"\"\n",
    "    features = (\n",
    "        'features', \n",
    "        FeatureUnion([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=CustomTokenizer().tokenizer_with_stemming_doc)),\n",
    "            ('all_features', ThirdTransformer())\n",
    "        ])\n",
    "    )\n",
    "    clf = ('clf', RandomForestClassifier())\n",
    "    return Pipeline([features, clf])\n",
    "            \n",
    "def get_experiment_4_pipeline():\n",
    "    \"\"\"\n",
    "    All features\n",
    "    \"\"\"\n",
    "    features = (\n",
    "        'features', \n",
    "        FeatureUnion([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=CustomTokenizer().tokenizer_with_stemming_doc, ngram_range=(1,2))),\n",
    "            ('all_features', ThirdTransformer())\n",
    "        ])\n",
    "    )\n",
    "    clf = ('clf', LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 10000))\n",
    "    return Pipeline([features, clf])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmMdm98vzvIy"
   },
   "source": [
    "### Ejecutar el pipeline para algún dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.167498Z",
     "start_time": "2020-04-07T15:44:21.157540Z"
    },
    "id": "_eX0cEu-zvIz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(dataset, dataset_name, pipeline):\n",
    "    \"\"\"Creamos el pipeline y luego lo ejecutamos el pipeline sobre un dataset. \n",
    "    Retorna el modelo ya entrenado mas sus labels asociadas y los scores obtenidos al evaluarlo.\"\"\"\n",
    "\n",
    "    # Dividimos el dataset en train y test, aún no se transforma de Strings a valores numéricos.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset.tweet,\n",
    "        dataset.sentiment_intensity,\n",
    "        shuffle=True,\n",
    "        test_size=0.33)\n",
    "    \n",
    "    print(f'# Datos de entrenamiento en dataset {dataset_name}: {len(X_train)}')\n",
    "    print(f'# Datos de testing en dataset {dataset_name}: {len(X_test)}')\n",
    "\n",
    "    # Entrenamos el clasificador (Ejecuta el entrenamiento sobre todo el pipeline). \n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predecimos las probabilidades de intensidad de cada elemento del set de prueba.\n",
    "    predicted_probabilities = pipeline.predict_proba(X_test)\n",
    "\n",
    "    # Obtenemos el orden de las clases aprendidas.\n",
    "    learned_labels = pipeline.classes_\n",
    "    \n",
    "    # Evaluamos:\n",
    "    scores = evaluate(predicted_probabilities, y_test, learned_labels, dataset_name)\n",
    "    return pipeline, learned_labels, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z96C1ZOfzvIz"
   },
   "source": [
    "### Ejecutar el sistema creado por cada train set\n",
    "\n",
    "Este código crea y entrena los 4 sistemas de clasificación y luego los evalua. Para los experimentos, pueden copiar este código variando el pipeline cuantas veces estimen conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.384119Z",
     "start_time": "2020-04-07T15:44:21.170488Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1647890223742,
     "user": {
      "displayName": "Gabriel Iturra",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghe-mqbWbrqQ1gVhaBhwEAK5Uu5cfHEnENzwLJUGA=s64",
      "userId": "02319919045117626989"
     },
     "user_tz": 180
    },
    "id": "OXAxZBdVzvI0",
    "outputId": "dfc387b4-3121-43f4-d892-eca1ee100367",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados pipeline: 1\n",
      "\n",
      "# Datos de entrenamiento en dataset anger: 630\n",
      "# Datos de testing en dataset anger: 311\n",
      "Confusion Matrix for anger:\n",
      "\n",
      "[[  6  47   0]\n",
      " [  5 200   3]\n",
      " [  0  48   2]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.55      0.11      0.19        53\n",
      "      medium       0.68      0.96      0.80       208\n",
      "        high       0.40      0.04      0.07        50\n",
      "\n",
      "    accuracy                           0.67       311\n",
      "   macro avg       0.54      0.37      0.35       311\n",
      "weighted avg       0.61      0.67      0.58       311\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.579\tKappa: 0.072\tAccuracy: 0.669\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset fear: 842\n",
      "# Datos de testing en dataset fear: 415\n",
      "Confusion Matrix for fear:\n",
      "\n",
      "[[ 11  86   1]\n",
      " [  6 217   4]\n",
      " [  3  81   6]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.55      0.11      0.19        98\n",
      "      medium       0.57      0.96      0.71       227\n",
      "        high       0.55      0.07      0.12        90\n",
      "\n",
      "    accuracy                           0.56       415\n",
      "   macro avg       0.55      0.38      0.34       415\n",
      "weighted avg       0.56      0.56      0.46       415\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.609\tKappa: 0.085\tAccuracy: 0.564\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset joy: 604\n",
      "# Datos de testing en dataset joy: 298\n",
      "Confusion Matrix for joy:\n",
      "\n",
      "[[ 10  61   1]\n",
      " [  8 141  14]\n",
      " [  1  43  19]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.53      0.14      0.22        72\n",
      "      medium       0.58      0.87      0.69       163\n",
      "        high       0.56      0.30      0.39        63\n",
      "\n",
      "    accuracy                           0.57       298\n",
      "   macro avg       0.55      0.44      0.43       298\n",
      "weighted avg       0.56      0.57      0.51       298\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.686\tKappa: 0.159\tAccuracy: 0.57\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset sadness: 576\n",
      "# Datos de testing en dataset sadness: 284\n",
      "Confusion Matrix for sadness:\n",
      "\n",
      "[[ 11  56   1]\n",
      " [ 13 133   8]\n",
      " [  2  49  11]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.42      0.16      0.23        68\n",
      "      medium       0.56      0.86      0.68       154\n",
      "        high       0.55      0.18      0.27        62\n",
      "\n",
      "    accuracy                           0.55       284\n",
      "   macro avg       0.51      0.40      0.39       284\n",
      "weighted avg       0.52      0.55      0.48       284\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.61\tKappa: 0.106\tAccuracy: 0.546\n",
      "------------------------------------------------------\n",
      "\n",
      "Average scores:\n",
      "\n",
      " Average AUC: 0.621\t Average Kappa: 0.105\t Average Accuracy: 0.587\n",
      "\n",
      "\n",
      "Resultados pipeline: 2\n",
      "\n",
      "# Datos de entrenamiento en dataset anger: 630\n",
      "# Datos de testing en dataset anger: 311\n",
      "Confusion Matrix for anger:\n",
      "\n",
      "[[  3  46   0]\n",
      " [  2 201   2]\n",
      " [  0  53   4]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.60      0.06      0.11        49\n",
      "      medium       0.67      0.98      0.80       205\n",
      "        high       0.67      0.07      0.13        57\n",
      "\n",
      "    accuracy                           0.67       311\n",
      "   macro avg       0.65      0.37      0.34       311\n",
      "weighted avg       0.66      0.67      0.57       311\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.682\tKappa: 0.075\tAccuracy: 0.669\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset fear: 842\n",
      "# Datos de testing en dataset fear: 415\n",
      "Confusion Matrix for fear:\n",
      "\n",
      "[[ 24  68   0]\n",
      " [ 13 222   5]\n",
      " [  1  70  12]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.63      0.26      0.37        92\n",
      "      medium       0.62      0.93      0.74       240\n",
      "        high       0.71      0.14      0.24        83\n",
      "\n",
      "    accuracy                           0.62       415\n",
      "   macro avg       0.65      0.44      0.45       415\n",
      "weighted avg       0.64      0.62      0.56       415\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.686\tKappa: 0.195\tAccuracy: 0.622\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset joy: 604\n",
      "# Datos de testing en dataset joy: 298\n",
      "Confusion Matrix for joy:\n",
      "\n",
      "[[ 22  48   0]\n",
      " [ 20 141   4]\n",
      " [  1  47  15]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.51      0.31      0.39        70\n",
      "      medium       0.60      0.85      0.70       165\n",
      "        high       0.79      0.24      0.37        63\n",
      "\n",
      "    accuracy                           0.60       298\n",
      "   macro avg       0.63      0.47      0.49       298\n",
      "weighted avg       0.62      0.60      0.56       298\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.723\tKappa: 0.217\tAccuracy: 0.597\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset sadness: 576\n",
      "# Datos de testing en dataset sadness: 284\n",
      "Confusion Matrix for sadness:\n",
      "\n",
      "[[ 30  48   0]\n",
      " [ 17 128   8]\n",
      " [  4  35  14]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.59      0.38      0.47        78\n",
      "      medium       0.61      0.84      0.70       153\n",
      "        high       0.64      0.26      0.37        53\n",
      "\n",
      "    accuracy                           0.61       284\n",
      "   macro avg       0.61      0.50      0.51       284\n",
      "weighted avg       0.61      0.61      0.58       284\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.721\tKappa: 0.264\tAccuracy: 0.606\n",
      "------------------------------------------------------\n",
      "\n",
      "Average scores:\n",
      "\n",
      " Average AUC: 0.703\t Average Kappa: 0.188\t Average Accuracy: 0.623\n",
      "\n",
      "\n",
      "Resultados pipeline: 3\n",
      "\n",
      "# Datos de entrenamiento en dataset anger: 630\n",
      "# Datos de testing en dataset anger: 311\n",
      "Confusion Matrix for anger:\n",
      "\n",
      "[[  2  52   0]\n",
      " [  5 194   4]\n",
      " [  0  48   6]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.29      0.04      0.07        54\n",
      "      medium       0.66      0.96      0.78       203\n",
      "        high       0.60      0.11      0.19        54\n",
      "\n",
      "    accuracy                           0.65       311\n",
      "   macro avg       0.52      0.37      0.34       311\n",
      "weighted avg       0.58      0.65      0.55       311\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.577\tKappa: 0.062\tAccuracy: 0.65\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset fear: 842\n",
      "# Datos de testing en dataset fear: 415\n",
      "Confusion Matrix for fear:\n",
      "\n",
      "[[ 22  59   1]\n",
      " [ 10 220   7]\n",
      " [  2  83  11]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.65      0.27      0.38        82\n",
      "      medium       0.61      0.93      0.73       237\n",
      "        high       0.58      0.11      0.19        96\n",
      "\n",
      "    accuracy                           0.61       415\n",
      "   macro avg       0.61      0.44      0.44       415\n",
      "weighted avg       0.61      0.61      0.54       415\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.647\tKappa: 0.178\tAccuracy: 0.61\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset joy: 604\n",
      "# Datos de testing en dataset joy: 298\n",
      "Confusion Matrix for joy:\n",
      "\n",
      "[[ 19  55   0]\n",
      " [  7 147   9]\n",
      " [  1  39  21]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.70      0.26      0.38        74\n",
      "      medium       0.61      0.90      0.73       163\n",
      "        high       0.70      0.34      0.46        61\n",
      "\n",
      "    accuracy                           0.63       298\n",
      "   macro avg       0.67      0.50      0.52       298\n",
      "weighted avg       0.65      0.63      0.59       298\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.712\tKappa: 0.276\tAccuracy: 0.628\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset sadness: 576\n",
      "# Datos de testing en dataset sadness: 284\n",
      "Confusion Matrix for sadness:\n",
      "\n",
      "[[ 17  47   3]\n",
      " [ 11 137   8]\n",
      " [  5  41  15]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.52      0.25      0.34        67\n",
      "      medium       0.61      0.88      0.72       156\n",
      "        high       0.58      0.25      0.34        61\n",
      "\n",
      "    accuracy                           0.60       284\n",
      "   macro avg       0.57      0.46      0.47       284\n",
      "weighted avg       0.58      0.60      0.55       284\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.695\tKappa: 0.218\tAccuracy: 0.595\n",
      "------------------------------------------------------\n",
      "\n",
      "Average scores:\n",
      "\n",
      " Average AUC: 0.658\t Average Kappa: 0.183\t Average Accuracy: 0.621\n",
      "\n",
      "\n",
      "Resultados pipeline: 4\n",
      "\n",
      "# Datos de entrenamiento en dataset anger: 630\n",
      "# Datos de testing en dataset anger: 311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for anger:\n",
      "\n",
      "[[  6  56   2]\n",
      " [  2 189   6]\n",
      " [  0  45   5]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.75      0.09      0.17        64\n",
      "      medium       0.65      0.96      0.78       197\n",
      "        high       0.38      0.10      0.16        50\n",
      "\n",
      "    accuracy                           0.64       311\n",
      "   macro avg       0.60      0.38      0.37       311\n",
      "weighted avg       0.63      0.64      0.55       311\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.661\tKappa: 0.102\tAccuracy: 0.643\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset fear: 842\n",
      "# Datos de testing en dataset fear: 415\n",
      "Confusion Matrix for fear:\n",
      "\n",
      "[[ 29  59   0]\n",
      " [ 20 210   2]\n",
      " [  3  79  13]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.56      0.33      0.41        88\n",
      "      medium       0.60      0.91      0.72       232\n",
      "        high       0.87      0.14      0.24        95\n",
      "\n",
      "    accuracy                           0.61       415\n",
      "   macro avg       0.68      0.46      0.46       415\n",
      "weighted avg       0.65      0.61      0.55       415\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.673\tKappa: 0.209\tAccuracy: 0.607\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset joy: 604\n",
      "# Datos de testing en dataset joy: 298\n",
      "Confusion Matrix for joy:\n",
      "\n",
      "[[ 25  43   0]\n",
      " [ 13 132  17]\n",
      " [  1  42  25]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.64      0.37      0.47        68\n",
      "      medium       0.61      0.81      0.70       162\n",
      "        high       0.60      0.37      0.45        68\n",
      "\n",
      "    accuracy                           0.61       298\n",
      "   macro avg       0.61      0.52      0.54       298\n",
      "weighted avg       0.61      0.61      0.59       298\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.721\tKappa: 0.282\tAccuracy: 0.611\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset sadness: 576\n",
      "# Datos de testing en dataset sadness: 284\n",
      "Confusion Matrix for sadness:\n",
      "\n",
      "[[ 27  39   1]\n",
      " [ 15 117  15]\n",
      " [  7  45  18]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.55      0.40      0.47        67\n",
      "      medium       0.58      0.80      0.67       147\n",
      "        high       0.53      0.26      0.35        70\n",
      "\n",
      "    accuracy                           0.57       284\n",
      "   macro avg       0.55      0.49      0.49       284\n",
      "weighted avg       0.56      0.57      0.54       284\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.721\tKappa: 0.238\tAccuracy: 0.57\n",
      "------------------------------------------------------\n",
      "\n",
      "Average scores:\n",
      "\n",
      " Average AUC: 0.694\t Average Kappa: 0.208\t Average Accuracy: 0.608\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_pipelines = [\n",
    "    get_experiment_1_pipeline,\n",
    "    get_experiment_2_pipeline,\n",
    "    get_experiment_3_pipeline,\n",
    "    get_experiment_4_pipeline\n",
    "]\n",
    "\n",
    "classifiers = []\n",
    "learned_labels_array = []\n",
    "for i, f_pipeline in enumerate(f_pipelines):\n",
    "    print(f\"Resultados pipeline: {i+1}\\n\")\n",
    "    scores_array = []\n",
    "    # Por cada nombre_dataset, dataset en train ('anger', 'fear', 'joy', 'sadness')\n",
    "    for dataset_name, dataset in train.items():\n",
    "        # creamos el pipeline\n",
    "        pipeline = f_pipeline()\n",
    "        \n",
    "        # ejecutamos el pipeline sobre el dataset\n",
    "        classifier, learned_labels, scores = run(dataset, dataset_name, pipeline)\n",
    "        # guardamos el clasificador entrenado (en realidad es el pipeline ya entrenado...)\n",
    "        classifiers.append(classifier)\n",
    "        \n",
    "        # guardamos las labels aprendidas por el clasificador\n",
    "        learned_labels_array.append(learned_labels)\n",
    "        \n",
    "        # guardamos los scores obtenidos\n",
    "        scores_array.append(scores)\n",
    "    # print avg scores\n",
    "    print(\n",
    "        \"Average scores:\\n\\n\",\n",
    "        \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\\n\\n\"\n",
    "        .format(*np.array(scores_array).mean(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que los resultados de los experimentos anteriorermente mostados solo son *corren* una vez cada pipeline en cada dataset. Gustaría tener una mejor idea del poder de generalización de los pipelines y, para realizar lo necesitado, se creó la siguiente función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_n_iter(n: int):\n",
    "    \n",
    "    f_pipelines = [\n",
    "        get_experiment_1_pipeline,\n",
    "        get_experiment_2_pipeline,\n",
    "        get_experiment_3_pipeline,\n",
    "        get_experiment_4_pipeline\n",
    "    ]\n",
    "    for i, f_pipeline in enumerate(f_pipelines):\n",
    "        print(f\"Pipeline {i+1}\\n\")\n",
    "        auc_pipe = 0\n",
    "        kappa_pipe = 0\n",
    "        accuracy_pipe = 0\n",
    "        \n",
    "        for dataset_name, dataset in train.items():\n",
    "            \n",
    "            auc = 0\n",
    "            kappa = 0\n",
    "            accuracy = 0\n",
    "            for j in range(n):\n",
    "                # Dividimos el dataset en train y test, aún no se transforma de Strings a valores numéricos.\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    dataset.tweet,\n",
    "                    dataset.sentiment_intensity,\n",
    "                    shuffle=True,\n",
    "                    test_size=0.33)\n",
    "                pipeline = f_pipeline()\n",
    "                \n",
    "                # Entrenamos el clasificador (Ejecuta el entrenamiento sobre todo el pipeline). \n",
    "                pipeline.fit(X_train, y_train)\n",
    "                \n",
    "                # Predecimos las probabilidades de intensidad de cada elemento del set de prueba.\n",
    "                predicted_probabilities = pipeline.predict_proba(X_test)\n",
    "                \n",
    "                # Obtenemos el orden de las clases aprendidas.\n",
    "                learned_labels = pipeline.classes_\n",
    "                \n",
    "                predicted_labels = [\n",
    "                    learned_labels[np.argmax(item)] for item in predicted_probabilities\n",
    "                ]\n",
    "                \n",
    "                # Reorder predicted probabilities array.\n",
    "                learned_labels = learned_labels.tolist()\n",
    "                \n",
    "                predicted_probabilities = predicted_probabilities[:, [\n",
    "                    learned_labels.index('low'),\n",
    "                    learned_labels.index('medium'),\n",
    "                    learned_labels.index('high')\n",
    "                ]]\n",
    "           \n",
    "                auc += auc_score(y_test, predicted_probabilities)\n",
    "                kappa += cohen_kappa_score(y_test, predicted_labels)\n",
    "                accuracy += accuracy_score(y_test, predicted_labels)\n",
    "                \n",
    "            auc_pipe += auc\n",
    "            kappa_pipe += kappa\n",
    "            accuracy_pipe += accuracy\n",
    "            \n",
    "            auc = round(auc/n, 3)\n",
    "            kappa = round(kappa/n, 3)\n",
    "            accuracy = round(accuracy/n, 3)\n",
    "            \n",
    "            print(f\"Promedio de AUC para el dataset {dataset_name}: {auc}\")\n",
    "            print(f\"Promedio de Kappa para el dataset {dataset_name}: {kappa}\")\n",
    "            print(f\"Promedio de Accuracy para el dataset {dataset_name}: {accuracy}\\n\")\n",
    "            \n",
    "        print(f\"Promedio de AUC para el pipeline {i+1}: {round(auc_pipe/(n*4),3)}\")\n",
    "        print(f\"Promedio de Kappa para el pipeline {i+1}: {round(kappa_pipe/(n*4), 3)}\")\n",
    "        print(f\"Promedio de Accuracy para el pipeline {i+1}: {round(accuracy_pipe/(n*4), 3)}\")\n",
    "        print(\"-\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función dada se puede *correr* los pipeline *n* veces para cada dataset y calcular el promedio de los scores dados. En particular, se *correrá* los pipeline 4 veces en cada dataset. Los resultados son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 1\n",
      "\n",
      "Promedio de AUC para el dataset anger: 0.59\n",
      "Promedio de Kappa para el dataset anger: 0.097\n",
      "Promedio de Accuracy para el dataset anger: 0.667\n",
      "\n",
      "Promedio de AUC para el dataset fear: 0.615\n",
      "Promedio de Kappa para el dataset fear: 0.1\n",
      "Promedio de Accuracy para el dataset fear: 0.567\n",
      "\n",
      "Promedio de AUC para el dataset joy: 0.699\n",
      "Promedio de Kappa para el dataset joy: 0.238\n",
      "Promedio de Accuracy para el dataset joy: 0.605\n",
      "\n",
      "Promedio de AUC para el dataset sadness: 0.623\n",
      "Promedio de Kappa para el dataset sadness: 0.109\n",
      "Promedio de Accuracy para el dataset sadness: 0.538\n",
      "\n",
      "Promedio de AUC para el pipeline 1: 0.632\n",
      "Promedio de Kappa para el pipeline 1: 0.136\n",
      "Promedio de Accuracy para el pipeline 1: 0.594\n",
      "--------------------\n",
      "\n",
      "Pipeline 2\n",
      "\n",
      "Promedio de AUC para el dataset anger: 0.646\n",
      "Promedio de Kappa para el dataset anger: 0.048\n",
      "Promedio de Accuracy para el dataset anger: 0.654\n",
      "\n",
      "Promedio de AUC para el dataset fear: 0.695\n",
      "Promedio de Kappa para el dataset fear: 0.191\n",
      "Promedio de Accuracy para el dataset fear: 0.602\n",
      "\n",
      "Promedio de AUC para el dataset joy: 0.718\n",
      "Promedio de Kappa para el dataset joy: 0.222\n",
      "Promedio de Accuracy para el dataset joy: 0.586\n",
      "\n",
      "Promedio de AUC para el dataset sadness: 0.717\n",
      "Promedio de Kappa para el dataset sadness: 0.261\n",
      "Promedio de Accuracy para el dataset sadness: 0.607\n",
      "\n",
      "Promedio de AUC para el pipeline 2: 0.694\n",
      "Promedio de Kappa para el pipeline 2: 0.181\n",
      "Promedio de Accuracy para el pipeline 2: 0.612\n",
      "--------------------\n",
      "\n",
      "Pipeline 3\n",
      "\n",
      "Promedio de AUC para el dataset anger: 0.617\n",
      "Promedio de Kappa para el dataset anger: 0.11\n",
      "Promedio de Accuracy para el dataset anger: 0.66\n",
      "\n",
      "Promedio de AUC para el dataset fear: 0.67\n",
      "Promedio de Kappa para el dataset fear: 0.165\n",
      "Promedio de Accuracy para el dataset fear: 0.601\n",
      "\n",
      "Promedio de AUC para el dataset joy: 0.743\n",
      "Promedio de Kappa para el dataset joy: 0.274\n",
      "Promedio de Accuracy para el dataset joy: 0.61\n",
      "\n",
      "Promedio de AUC para el dataset sadness: 0.674\n",
      "Promedio de Kappa para el dataset sadness: 0.15\n",
      "Promedio de Accuracy para el dataset sadness: 0.558\n",
      "\n",
      "Promedio de AUC para el pipeline 3: 0.676\n",
      "Promedio de Kappa para el pipeline 3: 0.175\n",
      "Promedio de Accuracy para el pipeline 3: 0.607\n",
      "--------------------\n",
      "\n",
      "Pipeline 4\n",
      "\n",
      "Promedio de AUC para el dataset anger: 0.632\n",
      "Promedio de Kappa para el dataset anger: 0.062\n",
      "Promedio de Accuracy para el dataset anger: 0.65\n",
      "\n",
      "Promedio de AUC para el dataset fear: 0.703\n",
      "Promedio de Kappa para el dataset fear: 0.201\n",
      "Promedio de Accuracy para el dataset fear: 0.595\n",
      "\n",
      "Promedio de AUC para el dataset joy: 0.753\n",
      "Promedio de Kappa para el dataset joy: 0.34\n",
      "Promedio de Accuracy para el dataset joy: 0.639\n",
      "\n",
      "Promedio de AUC para el dataset sadness: 0.698\n",
      "Promedio de Kappa para el dataset sadness: 0.23\n",
      "Promedio de Accuracy para el dataset sadness: 0.57\n",
      "\n",
      "Promedio de AUC para el pipeline 4: 0.696\n",
      "Promedio de Kappa para el pipeline 4: 0.208\n",
      "Promedio de Accuracy para el pipeline 4: 0.614\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_n_iter(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir los target set y crear la submission\n",
    "\n",
    "Aquí predecimos los target set usando los clasificadores creados y creamos los archivos de las submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Datos de entrenamiento en dataset anger: 630\n",
      "# Datos de testing en dataset anger: 311\n",
      "Confusion Matrix for anger:\n",
      "\n",
      "[[  3  48   0]\n",
      " [  1 197   4]\n",
      " [  0  54   4]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.75      0.06      0.11        51\n",
      "      medium       0.66      0.98      0.79       202\n",
      "        high       0.50      0.07      0.12        58\n",
      "\n",
      "    accuracy                           0.66       311\n",
      "   macro avg       0.64      0.37      0.34       311\n",
      "weighted avg       0.64      0.66      0.55       311\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.665\tKappa: 0.067\tAccuracy: 0.656\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset fear: 842\n",
      "# Datos de testing en dataset fear: 415\n",
      "Confusion Matrix for fear:\n",
      "\n",
      "[[ 36  62   1]\n",
      " [ 20 212   7]\n",
      " [  2  62  13]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.62      0.36      0.46        99\n",
      "      medium       0.63      0.89      0.74       239\n",
      "        high       0.62      0.17      0.27        77\n",
      "\n",
      "    accuracy                           0.63       415\n",
      "   macro avg       0.62      0.47      0.49       415\n",
      "weighted avg       0.63      0.63      0.58       415\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.688\tKappa: 0.244\tAccuracy: 0.629\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset joy: 604\n",
      "# Datos de testing en dataset joy: 298\n",
      "Confusion Matrix for joy:\n",
      "\n",
      "[[ 23  50   0]\n",
      " [ 23 127   6]\n",
      " [  0  44  25]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.50      0.32      0.39        73\n",
      "      medium       0.57      0.81      0.67       156\n",
      "        high       0.81      0.36      0.50        69\n",
      "\n",
      "    accuracy                           0.59       298\n",
      "   macro avg       0.63      0.50      0.52       298\n",
      "weighted avg       0.61      0.59      0.56       298\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.717\tKappa: 0.249\tAccuracy: 0.587\n",
      "------------------------------------------------------\n",
      "\n",
      "# Datos de entrenamiento en dataset sadness: 576\n",
      "# Datos de testing en dataset sadness: 284\n",
      "Confusion Matrix for sadness:\n",
      "\n",
      "[[ 24  45   2]\n",
      " [ 17 131   6]\n",
      " [  5  36  18]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.52      0.34      0.41        71\n",
      "      medium       0.62      0.85      0.72       154\n",
      "        high       0.69      0.31      0.42        59\n",
      "\n",
      "    accuracy                           0.61       284\n",
      "   macro avg       0.61      0.50      0.52       284\n",
      "weighted avg       0.61      0.61      0.58       284\n",
      "\n",
      "Scores:\n",
      "\n",
      "AUC:  0.709\tKappa: 0.27\tAccuracy: 0.609\n",
      "------------------------------------------------------\n",
      "\n",
      "Average scores:\n",
      "\n",
      " Average AUC: 0.695\t Average Kappa: 0.208\t Average Accuracy: 0.62\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "learned_labels_array = []\n",
    "scores_array = []\n",
    "# Por cada nombre_dataset, dataset en train ('anger', 'fear', 'joy', 'sadness')\n",
    "for dataset_name, dataset in train.items():\n",
    "    \n",
    "    pipeline = get_experiment_4_pipeline()\n",
    "    \n",
    "    # ejecutamos el pipeline sobre el dataset\n",
    "    classifier, learned_labels, scores = run(dataset, dataset_name, pipeline)\n",
    "    # guardamos el clasificador entrenado (en realidad es el pipeline ya entrenado...)\n",
    "    classifiers.append(classifier)\n",
    "    \n",
    "    # guardamos las labels aprendidas por el clasificador\n",
    "    learned_labels_array.append(learned_labels)\n",
    "        \n",
    "    # guardamos los scores obtenidos\n",
    "    scores_array.append(scores)\n",
    "# print avg scores\n",
    "print(\n",
    "    \"Average scores:\\n\\n\",\n",
    "    \"Average AUC: {0:.3g}\\t Average Kappa: {1:.3g}\\t Average Accuracy: {2:.3g}\\n\\n\"\n",
    "    .format(*np.array(scores_array).mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.392097Z",
     "start_time": "2020-04-07T15:44:21.386114Z"
    },
    "id": "mWDUoSmbzvI1"
   },
   "outputs": [],
   "source": [
    "def predict_target(dataset, classifier, labels):\n",
    "    # Predecir las probabilidades de intensidad de cada elemento del target set.\n",
    "    predicted = pd.DataFrame(classifier.predict_proba(dataset.tweet), columns=labels)\n",
    "    \n",
    "    # Agregar ids\n",
    "    predicted['id'] = dataset.id.values\n",
    "    # Reordenar las columnas\n",
    "    predicted = predicted[['id', 'low', 'medium', 'high']]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T15:44:21.588573Z",
     "start_time": "2020-04-07T15:44:21.394094Z"
    },
    "id": "5CJ4PTwZzvI1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_target = {}\n",
    "\n",
    "# Crear carpeta ./predictions\n",
    "if (not os.path.exists('./predictions')):\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "else:\n",
    "    # Eliminar predicciones anteriores:\n",
    "    shutil.rmtree('./predictions')\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "# por cada target set:\n",
    "for idx, key in enumerate(target):\n",
    "    # Predecirlo\n",
    "    predicted_target[key] = predict_target(target[key], classifiers[idx],\n",
    "                                           learned_labels_array[idx])\n",
    "    # Guardar predicciones en archivos separados. \n",
    "    predicted_target[key].to_csv('./predictions/{}-pred.txt'.format(key),\n",
    "                                 sep='\\t',\n",
    "                                 header=False,\n",
    "                                 index=False)\n",
    "\n",
    "# Crear archivo zip\n",
    "a = shutil.make_archive('predictions', 'zip', './predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCAyJIj8nTlU"
   },
   "source": [
    "## **7. Resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAYwupS3naYX"
   },
   "source": [
    "A continuación se muestran los resultados de los experimentos (más los resultados dados del experimento del baseline). \n",
    "\n",
    "| No. | Approach                       || Dataset   | AUC   | Kappa | Accuracy |\n",
    "|-----|--------------------------------||-----------|-------|-------|----------|\n",
    "|     | Features        | Clasifier     |           |       |       |          |\n",
    "| 0   | bow+chars_count | MultinomialNB | anger     | 0.622 | 0.163 | 0.688    |\n",
    "|     |                 |               | fear      | 0.597 | 0.091 | 0.559    |\n",
    "|     |                 |               | joy       | 0.728 | 0.251 | 0.601    |\n",
    "|     |                 |               | sadness   | 0.645 | 0.166 | 0.581    |\n",
    "|     |                 |               |**average**| 0.648 | 0.168 | 0.607    |\n",
    "|     |                 |               |           |       |       |          |\n",
    "|     | Features        | Clasifier     |           |       |       |          |\n",
    "|1    | Tf-idf + non verbal features    |       RandomForest |  anger|  0.59 |   0.097   |  0.667        |\n",
    "|     |                 |               | fear        |    0.615   |   0.1    |     0.567     |\n",
    "|     |                 |               | joy         |     0.699  |     0.238  |    0.605      |\n",
    "|     |                 |               |sadness      |     0.623  |    0.109   |     0.594     |\n",
    "|     |                 |               | **average** |   0.632    |     0.136  |     0.594     |\n",
    "|     |                 |               |           |       |       |          |\n",
    "|     | Features        | Clasifier     |     |       |       |          |\n",
    "|2    | Tf-idf 2-gram + verbal features   |   LogisticRegressor | anger     | 0.646      |0.048    | 0.654         |\n",
    "|     |                 |               | fear          |  0.695     |   0.191     |    0.602      |\n",
    "|     |                 |               | joy  |      0.718  |      0.222 |    0.586 |\n",
    "|     |                 |               |sadness |    0.717  |   0.261    |  0.607        |\n",
    "|     |                 |               |   **average** |   0.694     |      0.181 |  0.612        |\n",
    "|     |                 |               |           |       |       |          |\n",
    "|     | Features        | Clasifier     |      |       |       |          |\n",
    "|3    | Tf-idf + all features   |       RandomForest  | anger     |     0.617  |  0.11     |    0.66     |\n",
    "|     |                 |               | fear        |    0.67   |  0.165     |      0.601    |\n",
    "|     |                 |               | joy         |   0.743    |   0.274    |     0.601     |\n",
    "|     |                 |               |sadness      |    0.674   |    0.15   |   0.558       |\n",
    "|     |                 |               | **average** |   0.676    |   0.175    |     0.607     |\n",
    "|     |                 |               |           |       |       |          |\n",
    "|     | Features        | Clasifier     |     |       |       |          |\n",
    "|4    | Tf-idf 2-gram  + all  features   |       LogisticRegressor | anger    |  0.632   |   0.062    |   0.65  |\n",
    "|     |                 |               | fear       |    0.703   |   0.201    |    0.595      |\n",
    "|     |                 |               | joy        |    0.753   |   0.34    |      0.639    |\n",
    "|     |                 |               |sadness     |       0.698 |   0.208    |      0.57   |\n",
    "|     |                 |               |**average** |   0.696    |    0.208   |      0.614    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sqlew0iizvI1"
   },
   "source": [
    "## **8. Conclusiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFTikGbszZuc"
   },
   "source": [
    " Respecto a los resultados obtenidos, se observa que el cuarto pipeline presenta los mejores resultados. Asimismo, las representaciones que presentaron 2-gramas obtienen mejores resultados que representaciones que no utilizan n-gramas. \n",
    " \n",
    " La utilización de custom features pareciese no ser tan relevante, es decir, los mejores resultados se obtienen utilizando Tf-idf con 2-gramas (independiente de las custom features). Lo anterior puede ocurrir ya que las custom features no entregan información relevante o porque, en comparación a dichos atributos, el vector Tf-idf con 2-gramas condensa la mayor relevancia a la hora de representar a los tweet.\n",
    " \n",
    " El punto anteriormente mencionado es un aspecto importante a destacar porque muestra la dificultad de definir buenos atributos, es decir, para el caso de estudio en la competencia, responder la pregunta *¿qué es lo más relevante para definir la intensidad de sentimiento en un tweet?* es complicado. En ese sentido, para futuras competencias se vislumbro como altamente deseable utilizar redes neuronales que entreguen representaciones que *no necesiten ser determinadas*, es decir, la utilización de modelos preentrenados que permitan generar la mejor representación para los datos es lo más óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mxlNrNf_p0ZY",
    "N6lhhfl2zvIk",
    "a6moqxkEwCe-",
    "LMSn_tDYwOb1",
    "E29LEMZ9zvIo",
    "OTAIEnSJzvIp",
    "kMOjYSQezvIq",
    "ECjkdgdwzvIq",
    "RkOP6ugwzvIt",
    "q5aNqEfVzvIv",
    "stZ6ig5hzvIv",
    "gmMdm98vzvIy"
   ],
   "name": "Assignment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
