{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0tyIsliieNr"
   },
   "source": [
    "# **Competencia 2 - CC6205 Natural Language Processing üìö**\n",
    "\n",
    "Integrantes: Mat√≠as Seda\n",
    "\n",
    "Usuario del equipo en CodaLab (Obligatorio): x_y_z\n",
    "\n",
    "Fecha l√≠mite de entrega üìÜ: 24 de Junio.\n",
    "\n",
    "Tiempo estimado de dedicaci√≥n: 12 horas\n",
    "\n",
    "Link competencia: Poner el link [aqu√≠](https://codalab.lisn.upsaclay.fr/competitions/5098?secret_key=09955d45-6210-4a35-a171-8050aa050855#learn_the_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MocJN22HSJ1x"
   },
   "source": [
    "### **Objetivo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwdgXS8FSLvc"
   },
   "source": [
    "El objetivo de esta competencia es resolver una de las tareas m√°s importantes en el √°rea del procesamiento de lenguage natural, relacionada con la extracci√≥n de informaci√≥n: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf). \n",
    "\n",
    "En particular, y al igual que en la competencia anterior, deber√°n crear distintos modelos que apunten a resolver la tarea de NER en Espa√±ol. Para esto, les entregaremos un dataset real perteneciente a la lista de espera NO GES en Chile. Es importante destacar que existe una falta de trabajos realizados en el √°rea de NER en Espa√±ol y a√∫n m√°s en el contexto cl√≠nico, por ende puede ser considerado como una tarea bien desafiante y quiz√°s les interesa trabajar en el √°rea m√°s adelante en sus carreras.\n",
    "\n",
    "En este notebook les entregaremos un baseline como referencia de los resultados que esperamos puedan obtener. Recuerden que el no superar a los baselines en alguna de las tres m√©tricas conlleva un descuento de 0.5 puntos hasta 1.5 puntos.\n",
    "\n",
    "Como hemos estado viendo redes neuronales tanto en catedras, tareas y auxiliares (o pr√≥ximamente lo har√°n), esperamos que (por lo menos) utilicen Redes Neuronales Recurrentes (RNN) para resolverla. \n",
    "\n",
    "Nuevamente, hay total libertad para utilizar el software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados. (De todas maneras como es un corpus nuevo, es dif√≠cil que haya alg√∫n modelo ya implementado con estas entidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnjgmvjBSReb"
   },
   "source": [
    "### **Explicaci√≥n de la competencia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH4HqnCjSWs-"
   },
   "source": [
    "La tarea **NER** que van a resolver en esta competencia es com√∫nmente abordada como un problema de Sequence Labeling.\n",
    "\n",
    "**¬øQu√© es Sequence Labeling?** \n",
    "\n",
    "En breves palabras, dada una secuencia de tokens (oraci√≥n) sequence labeling tiene por objetivo asignar una etiqueta a cada token de dicha secuencia. En pocas palabras, dada una lista de tokens esperamos encontrar la mejor secuencia de etiquetas asociadas a esa lista. Ahora veamos de qu√© se trata este problema.\n",
    "\n",
    "**Named Entity Recognition (NER)**\n",
    "\n",
    "NER es un ejemplo de un problema de Sequence Labeling. Pero antes de definir formalmente esta tarea, es necesario definir algunos conceptos claves para poder entenderla de la mejor manera:\n",
    "\n",
    "- *Token*: Un token es una secuencia de caracteres, puede ser una palabra, un n√∫mero o un s√≠mbolo.\n",
    "\n",
    "- *Entidad*: No es m√°s que un trozo de texto (uno o m√°s tokens) asociado a una categor√≠a predefinida. Originalmente se sol√≠an utilizar categor√≠as como nombres de personas, organizaciones, ubicaciones, pero actualmente se ha extendido a diferentes dominios.\n",
    "\n",
    "- *L√≠mites de una entidad*: Son los √≠ndices de los tokens de inicio y f√≠n dentro de una entidad.\n",
    "\n",
    "- *Tipo de entidad*: Es la categor√≠a predefinida asociada a la entidad.\n",
    "\n",
    "Dicho esto, definimos formalmente una entidad como una tupla: $(s, e, t)$, donde $s, t$ son los l√≠mites de la entidad (√≠ndices de los tokens de inicio y fin, respectivamente) y t corresponde al tipo de entidad o categor√≠a. Ya veremos m√°s ejemplos luego de describir el Dataset.\n",
    "\n",
    "**Corpus de la Lista de espera**\n",
    "\n",
    "Trabajaran con un conjunto de datos reales correspondiente a interconsultas de la lista de espera NO GES en Chile. Si quieren saber m√°s sobre c√≥mo fueron generados los datos pueden revisar el paper publicado hace unos meses atr√°s en el workshop de EMNLP, una de las conferencias m√°s importantes de NLP: [https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/](https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/).\n",
    "\n",
    "Este corpus Chileno est√° constituido originalmente por 7 tipos de entidades pero por simplicidad en esta competencia trabajar√°n con las siguientes:\n",
    "\n",
    "- **Disease**\n",
    "- **Body_Part**\n",
    "- **Medication** \n",
    "- **Procedures** \n",
    "- **Family_Member**\n",
    "\n",
    "Si quieren obtener m√°s informaci√≥n sobre estas entidades pueden consultar la [gu√≠a de anotaci√≥n](https://plncmm.github.io/annodoc/). Adem√°s, mencionar que este corpus est√° restringido bajo una licencia que permite solamente su uso acad√©mico, as√≠ que no puede ser compartido m√°s all√° de este curso o sin permisos por parte de los autores en caso que quieran utilizarlo fuera. Si este √∫ltimo es el caso entonces pueden escribir directamente al correo: pln@cmm.uchile.cl. Al aceptar los t√©rminos y condiciones de la competencia est√°n de acuerdo con los puntos descritos anteriormente.\n",
    "\n",
    "\n",
    "**Formato ConLL**\n",
    "\n",
    "Los archivos que ser√°n entregados a ustedes vienen en un formato est√°ndar utilizado en NER, llamado ConLL. No es m√°s que un archivo de texto, que cumple las siguientes propiedades.\n",
    "\n",
    "- Un salto de linea corresponde a la separaci√≥n entre oraciones. Esto es importante ya que al entrenar una red neuronal ustedes pasaran una lista de oraciones como input, m√°s conocidos como batches.\n",
    "\n",
    "- La primera columna del archivo contiene todos los tokens de la partici√≥n.\n",
    "\n",
    "- La segunda columna del archivo contiene el tipo de entidad asociado al token de la primera columna.\n",
    "\n",
    "- Los tipos de entidades siguen un formato cl√°sico en NER denominado *IOB2*. Si un tipo de entidad comienza con el prefijo \"B-\" (Beginning) significa que es el token de inicio de una entidad, si comienza con \"I-\" (Inside) es un token distinto al de inicio y si un token est√° asociado a la categor√≠a O (Outside) significa que no pertenece a ninguna entidad.\n",
    "\n",
    "Aqu√≠ va un ejemplo:\n",
    "\n",
    "```\n",
    "PACIENTE O\n",
    "PRESENTA O\n",
    "FRACTURA B-Disease\n",
    "CORONARIA I-Disease\n",
    "COMPLICADA I-Disease\n",
    "EN O\n",
    "PIE B-Body_Part\n",
    "IZQUIERDO I-Body_Part\n",
    ". O\n",
    "SE O\n",
    "REALIZA O\n",
    "INSTRUMENTACION B-Procedure\n",
    "INTRACONDUCTO I-Procedure\n",
    ". O\n",
    "```\n",
    "\n",
    "Seg√∫n nuestra definici√≥n tenemos las siguientes tres entidades (enumerando desde 0): \n",
    "\n",
    "- $(2, 4, Disease)$\n",
    "- $(6, 7, Body Part)$\n",
    "- $(11, 12, Procedure)$\n",
    "\n",
    "Repasen un par de veces todos estos conceptos antes de pasar a la siguiente secci√≥n del notebook.\n",
    "Es importante entender bien este formato ya que al medir el rendimiento de sus modelos, consideraremos una **m√©trica estricta**. Esta m√©trica se llama as√≠ ya que considera correcta una predicci√≥n de su modelo, s√≥lo si al compararlo con las entidades reales **coinciden tanto los l√≠mites de la entidad como el tipo.** \n",
    "\n",
    "Para ejemplificar, tomando el caso anterior, si el modelo es capaz de encontrar la siguiente entidad: $(2, 3, Disease)$, entonces se considera incorrecto ya que pudo predecir dos de los tres tokens de dicha enfermedad. Es decir, buscamos una m√©trica que sea alta a nivel de entidad y no a nivel de token.\n",
    "\n",
    "Antes de pasar a explicar las reglas, se recomienda visitar los siguientes links para entender bien el baseline de la competencia:\n",
    "\n",
    "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
    "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
    "\n",
    "\n",
    "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWlfabmkaSE7"
   },
   "source": [
    "### **Reglas de la competencia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w9Dw4CSaSE8"
   },
   "source": [
    "**texto en negrita**- Para que su competencia sea evaluada, deben participar en la competencia y enviar este notebook con su informe.\n",
    "- Para participar, deben registrarse en la competencia en Codalab en grupos de m√°ximo 4 alumnos. Cada grupo debe tener un nombre de equipo. (¬°Y deben reportarlo en su informe, por favor!)\n",
    "- Las m√©tricas usadas ser√°n m√©tricas estrictas (ya explicado anteriormente) utilizando m√©tricas cl√°sicas como lo son precisi√≥n, recall y micro f1-score.\n",
    "- En esta tarea se recomienda usar GPU. Pueden ejecutar su tarea en colab (lo cual trae todo instalado) o pueden intentar ejecut√°ndolo en su computador. En este caso, deber√° ser compatible con cuda y deber√°n instalar todo por su cuenta.\n",
    "- En total pueden hacer un **m√°ximo de 5 env√≠os**.\n",
    "- Por favor, todas sus dudas haganlas por el canal de Discord. Los emails que lleguen al equipo docente ser√°n remitidos a ese medio. Recuerden el √°nimo colaborativo del curso.\n",
    "- Estar top 5 en alguna de las tres m√©tricas equivale a una bonificaci√≥n en su nota final.\n",
    "\n",
    "√âxito!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZyHBjU-R-wi"
   },
   "source": [
    "### **Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WZ8G01aSBYX"
   },
   "source": [
    "En este punto esperamos que tengan conocimiento sobre redes neuronales y en particular redes neuronales recurrentes (RNN), si no siempre pueden escribirnos por el canal de Discord para aclarar dudas. La RNN del baseline adjunto a este notebook est√° programado en la librer√≠a [`pytorch`](https://pytorch.org/) pero ustedes pueden utilizar keras, tensorflow si as√≠ lo desean. El c√≥digo contiene lo siguiente:\n",
    "\n",
    "- La carga de los datasets, creaci√≥n de batches de texto y padding (esto es importante ya que si utilizan redes neuronales tienen que tener el mismo largo los inputs). \n",
    "\n",
    "- La implementaci√≥n b√°sica de una red `LSTM` simple de solo un nivel y sin bi-direccionalidad. \n",
    "\n",
    "- La construcci√≥n del formato del output requerido para que lo puedan probar en la tarea en codalab.\n",
    "\n",
    "Se espera que como m√≠nimo ustedes puedan experimentar con el baseline utilizando (pero no limit√°ndose) estas sugerencias:\n",
    "\n",
    "*   Probar la t√©cnica de early stopping.\n",
    "*   Variar la cantidad de par√°metros de la capa de embeddings.\n",
    "*   Variar la cantidad de capas RNN.\n",
    "*   Variar la cantidad de par√°metros de las capas de RNN.\n",
    "*   Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...). [Embeddings en espa√±ol aqu√≠](https://github.com/dccuchile/spanish-word-embeddings). Tambi√©n aqu√≠ pueden encontrar unos embeddings cl√≠nicos en Espa√±ol: [https://zenodo.org/record/3924799](https://zenodo.org/record/3924799)\n",
    "*   Variar la cantidad de √©pocas de entrenamiento.\n",
    "*   Variar el optimizador, learning rate, batch size, usar CRF loss, etc.\n",
    "*   Probar una capa de CRF para garantizar el     formato IOB2.\n",
    "*   Probar bi-direccionalidad.\n",
    "*   Incluir dropout.\n",
    "*   Probar modelos de tipo GRU.\n",
    "*   Probar usando capas de atenci√≥n.\n",
    "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
    "*   Probar modelos de transformers en espa√±ol usando [Huggingface](https://github.com/huggingface/transformers) o el framework Flair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rr2mzxPTzNd"
   },
   "source": [
    "### **Reporte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEf33mnxT0rf"
   },
   "source": [
    "Este debe cumplir la siguiente estructura:\n",
    "\n",
    "1.\t**Introducci√≥n**: Presentar brevemente el contexto, problema a resolver, incluyendo la formalizaci√≥n de la task (c√≥mo son los inputs y outputs del problema) y los desaf√≠os que ven al analizar el corpus entregado. (**0.5 puntos**)\n",
    "\n",
    "2.\t**Modelos**: Describir brevemente los modelos, m√©todos e hiperpar√°metros utilizados. (**1.0 puntos**)\n",
    "\n",
    "4.\t**M√©tricas de evaluaci√≥n**: Describir las m√©tricas utilizadas en la evaluaci√≥n indicando qu√© miden y cu√°l es su interpretaci√≥n en este problema en particular. (**0.5 puntos**)\n",
    "\n",
    "5.  **Dise√±o experimental**: Esta es una de las secciones m√°s importantes del reporte. Deben describir minuciosamente los experimentos que realizar√°n en la siguiente secci√≥n. Describir las variables de control que manejar√°n, algunos ejemplos pueden ser: Los hiperpar√°metros de los modelos, tipo de embeddings utilizados, tipos de arquitecturas. Ser claros con el conjunto de hiperpar√°metros que probar√°n, la decisi√≥n en las funciones de optimizaci√≥n, funci√≥n de p√©rdida,  regulaci√≥n, etc. B√°sicamente explicar qu√© es lo que veremos en la siguiente secci√≥n.\n",
    "(**1 punto**)\n",
    "\n",
    "6.\t**Experimentos**: Reportar todos sus experimentos y c√≥digo en esta secci√≥n. Comparar los resultados obtenidos utilizando diferentes modelos. ¬°Es vital haber realizado varios experimentos para sacar una buena nota! (**2.0 puntos**)\n",
    "\n",
    "7.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (**1 punto**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaoU1EXfUDbl"
   },
   "source": [
    "# **Entregable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzQlYlmGaSFH"
   },
   "source": [
    "## **Introducci√≥n**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rekGPTcgL4qI"
   },
   "source": [
    "En el siguiente trabajo se busca resolver un problema de *etiquetados* de secuencias. M√°s es particular, se busca resolver una tarea de reconocimiento de entidades en un contexto cl√≠nico. Se utilizar√° el Corpus de lista de espera propuesto en el enunciado. El corpus mencionado est√° compuesto por derivaciones de consultas de la lista de espera NO GES de los hospitales p√∫blicos chilenos. Este corpus est√° constituido, originalmente, por 7 tipos de entidades, pero por simplicidad en esta competencia trabajar√°n con las siguientes:\n",
    "- Disease\n",
    "- Body_Part\n",
    "- Medication\n",
    "- Procedures\n",
    "- Family_Member\n",
    "\n",
    "El dataset entregado para la competencia viene en un formato denominado ConLL. Los archivos asociados a este formato consisten en archivo de texto con dos columnas y saltos de l√≠nea que separan cada oraci√≥n. La primera columna contiene los tokens de la secuencia. Por el otro lado, la segunda columna, contiene las etiquetas para cada token de la oraci√≥n. Las etiquetas para cada token siguen formato IOB2 (convenci√≥n explicada en el enunciado de la competencia).\n",
    "\n",
    "As√≠, el trabajo busca, dado los dataset de entrenamiento, validaci√≥n y testing, entrenar un modelo *RNN* para predecir las etiquetas de una secuencias siguiendo los formatos y est√°ndares mencionados anteriormente. As√≠, el modelo a entrenar entregar√° una secuencia de etiquetas para una oraci√≥n, es decir, para una oraci√≥n con una cantidad espec√≠fica de tokens, el modelo *predice* la etiqueta para cada token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbA1EmhCaSFI"
   },
   "source": [
    "## **Modelos**\n",
    "\n",
    "**Modelo baseline**: Es una *RNN* entregada en el enunciado. Posee las siguientes caracter√≠sticas:\n",
    "- Dimensi√≥n de capa embedding: *200*\n",
    "- Tipo de capas intermedias: *LSTM*\n",
    "- N√∫mero de capas LSTM: *3*\n",
    "- Dimensi√≥n de capas LSTM: *128*\n",
    "- Dimensi√≥n output: *12*\n",
    "- Tama√±o de los batches: *22*\n",
    "- Funci√≥n de p√©rdida: *Cross entropy loss*\n",
    "- Algormito pptimizador: *Adam*\n",
    "- Learning rate: 0.001\n",
    "- Bireccionalidad: *No posee*\n",
    "- Valor dropout: *0.5*\n",
    "- Cantidad de √©pocas de entrenamiento: *10*\n",
    "   \n",
    "\n",
    "**Modelo baseline escogiendo mejores hiperpar√°metros**: Es la red baseline pero con una elecci√≥n de hiperpar√°metros mediante *grid search*. En particular, la b√∫squeda mediante *grid search* utiliz√≥ los siguientes par√°metros con sus respectivos valores posibles:\n",
    "- Dimensi√≥n de capa embedding: *[128, 200, 256]*\n",
    "- N√∫mero de capas LSTM: *[3, 4]*\n",
    "- Dimensi√≥n de capas LSTM: *[128, 200, 256]*\n",
    "- Valor dropout: *[0.4, 0.5]*\n",
    "- Bireccionalidad: *[Posee, No posee]*\n",
    "\n",
    "En la secci√≥n de experimentos se muestra los resultados obtenidos para la b√∫squeda pero, adelantando la informaci√≥n, el modelo con los mejores resultados posee las siguientes caracter√≠sticas:\n",
    "- Dimensi√≥n de capa embedding: *128*\n",
    "- Tipo de capas intermedias: *LSTM*\n",
    "- N√∫mero de capas LSTM: *3*\n",
    "- Dimensi√≥n de capas LSTM: *256*\n",
    "- Dimensi√≥n output: *12*\n",
    "- Tama√±o de los batches: *22*\n",
    "- Funci√≥n de p√©rdida: *Cross entropy loss*\n",
    "- Algormito optimizador: *Adam*\n",
    "- Learning rate: 0.001\n",
    "- Bireccionalidad: *Posee*\n",
    "- Valor dropout: *0.5*\n",
    "- Cantidad de √©pocas de entrenamiento: *10*\n",
    "\n",
    "**Modelo baseline escogiendo mejores hiperpar√°metros y cantidad de √©pocas de entrenamiento**: Es la red baseline pero con una elecci√≥n de algunos hiperpar√°metros y la cantidad de √©pocas de entreniamento mediante *grid search*. En particular, la b√∫squeda mediante *grid search* utiliz√≥ los siguientes par√°metros con sus respectivos valores posibles:\n",
    "- Dimensi√≥n de capa embedding: *[128, 200, 256]*\n",
    "- Dimensi√≥n de capas LSTM: *[128, 200, 256]*\n",
    "- Cantidad de √©pocas de entrenamiento: *[15, 20]*\n",
    "\n",
    "N√≥tese que, en este caso, el n√∫mero de capas LSTM, la bireccionalidad y el valor dropout son valores fijos. En espec√≠fico, se fij√≥ dichos valores acorde a los resultados del experimento del modelo anterior, definiendo as√≠ como 3 el n√∫mero de capas LSTM, *Posee* como valor de la bireccionalidad y 0.5 el valor dropout.\n",
    "\n",
    "Del mismo modo el modelo anterior, en la secci√≥n de experimentos se muestra los resultados obtenidos para la b√∫squeda pero, adelantando la informaci√≥n, el modelo con los mejores resultados posee las siguientes caracter√≠sticas:\n",
    "- Dimensi√≥n de capa embedding: *200*\n",
    "- Tipo de capas intermedias: *LSTM*\n",
    "- N√∫mero de capas LSTM: *3*\n",
    "- Dimensi√≥n de capas LSTM: *200*\n",
    "- Dimensi√≥n output: *12*\n",
    "- Tama√±o de los batches: *22*\n",
    "- Funci√≥n de p√©rdida: *Cross entropy loss*\n",
    "- Algormito optimizador: *Adam*\n",
    "- Learning rate: 0.001\n",
    "- Bireccionalidad: *Posee*\n",
    "- Valor dropout: *0.5*\n",
    "- Cantidad de √©pocas de entrenamiento: *20*\n",
    "\n",
    "**Mejores modelos variando optimizador y learning rate**: Son los dos modelos escogidos en las dos secciones pero con una elecci√≥n de optimizador y *learning rate* mediante *grid search*. En particular, la b√∫squeda mediante *grid search* utiliz√≥ los siguientes par√°metros con sus respectivos valores posibles:\n",
    "- Algormito optimizador: *[Adam, SGD]*\n",
    "- Learning rate: *[0.01, 0.001, 0.0001]*\n",
    "\n",
    "En la secci√≥n de experimentos se muestra los resultados obtenidos para la b√∫squeda pero, adelantando la informaci√≥n, el modelo con los mejores resultados posee las siguientes caracter√≠sticas:\n",
    "- Dimensi√≥n de capa embedding: *128*\n",
    "- Tipo de capas intermedias: *LSTM*\n",
    "- N√∫mero de capas LSTM: *3*\n",
    "- Dimensi√≥n de capas LSTM: *256*\n",
    "- Dimensi√≥n output: *12*\n",
    "- Tama√±o de los batches: *22*\n",
    "- Funci√≥n de p√©rdida: *Cross entropy loss*\n",
    "- Algormito optimizador: *Adam*\n",
    "- Learning rate: 0.001\n",
    "- Bireccionalidad: *Posee*\n",
    "- Valor dropout: *0.5*\n",
    "- Cantidad de √©pocas de entrenamiento: *10*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaVhZ5iaaSFK"
   },
   "source": [
    "## **M√©tricas de evaluaci√≥n**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXl3GaVMUYA7"
   },
   "source": [
    "- **M√©trica estricta:** El modelo a entrenar entrega una secuencia de etiquetas para una oraci√≥n, es decir, para una oraci√≥n con una cantidad espec√≠fica de tokens, el modelo *predice* la etiqueta para cada token. En ese sentido, una m√©trica no estricta medir√≠a la calidad del modelo evaluando la predicci√≥n de cada token con su etiqueta, de manera individual e independiente. Sin embargo, en esta tarea se busca identificar entidades (y no etiquetas independientes) y, por tanto, se necesita utilizar m√©tricas que reconozcan tanto la ubicaci√≥n y el tipo de entidades asociadas a cada oraci√≥n. En ese sentido, las m√©tricas estrictas resuelven los problemas mencionados y permiten medir el modelo en su capacidad de predecir **entidades** (y no solo la capacidad de los modelos de precedir etiquetas independientes).\n",
    "\n",
    "- **Precision:** Dada una entidad, la precisi√≥n mide la cantidad de veces que el modelo predice correctamente dicha entidad versus la cantidad total de veces que el modelo predice dicha entidad (tanto correctamente como incorrectamente).\n",
    "\n",
    "- **Recall:** Dada una entidad, el recall mide la cantidad de veces que el modelo predice correctamente dicha entidad versus la cantidad total de veces que dicha entidad est√° presente, es decir, mide la proporci√≥n entre la veces que se predijo correctamente la entidad versus la cantidad total de *apariciones* de la entidad. \n",
    "\n",
    "- **Micro F1 score:** Dada una entidad, la m√©trica F1 score es la media arm√≥nica entre la *precision* y el *recall*. Ahora, dada todas las entidades, se puede definir una m√©trica global asocida a *F1 score*. Dicha m√©trica global puede considerar la proporci√≥n de las clases o no. En caso de no considerar la proporci√≥n de la clases, la m√©trica se denomina *macro f1 score* y no es m√°s que el promedio *normal* de los *f1 scores* de todas las clases. Por el otro lado, en caso de considerar la proporci√≥n de las entidades, la m√©trica se denomina *micro f1 score* y es un promedio *ponderado* de los *f1 scores* de todas las entidades, es decir, es una media que considera la proporci√≥n de entidades de cada tipo a la hora de promediar los *f1 scores*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u27WffRVUj4v"
   },
   "source": [
    "## **Dise√±o experimental**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O228DbeUmE7"
   },
   "source": [
    "El dise√±o experimental est√° estrechamente correlacionado con la metodolog√≠a para escoger modelos descrita en la secci√≥n **Modelos**. As√≠, con lo anterior en mente, se tiene que se realiz√≥ lo siguiente:\n",
    "\n",
    "- Iniclamente se entrenar√° el modelo entregado en el enunciado para observar sus resultados.\n",
    "- Luego, con la RNN baseline, se realizar√° una elecci√≥n de hiperpar√°metros mediante *grid search*. En particular, la b√∫squeda mediante *grid search* utilizar√° los siguientes par√°metros con sus respectivos valores posibles:\n",
    " - Dimensi√≥n de capa embedding: *[128, 200, 256]*\n",
    " - N√∫mero de capas LSTM: *[3, 4]*\n",
    " - Dimensi√≥n de capas LSTM: *[128, 200, 256]*\n",
    " - Valor dropout: *[0.4, 0.5]*\n",
    " - Bireccionalidad: *[Posee, No posee]*\n",
    "- Posteriormente, se realizar√° una elecci√≥n de hiperpar√°metros y n√∫mero de √©pocas de entrenamiento mediante *grid search*. En particular, la b√∫squeda mediante *grid search* utilizar√° los siguientes par√°metros con sus respectivos valores posibles:\n",
    " - Dimensi√≥n de capa embedding: *[128, 200, 256]*\n",
    " - Dimensi√≥n de capas LSTM: *[128, 200, 256]*\n",
    " - Cantidad de √©pocas de entrenamiento: *[15, 20]*\n",
    "- Finalmente, se escoger√° el mejor modelo para ambas b√∫squedas y se realizar√° una elecci√≥n del algoritmo optimizador y el learning rate. En particular, la b√∫squeda mediante *grid search* utilizar√° los siguientes par√°metros con sus respectivos valores posibles:\n",
    " - Algormito optimizador: *[Adam, SGD]*\n",
    " - Learning rate: *[0.01, 0.001, 0.0001]*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFM-wNt8aSFM"
   },
   "source": [
    "## **Experimentos**\n",
    "\n",
    "\n",
    "El c√≥digo que les entregaremos servir√° de baseline para luego implementar mejores modelos. \n",
    "En general, el c√≥digo asociado a la carga de los datos, las funciones de entrenamiento, de evaluaci√≥n y la predicci√≥n de los datos de la competencia no deber√≠an cambiar. \n",
    "Solo deben preocuparse de cambiar la arquitectura del modelo, sus hiperpar√°metros y reportar, lo cual lo pueden hacer en las subsecciones *modelos*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMgKjfYC_Go-"
   },
   "source": [
    "###  **Carga de datos y Preprocesamiento**\n",
    "\n",
    "Para cargar los datos y preprocesarlos usaremos la librer√≠a [`torchtext`](https://github.com/pytorch/text). Tener cuidado ya que hace algunos meses esta librer√≠a tuvo cambios radicales, quedando las funcionalidades pasadas en un nuevo paquete llamado legacy. Esto ya que si quieren usar m√°s funciones de la librer√≠a entonces vean los cambios en la documentaci√≥n.\n",
    "\n",
    "En particular usaremos su m√≥dulo `data`, el cual seg√∫n su documentaci√≥n original provee: \n",
    "\n",
    "    - Ability to describe declaratively how to load a custom NLP dataset that's in a \"normal\" format\n",
    "    - Ability to define a preprocessing pipeline\n",
    "    - Batching, padding, and numericalizing (including building a vocabulary object)\n",
    "    - Wrapper for dataset splits (train, validation, test)\n",
    "\n",
    "\n",
    "El proceso ser√° el siguiente: \n",
    "\n",
    "1. Descargar los datos desde github y examinarlos.\n",
    "2. Definir los campos (`fields`) que cargaremos desde los archivos.\n",
    "3. Cargar los datasets.\n",
    "4. Crear el vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27csY87GaSFO",
    "outputId": "c18672d7-a001-450f-da9a-497e9811b321",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchtext==0.10.0\n",
      "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 831.4 MB 2.8 kB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
      "Installing collected packages: torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0+cu113\n",
      "    Uninstalling torch-1.11.0+cu113:\n",
      "      Successfully uninstalled torch-1.11.0+cu113\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.12.0\n",
      "    Uninstalling torchtext-0.12.0:\n",
      "      Successfully uninstalled torchtext-0.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n",
      "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Instalamos torchtext que nos facilitar√° la vida en el pre-procesamiento del formato ConLL.\n",
    "!pip install -U torchtext==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ng7wRGEyawjM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets, legacy\n",
    "\n",
    "\n",
    "# Garantizar reproducibilidad de los experimentos\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BehSou6rCvwg"
   },
   "source": [
    "#### **Obtener datos**\n",
    "\n",
    "Descargamos los datos de entrenamiento, validaci√≥n y prueba en nuestro directorio de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbT0g_kC18Jb",
    "outputId": "5f990d71-fdab-4c22-c216-5d255b7fd5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-29 17:39:18--  https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/77198f00-c145-11eb-83d1-11e647241ab6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T173918Z&X-Amz-Expires=300&X-Amz-Signature=5329c8797157e06cac4587a3db74f854a76307483c52f2d403e6e04e1c4c2b07&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtrain.txt&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-06-29 17:39:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/77198f00-c145-11eb-83d1-11e647241ab6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T173918Z&X-Amz-Expires=300&X-Amz-Signature=5329c8797157e06cac4587a3db74f854a76307483c52f2d403e6e04e1c4c2b07&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtrain.txt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1607913 (1.5M) [application/octet-stream]\n",
      "Saving to: ‚Äòtrain.txt‚Äô\n",
      "\n",
      "train.txt           100%[===================>]   1.53M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2022-06-29 17:39:18 (28.4 MB/s) - ‚Äòtrain.txt‚Äô saved [1607913/1607913]\n",
      "\n",
      "--2022-06-29 17:39:18--  https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt\n",
      "Resolving github.com (github.com)... 140.82.114.4\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/741e9e80-c145-11eb-813a-b9abac0d674c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T173918Z&X-Amz-Expires=300&X-Amz-Signature=ed4a7f871256a54609dfebc30f59677bb80a6627889d3f06e21ebb72b179183e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Ddev.txt&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-06-29 17:39:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/741e9e80-c145-11eb-813a-b9abac0d674c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T173918Z&X-Amz-Expires=300&X-Amz-Signature=ed4a7f871256a54609dfebc30f59677bb80a6627889d3f06e21ebb72b179183e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Ddev.txt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 177166 (173K) [application/octet-stream]\n",
      "Saving to: ‚Äòdev.txt‚Äô\n",
      "\n",
      "dev.txt             100%[===================>] 173.01K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2022-06-29 17:39:18 (7.59 MB/s) - ‚Äòdev.txt‚Äô saved [177166/177166]\n",
      "\n",
      "--2022-06-29 17:39:19--  https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/75e86200-c145-11eb-94f8-49517311d768?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T173919Z&X-Amz-Expires=300&X-Amz-Signature=a5fbda250b8f472a4ce7eac4bb2a1e4704b4bf33eeab13b7effac9a04ab5356f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtest.txt&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-06-29 17:39:19--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/75e86200-c145-11eb-94f8-49517311d768?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220629%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220629T173919Z&X-Amz-Expires=300&X-Amz-Signature=a5fbda250b8f472a4ce7eac4bb2a1e4704b4bf33eeab13b7effac9a04ab5356f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtest.txt&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 147052 (144K) [application/octet-stream]\n",
      "Saving to: ‚Äòtest.txt‚Äô\n",
      "\n",
      "test.txt            100%[===================>] 143.61K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2022-06-29 17:39:19 (6.63 MB/s) - ‚Äòtest.txt‚Äô saved [147052/147052]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt -nc # Dataset de Entrenamiento\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt -nc    # Dataset de Validaci√≥n (Para probar y ajustar el modelo)\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¬°¬°SON LOS QUE DEBEN SER PREDICHOS!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMud7YGMBZvg"
   },
   "source": [
    "####  **Fields**\n",
    "\n",
    "Un `field`:\n",
    "\n",
    "* Define un tipo de datos junto con instrucciones para convertir el texto a Tensor.\n",
    "* Contiene un objeto `Vocab` que contiene el vocabulario (palabras posibles que puede tomar ese campo).\n",
    "* Contiene otros par√°metros relacionados con la forma en que se debe numericalizar un tipo de datos, como un m√©todo de tokenizaci√≥n y el tipo de Tensor que se debe producir.\n",
    "\n",
    "\n",
    "Analizemos el siguiente cuadro el cual contiene un ejemplo cualquiera de entrenamiento:\n",
    "\n",
    "\n",
    "```\n",
    "El O\n",
    "paciente O\n",
    "padece O\n",
    "de O\n",
    "cancer B-Disease\n",
    "de I-Disease\n",
    "colon I-Disease\n",
    ". O\n",
    "```\n",
    "\n",
    "Cada linea contiene un token y el tipo de entidad asociado en el formato IOB2 ya explicado. Para que `torchtext` pueda cargar estos datos, debemos definir como va a leer y separar los componentes de cada una de las lineas.\n",
    "Para esto, definiremos un field para cada uno de esos componentes: Las palabras (`TEXT`) y las etiquetas o categor√≠as (`NER_TAGS`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3DcM_IjgCdzz"
   },
   "outputs": [],
   "source": [
    "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
    "TEXT = legacy.data.Field(lower=False) \n",
    "\n",
    "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
    "NER_TAGS = legacy.data.Field(unk_token=None)\n",
    "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZPxDaaKgeqI",
    "outputId": "e3603ec0-532c-428b-a9d9-ee05aeb02157"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('text', <torchtext.legacy.data.field.Field at 0x7fc27c115510>),\n",
       " ('nertags', <torchtext.legacy.data.field.Field at 0x7fc27c183990>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCKTJOdgC5eC"
   },
   "source": [
    "####  **SequenceTaggingDataset**\n",
    "\n",
    "`SequenceTaggingDataset` es una clase de torchtext dise√±ada para contener datasets de sequence labeling. Los ejemplos que se guarden en una instancia de estos ser√°n arreglos de palabras asociados con sus respectivos tags.\n",
    "\n",
    "Por ejemplo, para Part-of-speech tagging:\n",
    "\n",
    "[I, love, PyTorch, .] estar√° asociado con [PRON, VERB, PROPN, PUNCT]\n",
    "\n",
    "\n",
    "La idea es que usando los fields que definimos antes, le indiquemos a la clase c√≥mo cargar los datasets de prueba, validaci√≥n y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HsHdGml62J21"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = legacy.datasets.SequenceTaggingDataset.splits(\n",
    "    path=\"./\",\n",
    "    train=\"train.txt\",\n",
    "    validation=\"dev.txt\",\n",
    "    test=\"test.txt\",\n",
    "    fields=fields,\n",
    "    encoding=\"utf-8\",\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2qf7YTWHEYR",
    "outputId": "8699af04-387e-45bb-db35-3751d495552b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.datasets.sequence_tagging.SequenceTaggingDataset at 0x7fc27c1839d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hu7q3HCliia5",
    "outputId": "5b2ed871-9586-4c7e-f9ca-b28d84ef268d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de ejemplos de entrenamiento: 8025\n",
      "N√∫mero de ejemplos de validaci√≥n: 891\n",
      "N√∫mero de ejemplos de test (competencia): 992\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
    "print(f\"N√∫mero de ejemplos de validaci√≥n: {len(valid_data)}\")\n",
    "print(f\"N√∫mero de ejemplos de test (competencia): {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDRnhXAdFGL-"
   },
   "source": [
    "Visualizemos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T023Ld4RaSF4",
    "outputId": "91e150ed-3ab0-4761-8b13-35cdefdba558",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ANTERIOR', 'O'),\n",
       " ('CESARIA', 'B-Procedure'),\n",
       " ('POR', 'O'),\n",
       " ('PRECLAMPSIA', 'B-Disease'),\n",
       " ('A√ëO', 'O'),\n",
       " ('2011', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_item_idx = random.randint(0, len(train_data))\n",
    "random_example = train_data.examples[random_item_idx]\n",
    "list(zip(random_example.text, random_example.nertags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l05KYy5FSUy"
   },
   "source": [
    "#### **Construir los vocabularios para el texto y las etiquetas**\n",
    "\n",
    "Los vocabularios son los objetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields. El siguiente paso consiste en construirlos. Para esto, hacemos uso del m√©todo `Field.build_vocab` sobre cada uno de nuestros `fields`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PBhp7WICiibL"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "NER_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4OgUKM_iibO",
    "outputId": "ccfe71fe-014f-4b58-f458-0e1543710dc5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens √∫nicos en TEXT: 17591\n",
      "Tokens √∫nicos en NER_TAGS: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokens √∫nicos en TEXT: {len(TEXT.vocab)}\")\n",
    "print(f\"Tokens √∫nicos en NER_TAGS: {len(NER_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4FeyL9nFnId",
    "outputId": "150e4a3e-7b3d-4456-a0b4-ef2ce764d575"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'O',\n",
       " 'I-Disease',\n",
       " 'B-Disease',\n",
       " 'I-Body_Part',\n",
       " 'B-Body_Part',\n",
       " 'B-Procedure',\n",
       " 'I-Procedure',\n",
       " 'B-Medication',\n",
       " 'B-Family_Member',\n",
       " 'I-Medication',\n",
       " 'I-Family_Member']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veamos las posibles etiquetas que hemos cargado:\n",
    "NER_TAGS.vocab.itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYQDoUqSHFKj"
   },
   "source": [
    "Observen que ademas de los tags NER, tenemos \\<pad\\>, el cual es generado por el dataloader para cumplir con el padding de cada oraci√≥n.\n",
    "\n",
    "Veamos ahora los tokens mas frecuentes y especiales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5eSLm4diibR",
    "outputId": "52a5305d-62cc-4e62-bd82-4b381d4a67e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 7396),\n",
       " (',', 6821),\n",
       " ('-', 4985),\n",
       " ('de', 3811),\n",
       " ('DE', 3645),\n",
       " ('/', 2317),\n",
       " (':', 2209),\n",
       " ('con', 1484),\n",
       " ('y', 1439),\n",
       " ('APS', 1429)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens mas frecuentes (Ser√° necesario usar stopwords, eliminar s√≠mbolos o nos entregan informaci√≥n (?) )\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WDyNLMPz9duD"
   },
   "outputs": [],
   "source": [
    "# Seteamos algunas variables que nos ser√°n de utilidad mas adelante...\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "O_TAG_IDX = NER_TAGS.vocab.stoi['O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrYvF3X0sjWL"
   },
   "source": [
    "#### **Frecuencia de los Tags**\n",
    "\n",
    "Visualizemos r√°pidamente las cantidades y frecuencias de cada tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuXOsbJUiibh",
    "outputId": "f19e6c26-cffe-4f82-d652-99649bb659bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag Ocurrencia Porcentaje\n",
      "\n",
      "O\t101671\t68.1%\n",
      "I-Disease\t21629\t14.5%\n",
      "B-Disease\t8831\t 5.9%\n",
      "I-Body_Part\t6489\t 4.3%\n",
      "B-Body_Part\t3755\t 2.5%\n",
      "B-Procedure\t2891\t 1.9%\n",
      "I-Procedure\t2819\t 1.9%\n",
      "B-Medication\t784\t 0.5%\n",
      "B-Family_Member\t228\t 0.2%\n",
      "I-Medication\t116\t 0.1%\n",
      "I-Family_Member\t9\t 0.0%\n"
     ]
    }
   ],
   "source": [
    "def tag_percentage(tag_counts):\n",
    "    \n",
    "    total_count = sum([count for tag, count in tag_counts])\n",
    "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
    "  \n",
    "    return tag_counts_percentages\n",
    "\n",
    "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
    "\n",
    "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
    "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4wPiydnaSGs"
   },
   "source": [
    "#### **Configuramos pytorch y dividimos los datos.**\n",
    "\n",
    "Importante: si tienes problemas con la ram de la gpu, disminuye el tama√±o de los batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uB7cwLWpaSGs",
    "outputId": "b22c269d-4e28-491c-eee5-94255625d1c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 22  # disminuir si hay problemas de ram.\n",
    "\n",
    "# Usar cuda si es que est√° disponible.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "# Dividir datos entre entrenamiento y test. Si van a hacer alg√∫n sort no puede ser sobre\n",
    "# el conjunto de testing ya que al hacer sus predicciones sobre el conjunto de test sin etiquetas\n",
    "# debe conservar el orden original para ser comparado con los golden_labels. \n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = legacy.data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B21E1eAFId16"
   },
   "source": [
    "#### **M√©tricas de evaluaci√≥n**\n",
    "\n",
    "Adem√°s, definiremos las m√©tricas que ser√°n usadas tanto para la competencia como para evaluar el modelo: `precision`, `recall` y `micro f1-score`.\n",
    "**Importante**: Noten que la evaluaci√≥n solo se hace para las Named Entities (sin contar 'O'), toda esta funcionalidad nos la entrega la librer√≠a seqeval, pueden revisar m√°s documentaci√≥n aqu√≠: https://github.com/chakki-works/seqeval. No utilicen el c√≥digo entregado por sklearn para calcular las m√©tricas ya que esta lo hace a nivel de token y no a nivel de entidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o63ov69_rX2T",
    "outputId": "dd4929b7-9f29-4abe-cd04-01cf83aa8103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43 kB 977 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=08b2c72c8bdcb433a4c21abbe8a0edb9f6bd3fa8047a7aa349efc4e86b585f80\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9mUOOLEWiicU"
   },
   "outputs": [],
   "source": [
    "# Definimos las m√©tricas\n",
    "\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
    "    \"\"\"\n",
    "    Calcula precision, recall y f1 de cada batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
    "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    # filtramos <pad> para calcular los scores.\n",
    "    mask = [(y_true != pad_idx)]\n",
    "    y_pred = y_pred[mask]\n",
    "    y_true = y_true[mask]\n",
    "\n",
    "    # traemos a la cpu\n",
    "    y_pred = y_pred.view(-1).to('cpu').numpy()\n",
    "    y_true = y_true.to('cpu').numpy()\n",
    "    y_pred = [[NER_TAGS.vocab.itos[v] for v in y_pred]]\n",
    "    y_true = [[NER_TAGS.vocab.itos[v] for v in y_true]]\n",
    "    \n",
    "    # calcular scores\n",
    "    f1 = f1_score(y_true, y_pred, mode='strict')\n",
    "    precision = precision_score(y_true, y_pred, mode='strict')\n",
    "    recall = recall_score(y_true, y_pred, mode='strict')\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hod516H1aSG2"
   },
   "source": [
    "\n",
    "\n",
    "### **Modelo Baseline**\n",
    "\n",
    "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendr√° una capa de embedding, unas cuantas LSTM y una capa de salida y usar√° dropout en el entrenamiento.\n",
    "\n",
    "Este constar√° de los siguientes pasos: \n",
    "\n",
    "1. Definir la clase que contendr√° la red.\n",
    "2. Definir los hiperpar√°metros e inicializar la red. \n",
    "3. Definir el n√∫mero de √©pocas de entrenamiento\n",
    "4. Definir la funci√≥n de loss.\n",
    "\n",
    "\n",
    "\n",
    "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rMPL08XqaSG3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Definir la red\n",
    "class NER_RNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim,\n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Capa de embedding\n",
    "        self.embedding = nn.Embedding(input_dim,\n",
    "                                      embedding_dim,\n",
    "                                      padding_idx=pad_idx,\n",
    "                                      )\n",
    "\n",
    "        # Capa LSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout = dropout if n_layers > 1 else 0)\n",
    "\n",
    "        # Capa de salida\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
    "                            output_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # Convertir lo enviado a embedding\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "\n",
    "        # Pasar los embeddings por la rnn (LSTM)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        # Predecir usando la capa de salida.\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCl3530VaSG7"
   },
   "source": [
    "#### **Hiperpar√°metros de la red**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EHdi3QdOaSG8"
   },
   "outputs": [],
   "source": [
    "# tama√±o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 200  # dimensi√≥n de los embeddings.\n",
    "HIDDEN_DIM = 128  # dimensi√≥n de la capas LSTM\n",
    "OUTPUT_DIM = len(NER_TAGS.vocab)  # n√∫mero de clases\n",
    "\n",
    "N_LAYERS = 3  # n√∫mero de capas.\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "# Creamos nuestro modelo.\n",
    "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
    "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "\n",
    "baseline_model_name = 'baseline'  # nombre que tendr√° el modelo guardado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jlF1DhJeaSHA"
   },
   "outputs": [],
   "source": [
    "baseline_n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3u4imJGaSHE"
   },
   "source": [
    "#### Definimos la funci√≥n de loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6G_4k99_aSHG"
   },
   "outputs": [],
   "source": [
    "# Loss: Cross Entropy\n",
    "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4bpQyGe2PMK"
   },
   "source": [
    "#### Entrenamiento y evaluaci√≥n modelo baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "r8YlGnjxaSHZ"
   },
   "outputs": [],
   "source": [
    "model = baseline_model\n",
    "model_name = baseline_model_name\n",
    "criterion = baseline_criterion\n",
    "n_epochs = baseline_n_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pu_lXic2aSHd"
   },
   "source": [
    "\n",
    "\n",
    "#### **Inicializamos la red**\n",
    "\n",
    "Iniciamos los pesos de la red de forma aleatoria (Usando una distribuci√≥n normal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-G_NWFcaSHe",
    "outputId": "9f5575d5-2155-4174-d097-a6db5e8a8ba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NER_RNN(\n",
       "  (embedding): Embedding(17591, 200, padding_idx=1)\n",
       "  (lstm): LSTM(200, 128, num_layers=3, dropout=0.5)\n",
       "  (fc): Linear(in_features=128, out_features=12, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # Inicializamos los pesos como aleatorios\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "        \n",
    "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjWDX2CJaSHh",
    "outputId": "63a88cd8-b687-44d4-bc10-8a7ce3e8d80f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo actual tiene 3,952,900 par√°metros entrenables.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'El modelo actual tiene {count_parameters(model):,} par√°metros entrenables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVqBqerlaSHk"
   },
   "source": [
    "Notar que definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVZvHtwpaSHq"
   },
   "source": [
    "#### **Definimos el optimizador**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AH6o8_cTaSHq"
   },
   "outputs": [],
   "source": [
    "# Optimizador\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz39wa78wGYR"
   },
   "source": [
    "#### **Enviamos el modelo a cuda**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqr0AJ6_iicR"
   },
   "outputs": [],
   "source": [
    "# Enviamos el modelo y la loss a cuda (en el caso en que est√© disponible)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xlq48WjiW6U"
   },
   "source": [
    "#### **Definimos el entrenamiento de la red**\n",
    "\n",
    "Algunos conceptos previos: \n",
    "\n",
    "- `epoch` : una pasada de entrenamiento completa de una dataset.\n",
    "- `batch`: una fracci√≥n de la √©poca. Se utilizan para entrenar mas r√°pidamente la red. (mas eficiente pasar n datos que uno en cada ejecuci√≥n del backpropagation)\n",
    "\n",
    "Esta funci√≥n est√° encargada de entrenar la red en una √©poca. Para esto, por cada batch de la √©poca actual, predice los tags del texto, calcula su loss y luego hace backpropagation para actualizar los pesos de la red.\n",
    "\n",
    "Observaci√≥n: En algunos comentarios aparecer√° el tama√±o de los tensores entre corchetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DV6YLt0oiicW"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Por cada batch del iterador de la √©poca:\n",
    "    for batch in iterator:\n",
    "\n",
    "        # Extraemos el texto y los tags del batch que estamos procesado\n",
    "        text = batch.text\n",
    "        tags = batch.nertags\n",
    "\n",
    "        # Reiniciamos los gradientes calculados en la iteraci√≥n anterior\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # Predecimos los tags del texto del batch.\n",
    "        predictions = model(text)\n",
    "\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "\n",
    "        # Reordenamos los datos para calcular la loss\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "\n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "\n",
    "\n",
    "\n",
    "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
    "        loss = criterion(predictions, tags)\n",
    "        \n",
    "        # Calculamos el accuracy\n",
    "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
    "\n",
    "        # Calculamos los gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualizamos los par√°metros de la red\n",
    "        optimizer.step()\n",
    "\n",
    "        # Actualizamos el loss y las m√©tricas\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_precision += precision\n",
    "        epoch_recall += recall\n",
    "        epoch_f1 += f1\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_precision / len(\n",
    "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYNcwKnAz5Hf"
   },
   "source": [
    "#### **Definimos la funci√≥n de evaluaci√≥n**\n",
    "\n",
    "Evalua el rendimiento actual de la red usando los datos de validaci√≥n. \n",
    "\n",
    "Por cada batch de estos datos, calcula y reporta el loss y las m√©tricas asociadas al conjunto de validaci√≥n. \n",
    "Ya que las m√©tricas son calculadas por cada batch, estas son retornadas promediadas por el n√∫mero de batches entregados. (ver linea del return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WsRuiUuHiicY"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Indicamos que ahora no guardaremos los gradientes\n",
    "    with torch.no_grad():\n",
    "        # Por cada batch\n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.nertags\n",
    "\n",
    "            # Predecimos\n",
    "            predictions = model(text)\n",
    "\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
    "            loss = criterion(predictions, tags)\n",
    "\n",
    "            # Calculamos las m√©tricas\n",
    "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
    "\n",
    "            # Actualizamos el loss y las m√©tricas\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_precision += precision\n",
    "            epoch_recall += recall\n",
    "            epoch_f1 += f1\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_precision / len(\n",
    "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Xs-n9Y5yiica"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy3MVf5H0A94"
   },
   "source": [
    "\n",
    "#### **Entrenamiento de la red**\n",
    "\n",
    "En este cuadro de c√≥digo ejecutaremos el entrenamiento de la red.\n",
    "Para esto, primero definiremos el n√∫mero de √©pocas y luego por cada √©poca, ejecutaremos `train` y `evaluate`.\n",
    "\n",
    "**Importante: Reiniciar los pesos del modelo**\n",
    "\n",
    "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez. \n",
    "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la funci√≥n `init_weights`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iK5lQqpviicf",
    "outputId": "f11942b3-7756-4023-de3e-bfd05a687e22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.992 | Train f1: 0.24 | Train precision: 0.43 | Train recall: 0.19\n",
      "\t Val. Loss: 0.628 |  Val. f1: 0.54 |  Val. precision: 0.71 | Val. recall: 0.44\n",
      "Epoch: 02 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.561 | Train f1: 0.60 | Train precision: 0.69 | Train recall: 0.54\n",
      "\t Val. Loss: 0.475 |  Val. f1: 0.65 |  Val. precision: 0.75 | Val. recall: 0.58\n",
      "Epoch: 03 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.418 | Train f1: 0.70 | Train precision: 0.74 | Train recall: 0.66\n",
      "\t Val. Loss: 0.430 |  Val. f1: 0.70 |  Val. precision: 0.74 | Val. recall: 0.67\n",
      "Epoch: 04 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.339 | Train f1: 0.76 | Train precision: 0.78 | Train recall: 0.74\n",
      "\t Val. Loss: 0.413 |  Val. f1: 0.72 |  Val. precision: 0.75 | Val. recall: 0.70\n",
      "Epoch: 05 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.289 | Train f1: 0.79 | Train precision: 0.80 | Train recall: 0.78\n",
      "\t Val. Loss: 0.404 |  Val. f1: 0.73 |  Val. precision: 0.75 | Val. recall: 0.72\n",
      "Epoch: 06 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.249 | Train f1: 0.82 | Train precision: 0.83 | Train recall: 0.82\n",
      "\t Val. Loss: 0.400 |  Val. f1: 0.75 |  Val. precision: 0.78 | Val. recall: 0.72\n",
      "Epoch: 07 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.219 | Train f1: 0.84 | Train precision: 0.85 | Train recall: 0.84\n",
      "\t Val. Loss: 0.411 |  Val. f1: 0.74 |  Val. precision: 0.78 | Val. recall: 0.72\n",
      "Epoch: 08 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.199 | Train f1: 0.86 | Train precision: 0.86 | Train recall: 0.86\n",
      "\t Val. Loss: 0.397 |  Val. f1: 0.75 |  Val. precision: 0.76 | Val. recall: 0.74\n",
      "Epoch: 09 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.180 | Train f1: 0.87 | Train precision: 0.87 | Train recall: 0.87\n",
      "\t Val. Loss: 0.433 |  Val. f1: 0.75 |  Val. precision: 0.76 | Val. recall: 0.74\n",
      "Epoch: 10 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.168 | Train f1: 0.88 | Train precision: 0.88 | Train recall: 0.88\n",
      "\t Val. Loss: 0.435 |  Val. f1: 0.75 |  Val. precision: 0.77 | Val. recall: 0.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
    "\n",
    "    # Entrenar\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(\n",
    "        model, train_iterator, optimizer, criterion)\n",
    "\n",
    "    # Evaluar (valid = validaci√≥n)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "        model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
    "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c√≥digo.\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "    # Si ya no mejoramos el loss de validaci√≥n, terminamos de entrenar.\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(\n",
    "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
    "    )\n",
    "    print(\n",
    "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcZPraG-9duO"
   },
   "source": [
    "**Importante**: Recuerden que el √∫ltimo modelo entrenado no es el mejor (probablemente est√© *overfitteado*), si no el que guardamos con la menor loss del conjunto de validaci√≥n. Este problema lo pueden solucionar con *early stopping*.\n",
    "Para cargar el mejor modelo entrenado, ejecuten la siguiente celda.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y27CNYfrjtQ-",
    "outputId": "25d53d3a-3700-41fc-d5a0-f6781b145e3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargar el mejor modelo entrenado.\n",
    "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLuqFKFR9duO"
   },
   "outputs": [],
   "source": [
    "# Limpiar ram de cuda\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz1BYPY72PMS"
   },
   "source": [
    "#### **Evaluamos el set de validaci√≥n con el modelo final**\n",
    "\n",
    "Estos son los resultados de predecir el dataset de evaluaci√≥n con el *mejor* modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5UQi_Yu2PMT",
    "outputId": "5d760a53-5e23-4c89-8ba9-b7d1c6f904d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. Loss: 0.397 |  Val. f1: 0.75 | Val. precision: 0.76 | Val. recall: 0.74\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "    model, valid_iterator, criterion)\n",
    "\n",
    "print(\n",
    "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LpKGamd2PMU"
   },
   "source": [
    "### Modelo baseline escogiendo mejores hiperpar√°metros:\n",
    "\n",
    "Ahora, dada la estructura *base* del modelo anterior, mediante gridsearch, se busc√≥ los mejores hiperpar√°metros (embedding dim, hidden dim, n√∫mero de capaps, dropout y bidireccionalidad), es decir, los hiperpar√°metros que maximizaran el *f1-score*. As√≠, siguiendo un procedimiento similar realizado para el modelo anterior, se calcul√≥ *loss*, *f1-score*, *precision* y *recall* para cada caso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvdSyy6rlUdt",
    "outputId": "38076c6d-26a1-43ec-b9aa-6ec956a34c15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128-128-3-0.4-True\n",
      "Val. Loss: 0.353 |  Val. f1: 0.76 | Val. precision: 0.78 | Val. recall: 0.74\n",
      "\n",
      "128-128-3-0.4-False\n",
      "Val. Loss: 0.397 |  Val. f1: 0.74 | Val. precision: 0.76 | Val. recall: 0.72\n",
      "\n",
      "128-128-3-0.5-True\n",
      "Val. Loss: 0.339 |  Val. f1: 0.78 | Val. precision: 0.80 | Val. recall: 0.77\n",
      "\n",
      "128-128-3-0.5-False\n",
      "Val. Loss: 0.398 |  Val. f1: 0.74 | Val. precision: 0.75 | Val. recall: 0.73\n",
      "\n",
      "128-128-4-0.4-True\n",
      "Val. Loss: 0.358 |  Val. f1: 0.75 | Val. precision: 0.77 | Val. recall: 0.73\n",
      "\n",
      "128-128-4-0.4-False\n",
      "Val. Loss: 0.412 |  Val. f1: 0.71 | Val. precision: 0.72 | Val. recall: 0.71\n",
      "\n",
      "128-128-4-0.5-True\n",
      "Val. Loss: 0.360 |  Val. f1: 0.76 | Val. precision: 0.80 | Val. recall: 0.73\n",
      "\n",
      "128-128-4-0.5-False\n",
      "Val. Loss: 0.416 |  Val. f1: 0.72 | Val. precision: 0.77 | Val. recall: 0.69\n",
      "\n",
      "128-200-3-0.4-True\n",
      "Val. Loss: 0.344 |  Val. f1: 0.78 | Val. precision: 0.80 | Val. recall: 0.76\n",
      "\n",
      "128-200-3-0.4-False\n",
      "Val. Loss: 0.379 |  Val. f1: 0.75 | Val. precision: 0.78 | Val. recall: 0.73\n",
      "\n",
      "128-200-3-0.5-True\n",
      "Val. Loss: 0.328 |  Val. f1: 0.77 | Val. precision: 0.80 | Val. recall: 0.75\n",
      "\n",
      "128-200-3-0.5-False\n",
      "Val. Loss: 0.389 |  Val. f1: 0.75 | Val. precision: 0.75 | Val. recall: 0.75\n",
      "\n",
      "128-200-4-0.4-True\n",
      "Val. Loss: 0.346 |  Val. f1: 0.77 | Val. precision: 0.80 | Val. recall: 0.75\n",
      "\n",
      "128-200-4-0.4-False\n",
      "Val. Loss: 0.400 |  Val. f1: 0.72 | Val. precision: 0.75 | Val. recall: 0.70\n",
      "\n",
      "128-200-4-0.5-True\n",
      "Val. Loss: 0.362 |  Val. f1: 0.75 | Val. precision: 0.79 | Val. recall: 0.73\n",
      "\n",
      "128-200-4-0.5-False\n",
      "Val. Loss: 0.394 |  Val. f1: 0.73 | Val. precision: 0.73 | Val. recall: 0.74\n",
      "\n",
      "128-256-3-0.4-True\n",
      "Val. Loss: 0.347 |  Val. f1: 0.75 | Val. precision: 0.79 | Val. recall: 0.72\n",
      "\n",
      "128-256-3-0.4-False\n",
      "Val. Loss: 0.375 |  Val. f1: 0.74 | Val. precision: 0.77 | Val. recall: 0.71\n",
      "\n",
      "128-256-3-0.5-True\n",
      "Val. Loss: 0.340 |  Val. f1: 0.79 | Val. precision: 0.81 | Val. recall: 0.77\n",
      "\n",
      "128-256-3-0.5-False\n",
      "Val. Loss: 0.377 |  Val. f1: 0.74 | Val. precision: 0.77 | Val. recall: 0.72\n",
      "\n",
      "128-256-4-0.4-True\n",
      "Val. Loss: 0.359 |  Val. f1: 0.78 | Val. precision: 0.77 | Val. recall: 0.78\n",
      "\n",
      "128-256-4-0.4-False\n",
      "Val. Loss: 0.393 |  Val. f1: 0.74 | Val. precision: 0.74 | Val. recall: 0.73\n",
      "\n",
      "128-256-4-0.5-True\n",
      "Val. Loss: 0.344 |  Val. f1: 0.78 | Val. precision: 0.78 | Val. recall: 0.77\n",
      "\n",
      "128-256-4-0.5-False\n",
      "Val. Loss: 0.389 |  Val. f1: 0.74 | Val. precision: 0.73 | Val. recall: 0.74\n",
      "\n",
      "200-128-3-0.4-True\n",
      "Val. Loss: 0.355 |  Val. f1: 0.76 | Val. precision: 0.78 | Val. recall: 0.76\n",
      "\n",
      "200-128-3-0.4-False\n",
      "Val. Loss: 0.395 |  Val. f1: 0.75 | Val. precision: 0.78 | Val. recall: 0.72\n",
      "\n",
      "200-128-3-0.5-True\n",
      "Val. Loss: 0.361 |  Val. f1: 0.76 | Val. precision: 0.79 | Val. recall: 0.74\n",
      "\n",
      "200-128-3-0.5-False\n",
      "Val. Loss: 0.400 |  Val. f1: 0.72 | Val. precision: 0.73 | Val. recall: 0.71\n",
      "\n",
      "200-128-4-0.4-True\n",
      "Val. Loss: 0.353 |  Val. f1: 0.76 | Val. precision: 0.77 | Val. recall: 0.74\n",
      "\n",
      "200-128-4-0.4-False\n",
      "Val. Loss: 0.407 |  Val. f1: 0.72 | Val. precision: 0.73 | Val. recall: 0.72\n",
      "\n",
      "200-128-4-0.5-True\n",
      "Val. Loss: 0.367 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.75\n",
      "\n",
      "200-128-4-0.5-False\n",
      "Val. Loss: 0.423 |  Val. f1: 0.73 | Val. precision: 0.75 | Val. recall: 0.72\n",
      "\n",
      "200-200-3-0.4-True\n",
      "Val. Loss: 0.344 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.76\n",
      "\n",
      "200-200-3-0.4-False\n",
      "Val. Loss: 0.389 |  Val. f1: 0.75 | Val. precision: 0.78 | Val. recall: 0.73\n",
      "\n",
      "200-200-3-0.5-True\n",
      "Val. Loss: 0.348 |  Val. f1: 0.77 | Val. precision: 0.81 | Val. recall: 0.73\n",
      "\n",
      "200-200-3-0.5-False\n",
      "Val. Loss: 0.387 |  Val. f1: 0.75 | Val. precision: 0.76 | Val. recall: 0.75\n",
      "\n",
      "200-200-4-0.4-True\n",
      "Val. Loss: 0.348 |  Val. f1: 0.76 | Val. precision: 0.78 | Val. recall: 0.74\n",
      "\n",
      "200-200-4-0.4-False\n",
      "Val. Loss: 0.395 |  Val. f1: 0.73 | Val. precision: 0.73 | Val. recall: 0.73\n",
      "\n",
      "200-200-4-0.5-True\n",
      "Val. Loss: 0.356 |  Val. f1: 0.76 | Val. precision: 0.79 | Val. recall: 0.74\n",
      "\n",
      "200-200-4-0.5-False\n",
      "Val. Loss: 0.400 |  Val. f1: 0.75 | Val. precision: 0.77 | Val. recall: 0.74\n",
      "\n",
      "200-256-3-0.4-True\n",
      "Val. Loss: 0.362 |  Val. f1: 0.76 | Val. precision: 0.79 | Val. recall: 0.74\n",
      "\n",
      "200-256-3-0.4-False\n",
      "Val. Loss: 0.378 |  Val. f1: 0.75 | Val. precision: 0.78 | Val. recall: 0.72\n",
      "\n",
      "200-256-3-0.5-True\n",
      "Val. Loss: 0.348 |  Val. f1: 0.78 | Val. precision: 0.78 | Val. recall: 0.78\n",
      "\n",
      "200-256-3-0.5-False\n",
      "Val. Loss: 0.387 |  Val. f1: 0.75 | Val. precision: 0.76 | Val. recall: 0.75\n",
      "\n",
      "200-256-4-0.4-True\n",
      "Val. Loss: 0.353 |  Val. f1: 0.76 | Val. precision: 0.79 | Val. recall: 0.75\n",
      "\n",
      "200-256-4-0.4-False\n",
      "Val. Loss: 0.394 |  Val. f1: 0.74 | Val. precision: 0.75 | Val. recall: 0.73\n",
      "\n",
      "200-256-4-0.5-True\n",
      "Val. Loss: 0.354 |  Val. f1: 0.75 | Val. precision: 0.77 | Val. recall: 0.74\n",
      "\n",
      "200-256-4-0.5-False\n",
      "Val. Loss: 0.396 |  Val. f1: 0.73 | Val. precision: 0.74 | Val. recall: 0.72\n",
      "\n",
      "256-128-3-0.4-True\n",
      "Val. Loss: 0.351 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.76\n",
      "\n",
      "256-128-3-0.4-False\n",
      "Val. Loss: 0.395 |  Val. f1: 0.73 | Val. precision: 0.77 | Val. recall: 0.70\n",
      "\n",
      "256-128-3-0.5-True\n",
      "Val. Loss: 0.344 |  Val. f1: 0.76 | Val. precision: 0.77 | Val. recall: 0.75\n",
      "\n",
      "256-128-3-0.5-False\n",
      "Val. Loss: 0.402 |  Val. f1: 0.74 | Val. precision: 0.76 | Val. recall: 0.73\n",
      "\n",
      "256-128-4-0.4-True\n",
      "Val. Loss: 0.348 |  Val. f1: 0.76 | Val. precision: 0.79 | Val. recall: 0.73\n",
      "\n",
      "256-128-4-0.4-False\n",
      "Val. Loss: 0.429 |  Val. f1: 0.71 | Val. precision: 0.73 | Val. recall: 0.69\n",
      "\n",
      "256-128-4-0.5-True\n",
      "Val. Loss: 0.364 |  Val. f1: 0.78 | Val. precision: 0.80 | Val. recall: 0.76\n",
      "\n",
      "256-128-4-0.5-False\n",
      "Val. Loss: 0.417 |  Val. f1: 0.73 | Val. precision: 0.75 | Val. recall: 0.71\n",
      "\n",
      "256-200-3-0.4-True\n",
      "Val. Loss: 0.348 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.76\n",
      "\n",
      "256-200-3-0.4-False\n",
      "Val. Loss: 0.391 |  Val. f1: 0.74 | Val. precision: 0.78 | Val. recall: 0.72\n",
      "\n",
      "256-200-3-0.5-True\n",
      "Val. Loss: 0.335 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.76\n",
      "\n",
      "256-200-3-0.5-False\n",
      "Val. Loss: 0.384 |  Val. f1: 0.73 | Val. precision: 0.74 | Val. recall: 0.72\n",
      "\n",
      "256-200-4-0.4-True\n",
      "Val. Loss: 0.343 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.75\n",
      "\n",
      "256-200-4-0.4-False\n",
      "Val. Loss: 0.397 |  Val. f1: 0.72 | Val. precision: 0.75 | Val. recall: 0.70\n",
      "\n",
      "256-200-4-0.5-True\n",
      "Val. Loss: 0.349 |  Val. f1: 0.77 | Val. precision: 0.78 | Val. recall: 0.77\n",
      "\n",
      "256-200-4-0.5-False\n",
      "Val. Loss: 0.399 |  Val. f1: 0.75 | Val. precision: 0.76 | Val. recall: 0.74\n",
      "\n",
      "256-256-3-0.4-True\n",
      "Val. Loss: 0.347 |  Val. f1: 0.77 | Val. precision: 0.81 | Val. recall: 0.74\n",
      "\n",
      "256-256-3-0.4-False\n",
      "Val. Loss: 0.377 |  Val. f1: 0.73 | Val. precision: 0.77 | Val. recall: 0.69\n",
      "\n",
      "256-256-3-0.5-True\n",
      "Val. Loss: 0.333 |  Val. f1: 0.77 | Val. precision: 0.80 | Val. recall: 0.74\n",
      "\n",
      "256-256-3-0.5-False\n",
      "Val. Loss: 0.381 |  Val. f1: 0.74 | Val. precision: 0.75 | Val. recall: 0.73\n",
      "\n",
      "256-256-4-0.4-True\n",
      "Val. Loss: 0.344 |  Val. f1: 0.78 | Val. precision: 0.79 | Val. recall: 0.77\n",
      "\n",
      "256-256-4-0.4-False\n",
      "Val. Loss: 0.399 |  Val. f1: 0.74 | Val. precision: 0.75 | Val. recall: 0.73\n",
      "\n",
      "256-256-4-0.5-True\n",
      "Val. Loss: 0.349 |  Val. f1: 0.76 | Val. precision: 0.78 | Val. recall: 0.75\n",
      "\n",
      "256-256-4-0.5-False\n",
      "Val. Loss: 0.380 |  Val. f1: 0.75 | Val. precision: 0.77 | Val. recall: 0.73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_dims = [128, 200, 256]\n",
    "hidden_dims = [128, 200, 256]\n",
    "n_layers = [3, 4]\n",
    "dropouts = [0.4, 0.5]\n",
    "bi_directionals = [True, False]\n",
    "\n",
    "results = []\n",
    "\n",
    "for embedding_dim in embedding_dims:\n",
    "  for hidden_dim in hidden_dims:\n",
    "    for n_layer in n_layers:\n",
    "      for dropout in dropouts:\n",
    "        for bi_directional in bi_directionals:\n",
    "          model = NER_RNN(INPUT_DIM, embedding_dim, hidden_dim, OUTPUT_DIM,\n",
    "                          n_layer, bi_directional, dropout, PAD_IDX)\n",
    "          model_name = f\"{embedding_dim}-{hidden_dim}-{n_layer}-{dropout}-{bi_directional}\"\n",
    "\n",
    "          def init_weights(m):\n",
    "            # Inicializamos los pesos como aleatorios\n",
    "            for name, param in m.named_parameters():\n",
    "              nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "              \n",
    "              # Seteamos como 0 los embeddings de UNK y PAD.\n",
    "              model.embedding.weight.data[UNK_IDX] = torch.zeros(embedding_dim)\n",
    "              model.embedding.weight.data[PAD_IDX] = torch.zeros(embedding_dim)\n",
    "\n",
    "          model.apply(init_weights)\n",
    "          # Optimizador\n",
    "          optimizer = optim.Adam(model.parameters())\n",
    "          model = model.to(device)\n",
    "          criterion = criterion.to(device)\n",
    "\n",
    "          best_valid_loss = float('inf')\n",
    "          \n",
    "          for epoch in range(n_epochs):\n",
    "            start_time = time.time()\n",
    "            # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
    "\n",
    "            # Entrenar\n",
    "            train_loss, train_precision, train_recall, train_f1 = train(\n",
    "                model, train_iterator, optimizer, criterion)\n",
    "            \n",
    "            # Evaluar (valid = validaci√≥n)\n",
    "            valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "                model, valid_iterator, criterion)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "            \n",
    "            # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
    "            # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c√≥digo.\n",
    "            if valid_loss < best_valid_loss:\n",
    "              best_valid_loss = valid_loss\n",
    "              torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "              # Si ya no mejoramos el loss de validaci√≥n, terminamos de entrenar.\n",
    "\n",
    "          # cargar el mejor modelo entrenado.\n",
    "          model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
    "\n",
    "          # Limpiar ram de cuda\n",
    "          torch.cuda.empty_cache()\n",
    "\n",
    "          valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "              model, valid_iterator, criterion)\n",
    "          results.append(\n",
    "              {\"embedding_dim\": embedding_dim, \n",
    "               \"hidden_dim\": hidden_dim, \n",
    "               \"n_layer\": n_layer, \n",
    "               \"dropout\": dropout, \n",
    "               \"bi_directional\": bi_directional, \n",
    "               \"loss\": valid_loss, \n",
    "               \"precision\": valid_precision, \n",
    "               \"recall\": valid_recall, \n",
    "               \"f1\": valid_f1\n",
    "              }\n",
    "          )\n",
    "          print(model_name)\n",
    "          print(\n",
    "              f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "              )\n",
    "          print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4gcLL5KPIOis",
    "outputId": "99bc1afd-34cf-45f1-e85e-b0201fbc7ebe",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1ab5a9d3-dc3f-46d1-9aab-ccbf3f49a1da\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>dropout</th>\n",
       "      <th>bi_directional</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.340089</td>\n",
       "      <td>0.809261</td>\n",
       "      <td>0.773710</td>\n",
       "      <td>0.788810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.338731</td>\n",
       "      <td>0.798046</td>\n",
       "      <td>0.767236</td>\n",
       "      <td>0.780058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.348018</td>\n",
       "      <td>0.782240</td>\n",
       "      <td>0.775647</td>\n",
       "      <td>0.777070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.363783</td>\n",
       "      <td>0.795619</td>\n",
       "      <td>0.763093</td>\n",
       "      <td>0.776906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.344051</td>\n",
       "      <td>0.789822</td>\n",
       "      <td>0.767525</td>\n",
       "      <td>0.776596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400231</td>\n",
       "      <td>0.754562</td>\n",
       "      <td>0.695353</td>\n",
       "      <td>0.721228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400483</td>\n",
       "      <td>0.731793</td>\n",
       "      <td>0.712543</td>\n",
       "      <td>0.720112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.406946</td>\n",
       "      <td>0.725159</td>\n",
       "      <td>0.718274</td>\n",
       "      <td>0.719491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.411971</td>\n",
       "      <td>0.723534</td>\n",
       "      <td>0.707200</td>\n",
       "      <td>0.713498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428579</td>\n",
       "      <td>0.726466</td>\n",
       "      <td>0.693233</td>\n",
       "      <td>0.706874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows √ó 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ab5a9d3-dc3f-46d1-9aab-ccbf3f49a1da')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1ab5a9d3-dc3f-46d1-9aab-ccbf3f49a1da button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1ab5a9d3-dc3f-46d1-9aab-ccbf3f49a1da');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    embedding_dim  hidden_dim  n_layer  dropout  bi_directional      loss  \\\n",
       "18            128         256        3      0.5            True  0.340089   \n",
       "2             128         128        3      0.5            True  0.338731   \n",
       "42            200         256        3      0.5            True  0.348018   \n",
       "54            256         128        4      0.5            True  0.363783   \n",
       "68            256         256        4      0.4            True  0.344051   \n",
       "..            ...         ...      ...      ...             ...       ...   \n",
       "13            128         200        4      0.4           False  0.400231   \n",
       "27            200         128        3      0.5           False  0.400483   \n",
       "29            200         128        4      0.4           False  0.406946   \n",
       "5             128         128        4      0.4           False  0.411971   \n",
       "53            256         128        4      0.4           False  0.428579   \n",
       "\n",
       "    precision    recall        f1  \n",
       "18   0.809261  0.773710  0.788810  \n",
       "2    0.798046  0.767236  0.780058  \n",
       "42   0.782240  0.775647  0.777070  \n",
       "54   0.795619  0.763093  0.776906  \n",
       "68   0.789822  0.767525  0.776596  \n",
       "..        ...       ...       ...  \n",
       "13   0.754562  0.695353  0.721228  \n",
       "27   0.731793  0.712543  0.720112  \n",
       "29   0.725159  0.718274  0.719491  \n",
       "5    0.723534  0.707200  0.713498  \n",
       "53   0.726466  0.693233  0.706874  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results).sort_values(\"f1\", ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxujvRmi2PMU"
   },
   "source": [
    "N√≥tese que el modelo con mejor f1-score es la red que utiliza 3 capas LSTM, sus embedding tienen un dimensi√≥n de tama√±o 128, la *hidden layer* (capa LSTM) tiene un dimensi√≥n de tama√±o 256, tiene un valor para el dropout 0.5 y posee biredicionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG1Jlcs92PMV"
   },
   "source": [
    "### Modelo baseline escogiendo mejores hiperpar√°metros y cantidad de √©pocas de entrenamiento\n",
    "\n",
    "Similar a lo realizado en la secci√≥n anterior, se busc√≥ algunos de los mejores hiperpar√°metros (embedding dim, hidden dim) y la mejor cantidad de √©pocas de entrenamiento, es decir, los hiperpar√°metros y la cantidad de √©pocas de entrenamiento que maximizaran el *f1-score*. As√≠, siguiendo un procedimiento similar realizado para el modelo anterior, se calcul√≥ *loss*, *f1-score*, *precision* y *recall* para cada caso.\n",
    "\n",
    "N√≥tese que, para este caso, para no tener que entrenar una cantidad excesivamente grande de modelos, se dej√≥ fijado el n√∫mero de capas, el valor del dropout y la bidireccionalidad (los hiperpar√°metros se fijaron acorde a los resultados obtenidos anteriormente, es decir, acorde a qu√© valores ten√≠an los mejores modelos para dichos hiperpar√°metros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBN90Ie-2PMW",
    "outputId": "66f8024d-5d1e-4da9-aea1-319ae2d3c5a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128-128-15\n",
      "Val. Loss: 0.342 |  Val. f1: 0.77 | Val. precision: 0.78 | Val. recall: 0.76\n",
      "\n",
      "128-128-20\n",
      "Val. Loss: 0.357 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.76\n",
      "\n",
      "128-200-15\n",
      "Val. Loss: 0.331 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.75\n",
      "\n",
      "128-200-20\n",
      "Val. Loss: 0.338 |  Val. f1: 0.77 | Val. precision: 0.80 | Val. recall: 0.75\n",
      "\n",
      "128-256-15\n",
      "Val. Loss: 0.343 |  Val. f1: 0.77 | Val. precision: 0.81 | Val. recall: 0.73\n",
      "\n",
      "128-256-20\n",
      "Val. Loss: 0.337 |  Val. f1: 0.76 | Val. precision: 0.79 | Val. recall: 0.74\n",
      "\n",
      "200-128-15\n",
      "Val. Loss: 0.356 |  Val. f1: 0.76 | Val. precision: 0.80 | Val. recall: 0.72\n",
      "\n",
      "200-128-20\n",
      "Val. Loss: 0.362 |  Val. f1: 0.77 | Val. precision: 0.79 | Val. recall: 0.77\n",
      "\n",
      "200-200-15\n",
      "Val. Loss: 0.341 |  Val. f1: 0.78 | Val. precision: 0.79 | Val. recall: 0.76\n",
      "\n",
      "200-200-20\n",
      "Val. Loss: 0.338 |  Val. f1: 0.78 | Val. precision: 0.79 | Val. recall: 0.77\n",
      "\n",
      "200-256-15\n",
      "Val. Loss: 0.337 |  Val. f1: 0.78 | Val. precision: 0.80 | Val. recall: 0.76\n",
      "\n",
      "200-256-20\n",
      "Val. Loss: 0.341 |  Val. f1: 0.77 | Val. precision: 0.80 | Val. recall: 0.75\n",
      "\n",
      "256-128-15\n",
      "Val. Loss: 0.358 |  Val. f1: 0.77 | Val. precision: 0.77 | Val. recall: 0.77\n",
      "\n",
      "256-128-20\n",
      "Val. Loss: 0.344 |  Val. f1: 0.77 | Val. precision: 0.80 | Val. recall: 0.74\n",
      "\n",
      "256-200-15\n",
      "Val. Loss: 0.354 |  Val. f1: 0.78 | Val. precision: 0.81 | Val. recall: 0.75\n",
      "\n",
      "256-200-20\n",
      "Val. Loss: 0.335 |  Val. f1: 0.77 | Val. precision: 0.78 | Val. recall: 0.76\n",
      "\n",
      "256-256-15\n",
      "Val. Loss: 0.334 |  Val. f1: 0.77 | Val. precision: 0.78 | Val. recall: 0.77\n",
      "\n",
      "256-256-20\n",
      "Val. Loss: 0.342 |  Val. f1: 0.76 | Val. precision: 0.78 | Val. recall: 0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = [128, 200, 256]\n",
    "hidden_dims = [128, 200, 256]\n",
    "n_epochs = [15, 20]\n",
    "\n",
    "results = []\n",
    "\n",
    "for embedding_dim in embedding_dims:\n",
    "    for hidden_dim in hidden_dims:\n",
    "        for n_epoch in n_epochs:\n",
    "            model = NER_RNN(INPUT_DIM, embedding_dim, hidden_dim, OUTPUT_DIM,\n",
    "                            3, True, 0.5, PAD_IDX)\n",
    "            model_name = f\"{embedding_dim}-{hidden_dim}-{n_epoch}\"\n",
    "            \n",
    "            def init_weights(m):\n",
    "                # Inicializamos los pesos como aleatorios\n",
    "                for name, param in m.named_parameters():\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "                    \n",
    "                    # Seteamos como 0 los embeddings de UNK y PAD.\n",
    "                    model.embedding.weight.data[UNK_IDX] = torch.zeros(embedding_dim)\n",
    "                    model.embedding.weight.data[PAD_IDX] = torch.zeros(embedding_dim)\n",
    "            \n",
    "            model.apply(init_weights)\n",
    "            # Optimizador\n",
    "            optimizer = optim.Adam(model.parameters())\n",
    "            model = model.to(device)\n",
    "            criterion = criterion.to(device)\n",
    "            \n",
    "            best_valid_loss = float('inf')\n",
    "            \n",
    "            for epoch in range(n_epoch):\n",
    "                start_time = time.time()\n",
    "                # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
    "                \n",
    "                # Entrenar\n",
    "                train_loss, train_precision, train_recall, train_f1 = train(\n",
    "                    model, train_iterator, optimizer, criterion)\n",
    "                \n",
    "                # Evaluar (valid = validaci√≥n)\n",
    "                valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "                    model, valid_iterator, criterion)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "            \n",
    "                # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
    "                # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c√≥digo.\n",
    "                if valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "                # Si ya no mejoramos el loss de validaci√≥n, terminamos de entrenar.\n",
    "            \n",
    "            # cargar el mejor modelo entrenado.\n",
    "            model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
    "\n",
    "            # Limpiar ram de cuda\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "                model, valid_iterator, criterion)\n",
    "            results.append(\n",
    "                {\n",
    "                    \"embedding_dim\": embedding_dim, \n",
    "                    \"hidden_dim\": hidden_dim, \n",
    "                    \"n_epoch\": n_epoch,\n",
    "                    \"loss\": valid_loss, \n",
    "                    \"precision\": valid_precision, \n",
    "                    \"recall\": valid_recall, \n",
    "                    \"f1\": valid_f1\n",
    "                }\n",
    "            )\n",
    "            print(model_name)\n",
    "            print(\n",
    "                f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "            )\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "id": "R-xCdSg_2PMX",
    "outputId": "7140d077-6e2a-4c90-fb47-d70c8bd1670c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-acfadc6d-8fc2-47db-93da-d9a62908ba85\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.338304</td>\n",
       "      <td>0.793715</td>\n",
       "      <td>0.766753</td>\n",
       "      <td>0.777908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td>0.354253</td>\n",
       "      <td>0.806481</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.777662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>15</td>\n",
       "      <td>0.336663</td>\n",
       "      <td>0.798876</td>\n",
       "      <td>0.757950</td>\n",
       "      <td>0.775592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td>0.340753</td>\n",
       "      <td>0.793823</td>\n",
       "      <td>0.762109</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>0.361722</td>\n",
       "      <td>0.789339</td>\n",
       "      <td>0.765319</td>\n",
       "      <td>0.774955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>0.357079</td>\n",
       "      <td>0.793851</td>\n",
       "      <td>0.755611</td>\n",
       "      <td>0.772169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>0.341390</td>\n",
       "      <td>0.796934</td>\n",
       "      <td>0.752001</td>\n",
       "      <td>0.771487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>15</td>\n",
       "      <td>0.334235</td>\n",
       "      <td>0.778374</td>\n",
       "      <td>0.765669</td>\n",
       "      <td>0.769943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.335145</td>\n",
       "      <td>0.784965</td>\n",
       "      <td>0.759378</td>\n",
       "      <td>0.769188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.341908</td>\n",
       "      <td>0.778514</td>\n",
       "      <td>0.763791</td>\n",
       "      <td>0.768711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>0.795021</td>\n",
       "      <td>0.745225</td>\n",
       "      <td>0.767511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>0.344326</td>\n",
       "      <td>0.796230</td>\n",
       "      <td>0.744378</td>\n",
       "      <td>0.767386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td>0.331022</td>\n",
       "      <td>0.791422</td>\n",
       "      <td>0.749671</td>\n",
       "      <td>0.767330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.358311</td>\n",
       "      <td>0.769340</td>\n",
       "      <td>0.768445</td>\n",
       "      <td>0.767170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>15</td>\n",
       "      <td>0.342583</td>\n",
       "      <td>0.810382</td>\n",
       "      <td>0.729828</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>0.337420</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.739793</td>\n",
       "      <td>0.761650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>0.341649</td>\n",
       "      <td>0.779118</td>\n",
       "      <td>0.745836</td>\n",
       "      <td>0.760040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>15</td>\n",
       "      <td>0.356308</td>\n",
       "      <td>0.799365</td>\n",
       "      <td>0.722753</td>\n",
       "      <td>0.757228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acfadc6d-8fc2-47db-93da-d9a62908ba85')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-acfadc6d-8fc2-47db-93da-d9a62908ba85 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-acfadc6d-8fc2-47db-93da-d9a62908ba85');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    embedding_dim  hidden_dim  n_epoch      loss  precision    recall  \\\n",
       "9             200         200       20  0.338304   0.793715  0.766753   \n",
       "14            256         200       15  0.354253   0.806481  0.754923   \n",
       "10            200         256       15  0.336663   0.798876  0.757950   \n",
       "8             200         200       15  0.340753   0.793823  0.762109   \n",
       "7             200         128       20  0.361722   0.789339  0.765319   \n",
       "1             128         128       20  0.357079   0.793851  0.755611   \n",
       "11            200         256       20  0.341390   0.796934  0.752001   \n",
       "16            256         256       15  0.334235   0.778374  0.765669   \n",
       "15            256         200       20  0.335145   0.784965  0.759378   \n",
       "0             128         128       15  0.341908   0.778514  0.763791   \n",
       "3             128         200       20  0.338364   0.795021  0.745225   \n",
       "13            256         128       20  0.344326   0.796230  0.744378   \n",
       "2             128         200       15  0.331022   0.791422  0.749671   \n",
       "12            256         128       15  0.358311   0.769340  0.768445   \n",
       "4             128         256       15  0.342583   0.810382  0.729828   \n",
       "5             128         256       20  0.337420   0.790554  0.739793   \n",
       "17            256         256       20  0.341649   0.779118  0.745836   \n",
       "6             200         128       15  0.356308   0.799365  0.722753   \n",
       "\n",
       "          f1  \n",
       "9   0.777908  \n",
       "14  0.777662  \n",
       "10  0.775592  \n",
       "8   0.775510  \n",
       "7   0.774955  \n",
       "1   0.772169  \n",
       "11  0.771487  \n",
       "16  0.769943  \n",
       "15  0.769188  \n",
       "0   0.768711  \n",
       "3   0.767511  \n",
       "13  0.767386  \n",
       "2   0.767330  \n",
       "12  0.767170  \n",
       "4   0.765192  \n",
       "5   0.761650  \n",
       "17  0.760040  \n",
       "6   0.757228  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results).sort_values(\"f1\", ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Am1O6NWkhozC"
   },
   "source": [
    "En este caso, el modelo con mejor f1-score es la red que utiliza 3 capas LSTM, sus embedding tienen un dimensi√≥n de tama√±o 200, la *hidden layer* (capa LSTM) tiene un dimensi√≥n de tama√±o 200, tiene un valor para el dropout 0.5, posee biredicionalidad y la cantidad de √©pocas de entrenamiento es 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k38uRNKEhozD"
   },
   "source": [
    "### Mejores modelos variando optimizador y learning rate:\n",
    "\n",
    "Dado los dos mejores modelos obtenidos en las dos b√∫squedas mediantes *grid search*, se utilizar√° dichos modelos para realizar otra *grid search* que vari√© el optimizador y el learning rate. As√≠, siguiendo un procedimiento similar realizado para las b√∫squedas anteriores, se calcul√≥ *loss*, *f1-score*, *precision* y *recall* para cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgC85f9ahozD",
    "outputId": "39be476b-c84e-4fee-f7a3-0244d5cbe6df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128-256-10-<class 'torch.optim.adam.Adam'>-0.01\n",
      "Val. Loss: 0.377 |  Val. f1: 0.74 | Val. precision: 0.76 | Val. recall: 0.72\n",
      "\n",
      "128-256-10-<class 'torch.optim.adam.Adam'>-0.001\n",
      "Val. Loss: 0.349 |  Val. f1: 0.77 | Val. precision: 0.78 | Val. recall: 0.76\n",
      "\n",
      "128-256-10-<class 'torch.optim.adam.Adam'>-0.0001\n",
      "Val. Loss: 0.495 |  Val. f1: 0.63 | Val. precision: 0.74 | Val. recall: 0.55\n",
      "\n",
      "128-256-10-<class 'torch.optim.sgd.SGD'>-0.01\n",
      "Val. Loss: 0.980 |  Val. f1: 0.26 | Val. precision: 0.49 | Val. recall: 0.18\n",
      "\n",
      "128-256-10-<class 'torch.optim.sgd.SGD'>-0.001\n",
      "Val. Loss: 1.159 |  Val. f1: 0.00 | Val. precision: 0.00 | Val. recall: 0.00\n",
      "\n",
      "128-256-10-<class 'torch.optim.sgd.SGD'>-0.0001\n",
      "Val. Loss: 1.218 |  Val. f1: 0.00 | Val. precision: 0.00 | Val. recall: 0.00\n",
      "\n",
      "200-200-20-<class 'torch.optim.adam.Adam'>-0.01\n",
      "Val. Loss: 0.397 |  Val. f1: 0.73 | Val. precision: 0.75 | Val. recall: 0.72\n",
      "\n",
      "200-200-20-<class 'torch.optim.adam.Adam'>-0.001\n",
      "Val. Loss: 0.355 |  Val. f1: 0.77 | Val. precision: 0.78 | Val. recall: 0.76\n",
      "\n",
      "200-200-20-<class 'torch.optim.adam.Adam'>-0.0001\n",
      "Val. Loss: 0.397 |  Val. f1: 0.73 | Val. precision: 0.77 | Val. recall: 0.70\n",
      "\n",
      "200-200-20-<class 'torch.optim.sgd.SGD'>-0.01\n",
      "Val. Loss: 0.910 |  Val. f1: 0.32 | Val. precision: 0.58 | Val. recall: 0.23\n",
      "\n",
      "200-200-20-<class 'torch.optim.sgd.SGD'>-0.001\n",
      "Val. Loss: 1.126 |  Val. f1: 0.00 | Val. precision: 0.00 | Val. recall: 0.00\n",
      "\n",
      "200-200-20-<class 'torch.optim.sgd.SGD'>-0.0001\n",
      "Val. Loss: 1.235 |  Val. f1: 0.00 | Val. precision: 0.00 | Val. recall: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ModelParams:\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_epoch):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_epoch = n_epoch\n",
    "        self.name = f\"{embedding_dim}-{hidden_dim}-{n_epoch}\"\n",
    "\n",
    "p_models = [ModelParams(128, 256, 10), ModelParams(200, 200, 20)]\n",
    "f_optimizers = [optim.Adam, optim.SGD]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for p_model in p_models:\n",
    "    for f_optimizer in f_optimizers:\n",
    "        for learning_rate in learning_rates:\n",
    "            n_epoch = p_model.n_epoch\n",
    "            \n",
    "            model = NER_RNN(INPUT_DIM, p_model.embedding_dim, p_model.hidden_dim, OUTPUT_DIM,\n",
    "                            3, True, 0.5, PAD_IDX)\n",
    "            model_name = f\"{p_model.name}-{f_optimizer}-{learning_rate}\"\n",
    "            \n",
    "            def init_weights(m):\n",
    "                # Inicializamos los pesos como aleatorios\n",
    "                for name, param in m.named_parameters():\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "                    \n",
    "                    # Seteamos como 0 los embeddings de UNK y PAD.\n",
    "                    model.embedding.weight.data[UNK_IDX] = torch.zeros(p_model.embedding_dim)\n",
    "                    model.embedding.weight.data[PAD_IDX] = torch.zeros(p_model.embedding_dim)\n",
    "            \n",
    "            model.apply(init_weights)\n",
    "            # Optimizador\n",
    "            optimizer = f_optimizer(model.parameters(), lr=learning_rate)\n",
    "            model = model.to(device)\n",
    "            criterion = criterion.to(device)\n",
    "            \n",
    "            best_valid_loss = float('inf')\n",
    "            \n",
    "            for epoch in range(p_model.n_epoch):\n",
    "                start_time = time.time()\n",
    "                # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
    "                \n",
    "                # Entrenar\n",
    "                train_loss, train_precision, train_recall, train_f1 = train(\n",
    "                    model, train_iterator, optimizer, criterion)\n",
    "                \n",
    "                # Evaluar (valid = validaci√≥n)\n",
    "                valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "                    model, valid_iterator, criterion)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "            \n",
    "                # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
    "                # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c√≥digo.\n",
    "                if valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "                # Si ya no mejoramos el loss de validaci√≥n, terminamos de entrenar.\n",
    "            \n",
    "            # cargar el mejor modelo entrenado.\n",
    "            model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
    "\n",
    "            # Limpiar ram de cuda\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "                model, valid_iterator, criterion)\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model_name\": p_model.name, \n",
    "                    \"optimizer\": f_optimizer, \n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"loss\": valid_loss, \n",
    "                    \"precision\": valid_precision, \n",
    "                    \"recall\": valid_recall, \n",
    "                    \"f1\": valid_f1\n",
    "                }\n",
    "            )\n",
    "            print(model_name)\n",
    "            print(\n",
    "                f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "            )\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "RZX_B9GIhozE",
    "outputId": "1b714107-9132-40ef-d1ee-c295d741f8f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-87716eeb-4d05-4e2c-a42b-c454a2d62931\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128-256-10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.348921</td>\n",
       "      <td>0.782067</td>\n",
       "      <td>0.762674</td>\n",
       "      <td>0.769946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200-200-20</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.355335</td>\n",
       "      <td>0.777800</td>\n",
       "      <td>0.762061</td>\n",
       "      <td>0.767723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128-256-10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.377106</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.717570</td>\n",
       "      <td>0.738195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200-200-20</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.396620</td>\n",
       "      <td>0.772737</td>\n",
       "      <td>0.702574</td>\n",
       "      <td>0.733675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200-200-20</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.397191</td>\n",
       "      <td>0.745995</td>\n",
       "      <td>0.723456</td>\n",
       "      <td>0.732899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128-256-10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.495256</td>\n",
       "      <td>0.742010</td>\n",
       "      <td>0.552388</td>\n",
       "      <td>0.630273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200-200-20</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.910128</td>\n",
       "      <td>0.581795</td>\n",
       "      <td>0.225890</td>\n",
       "      <td>0.319024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128-256-10</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.979735</td>\n",
       "      <td>0.491899</td>\n",
       "      <td>0.175266</td>\n",
       "      <td>0.255771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128-256-10</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.158531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128-256-10</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.217621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200-200-20</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.126306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200-200-20</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.234608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87716eeb-4d05-4e2c-a42b-c454a2d62931')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-87716eeb-4d05-4e2c-a42b-c454a2d62931 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-87716eeb-4d05-4e2c-a42b-c454a2d62931');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    model_name                        optimizer  learning_rate      loss  \\\n",
       "1   128-256-10  <class 'torch.optim.adam.Adam'>         0.0010  0.348921   \n",
       "7   200-200-20  <class 'torch.optim.adam.Adam'>         0.0010  0.355335   \n",
       "0   128-256-10  <class 'torch.optim.adam.Adam'>         0.0100  0.377106   \n",
       "8   200-200-20  <class 'torch.optim.adam.Adam'>         0.0001  0.396620   \n",
       "6   200-200-20  <class 'torch.optim.adam.Adam'>         0.0100  0.397191   \n",
       "2   128-256-10  <class 'torch.optim.adam.Adam'>         0.0001  0.495256   \n",
       "9   200-200-20    <class 'torch.optim.sgd.SGD'>         0.0100  0.910128   \n",
       "3   128-256-10    <class 'torch.optim.sgd.SGD'>         0.0100  0.979735   \n",
       "4   128-256-10    <class 'torch.optim.sgd.SGD'>         0.0010  1.158531   \n",
       "5   128-256-10    <class 'torch.optim.sgd.SGD'>         0.0001  1.217621   \n",
       "10  200-200-20    <class 'torch.optim.sgd.SGD'>         0.0010  1.126306   \n",
       "11  200-200-20    <class 'torch.optim.sgd.SGD'>         0.0001  1.234608   \n",
       "\n",
       "    precision    recall        f1  \n",
       "1    0.782067  0.762674  0.769946  \n",
       "7    0.777800  0.762061  0.767723  \n",
       "0    0.764000  0.717570  0.738195  \n",
       "8    0.772737  0.702574  0.733675  \n",
       "6    0.745995  0.723456  0.732899  \n",
       "2    0.742010  0.552388  0.630273  \n",
       "9    0.581795  0.225890  0.319024  \n",
       "3    0.491899  0.175266  0.255771  \n",
       "4    0.000000  0.000000  0.000000  \n",
       "5    0.000000  0.000000  0.000000  \n",
       "10   0.000000  0.000000  0.000000  \n",
       "11   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results).sort_values(\"f1\", ascending=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo con mejor f1-score es la red que utiliza 3 capas LSTM, sus embedding tienen un dimensi√≥n de tama√±o 128, la *hidden layer* (capa LSTM) tiene un dimensi√≥n de tama√±o 256, tiene un valor para el dropout 0.5, posee biredicionalidad, tiene un algoritmo optimizador Adam y un learning rate de 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejor modelo.\n",
    "\n",
    "Finalmente, se entrenar√° el mejor modelo obtenido para generar las predicciones para la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46Jwpv81hozE",
    "outputId": "aca5dd07-aa80-4e2f-bac3-edcf0036e4fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo actual tiene 6,202,252 par√°metros entrenables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <pad> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.857 | Train f1: 0.38 | Train precision: 0.57 | Train recall: 0.30\n",
      "\t Val. Loss: 0.557 |  Val. f1: 0.59 |  Val. precision: 0.73 | Val. recall: 0.50\n",
      "Epoch: 02 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.491 | Train f1: 0.66 | Train precision: 0.74 | Train recall: 0.60\n",
      "\t Val. Loss: 0.415 |  Val. f1: 0.70 |  Val. precision: 0.79 | Val. recall: 0.63\n",
      "Epoch: 03 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.340 | Train f1: 0.76 | Train precision: 0.80 | Train recall: 0.72\n",
      "\t Val. Loss: 0.368 |  Val. f1: 0.74 |  Val. precision: 0.78 | Val. recall: 0.71\n",
      "Epoch: 04 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.265 | Train f1: 0.81 | Train precision: 0.83 | Train recall: 0.79\n",
      "\t Val. Loss: 0.357 |  Val. f1: 0.76 |  Val. precision: 0.77 | Val. recall: 0.76\n",
      "Epoch: 05 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.209 | Train f1: 0.85 | Train precision: 0.85 | Train recall: 0.84\n",
      "\t Val. Loss: 0.355 |  Val. f1: 0.76 |  Val. precision: 0.81 | Val. recall: 0.72\n",
      "Epoch: 06 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.174 | Train f1: 0.87 | Train precision: 0.88 | Train recall: 0.87\n",
      "\t Val. Loss: 0.348 |  Val. f1: 0.78 |  Val. precision: 0.81 | Val. recall: 0.76\n",
      "Epoch: 07 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.150 | Train f1: 0.89 | Train precision: 0.90 | Train recall: 0.89\n",
      "\t Val. Loss: 0.356 |  Val. f1: 0.78 |  Val. precision: 0.80 | Val. recall: 0.76\n",
      "Epoch: 08 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.128 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.90\n",
      "\t Val. Loss: 0.365 |  Val. f1: 0.78 |  Val. precision: 0.81 | Val. recall: 0.76\n",
      "Epoch: 09 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.113 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.92\n",
      "\t Val. Loss: 0.368 |  Val. f1: 0.79 |  Val. precision: 0.80 | Val. recall: 0.78\n",
      "Epoch: 10 | Epoch Time: 0m 11s\n",
      "\tTrain Loss: 0.099 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.93\n",
      "\t Val. Loss: 0.380 |  Val. f1: 0.78 |  Val. precision: 0.79 | Val. recall: 0.78\n"
     ]
    }
   ],
   "source": [
    "# tama√±o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 128 # dimensi√≥n de los embeddings.\n",
    "HIDDEN_DIM = 256  # dimensi√≥n de la capas LSTM\n",
    "OUTPUT_DIM = len(NER_TAGS.vocab)  # n√∫mero de clases\n",
    "\n",
    "N_LAYERS = 3  # n√∫mero de capas.\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "# Creamos nuestro modelo.\n",
    "best_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
    "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "\n",
    "best_model_name = 'best'  # nombre que tendr√° el modelo guardado...\n",
    "\n",
    "best_n_epochs = 10\n",
    "# Loss: Cross Entropy\n",
    "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "best_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "model = best_model\n",
    "model_name = best_model_name\n",
    "criterion = best_criterion\n",
    "n_epochs = best_n_epochs\n",
    "\n",
    "def init_weights(m):\n",
    "    # Inicializamos los pesos como aleatorios\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "        \n",
    "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'El modelo actual tiene {count_parameters(model):,} par√°metros entrenables.')\n",
    "# Optimizador\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# Enviamos el modelo y la loss a cuda (en el caso en que est√© disponible)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
    "\n",
    "    # Entrenar\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(\n",
    "        model, train_iterator, optimizer, criterion)\n",
    "\n",
    "    # Evaluar (valid = validaci√≥n)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "        model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
    "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c√≥digo.\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "    # Si ya no mejoramos el loss de validaci√≥n, terminamos de entrenar.\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(\n",
    "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
    "    )\n",
    "    print(\n",
    "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Y5yYkUMuHpv",
    "outputId": "563bb437-810c-48a9-f4c2-e74b3bfae6de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. Loss: 0.348 |  Val. f1: 0.78 | Val. precision: 0.81 | Val. recall: 0.76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cargar el mejor modelo entrenado.\n",
    "model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
    "\n",
    "# Limpiar ram de cuda\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "    model, valid_iterator, criterion)\n",
    "print(\n",
    "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47lRKD0uhozE"
   },
   "source": [
    "### **Predecir datos para la competencia**\n",
    "\n",
    "Ahora, a partir de los datos de **test** y nuestro modelo entrenado, vamos a predecir las etiquetas que ser√°n evaluadas en la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "1RBs3UU4wLk3"
   },
   "outputs": [],
   "source": [
    "def predict_labels(model, iterator, criterion, fields=fields):\n",
    "\n",
    "    # Extraemos los vocabularios.\n",
    "    text_field = fields[0][1]\n",
    "    nertags_field = fields[1][1]\n",
    "    tags_vocab = nertags_field.vocab.itos\n",
    "    words_vocab = text_field.vocab.itos\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            text_batch = batch.text\n",
    "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
    "\n",
    "            # Predecir los tags de las sentences del batch\n",
    "            predictions_batch = model(batch.text)\n",
    "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
    "\n",
    "            # por cada oraci√≥n predicha:\n",
    "            for sentence, sentence_prediction in zip(text_batch,\n",
    "                                                     predictions_batch):\n",
    "                for word_idx, word_predictions in zip(sentence,\n",
    "                                                      sentence_prediction):\n",
    "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
    "                    argmax_index = word_predictions.topk(1)[1]\n",
    "\n",
    "                    current_tag = tags_vocab[argmax_index]\n",
    "                    # Obtenemos la palabra\n",
    "                    current_word = words_vocab[word_idx]\n",
    "\n",
    "                    if current_word != '<pad>':\n",
    "                        predictions.append([current_word, current_tag])\n",
    "                predictions.append(['EOS', 'EOS'])\n",
    "\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predictions = predict_labels(model, test_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcmEqmemHqJD"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwQp1Ru8Oht8"
   },
   "source": [
    "### **Generar el archivo para la submission**\n",
    "\n",
    "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "RPfZkjJGkWyq"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "if (os.path.isfile('./predictions.zip')):\n",
    "    os.remove('./predictions.zip')\n",
    "\n",
    "if (not os.path.isdir('./predictions')):\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "else:\n",
    "    # Eliminar predicciones anteriores:\n",
    "    shutil.rmtree('./predictions')\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "f = open('predictions/predictions.txt', 'w')\n",
    "for i, (word, tag) in enumerate(predictions[:-1]):\n",
    "    if word=='EOS' and tag=='EOS': f.write('\\n')\n",
    "    else: \n",
    "      if i == len(predictions[:-1])-1:\n",
    "        f.write(word + ' ' + tag)\n",
    "      else: f.write(word + ' ' + tag + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "a = shutil.make_archive('predictions', 'zip', './predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZEWJXrNaSIf"
   },
   "source": [
    "## **Conclusiones**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAtK7y43V7Z_"
   },
   "source": [
    " Respecto a los resultados obtenidos con los modelos entrenados, se tiene que la red *RNN* con las siguientes caracter√≠sticas fue la que obtuvo mejores resultados:\n",
    "- Dimensi√≥n de capa embedding: *128*\n",
    "- Tipo de capas intermedias: *LSTM*\n",
    "- N√∫mero de capas LSTM: *3*\n",
    "- Dimensi√≥n de capas LSTM: *256*\n",
    "- Dimensi√≥n output: *12*\n",
    "- Tama√±o de los batches: *22*\n",
    "- Funci√≥n de p√©rdida: *Cross entropy loss*\n",
    "- Algormito optimizador: *Adam*\n",
    "- Learning rate: 0.001\n",
    "- Bireccionalidad: *Posee*\n",
    "- Valor dropout: *0.5*\n",
    "- Cantidad de √©pocas de entrenamiento: *10*\n",
    "\n",
    "En particular, dicha red obtuvo los siguientes valores para cada m√©trica:\n",
    "- Precision: *0.809261*\n",
    "- Recall: *0.773710*\n",
    "- F1: *0.788810*\n",
    "\n",
    "valores que superan al modelo baseline entregado inicialmente.\n",
    "\n",
    "N√≥tese que, en el presente trabajo, la mejora del modelo se realiz√≥, b√°sicamente, mediante la b√∫squeda de mejores hiperpar√°metros a trav√©s *grid search* con *grillas* de un tama√±o peque√±o. En ese sentido, una simple mejora para realizar una b√∫squeda m√°s completa es utilizar *grillas* m√°s grandes, es decir, probar distintos modelos con variados hiperpar√°metros. Lo anterior permite b√∫squeda m√°s completa de mejores modelos pero aumenta el costo y tiempo de procesamiento.\n",
    "\n",
    "Otra forma de mejorar la b√∫squeda es probar modelos con distintas arquitecturas o distintos embeddings. En ese sentido, es importante destacar que uno de los mayores aprendizajes del presente trabajo fue conocer y explorar la complejidad de una red neuronal: encontrar el modelo que mejor resuelva un *problema* es una tarea tit√°nica que puede suponer mucho esfuerzo y trabajo. De todas formas, las redes neuronales permiten encontrar soluciones decentes y/o buenas con una cantidad razonable de trabajo (los mayores esfuerzos se hayan en encontrar la mejor o las mejores redes que resuelvan el problema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "AaVhZ5iaaSFK",
    "u27WffRVUj4v"
   ],
   "name": "Competencia2_CC6205.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
