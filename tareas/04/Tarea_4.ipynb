{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwaDuQqCOyLJ"
   },
   "source": [
    "# **Tarea 4 - CC6205 Natural Language Processing üìö**\n",
    "\n",
    "**Integrantes:** Nicol√°s Lemu√±ir y Mat√≠as Seda\n",
    "\n",
    "**Fecha l√≠mite de entrega üìÜ:** Martes 07 de junio.\n",
    "\n",
    "**Tiempo estimado de dedicaci√≥n:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4lL5hGw07yP"
   },
   "source": [
    "Bienvenid@s a la cuarta tarea del curso de Natural Language Processing (NLP). \n",
    "En esta tarea estaremos tratando el problema de **tagging** (generaci√≥n de secuencias de etiquetas del mismo largo que la secuencia de input), el uso de **Convolutional Neural Networks** y **Recurrent Neural Networks**, e implementaremos una red usando PyTorch. \n",
    "\n",
    "Usen $\\LaTeX$ para las f√≥rmulas matem√°ticas. En la parte de programaci√≥n pueden usar lo que quieran, pero la [Auxiliar 3](https://youtu.be/36WTXvg3zh0) les puede ser de *gran ayuda*.\n",
    "\n",
    "**Instrucciones:**\n",
    "- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
    "- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
    "- El formato de entrega es este mismo Jupyter Notebook.\n",
    "- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n.\n",
    "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav√©s del canal de Discord del curso.\n",
    "\n",
    "Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n",
    "\n",
    "**Referencias:**\n",
    "\n",
    "- [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/Tjgb-yQOg54), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
    "- [MEMMs and CRFs](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CRF.pdf): [notes 1](http://www.cs.columbia.edu/~mcollins/crf.pdf), [notes 2](http://www.cs.columbia.edu/~mcollins/fb.pdf), [video 1](https://youtu.be/qlI-4lSUDkg), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/ZpUwDy6o28Y)\n",
    "- [Convolutional Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CNN.pdf): [video](https://youtu.be/lLZW5Fn40r8)\n",
    "- [Recurrent Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-RNN.pdf): [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANqzQ3G9WNw3"
   },
   "source": [
    "# Hidden Markov Models (HMM), Maximum Entropy Markov Models (MEMM) and Conditional Random Field(CRF) (1,5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWXD3D7RYKJ-"
   },
   "source": [
    "### Pregunta 1 (1 pt)\n",
    "Para un problema de POS tagging se define el conjunto de etiquetas $S = \\{ \\text{DET}, \\text{NOUN}, \\text{VERB}, \\text{ADP} \\}$ y se tiene un Hidden Markov Model con los siguientes par√°metros estimados a partir de un corpus de entrenamiento:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "q(\\text{NOUN}| \\text{ VERB}, \\text{DET}) &= 0.3 \\\\\n",
    "q(\\text{NOUN}|\\ w, \\text{DET}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
    "q(\\text{DET}| \\text{ VERB}, \\text{NOUN}) &= 0.4 \\\\\n",
    "q(\\text{DET}|\\ w, \\text{NOUN}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
    "e(the|\\text{ DET}) &= 0.5 \\\\\n",
    "e(pasta|\\text{ NOUN}) &= 0.6\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Luego para la oraci√≥n: `the man is pouring sauce on the pasta`, se tiene una tabla de programaci√≥n din√°mica con los siguientes valores:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\pi(7,\\text{DET},\\text{DET})&=0.1\\\\\n",
    "\\pi(7,\\text{NOUN},\\text{DET})&=0.2\\\\\n",
    "\\pi(7,\\text{VERB},\\text{DET})&=0.01\\\\\n",
    "\\pi(7,\\text{ADP},\\text{DET})&=0.5\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Con esta informaci√≥n, calcule el valor de $\\pi(8,\\text{DET},\\text{NOUN})$. Puede dejar el resultado expresado como una fracci√≥n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EzgysW9kGi-"
   },
   "source": [
    "**Respuesta**\n",
    "\n",
    "Por definici√≥n, se tiene que $\\pi(8,\\text{DET},\\text{NOUN})$ viene dado por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\pi(8,\\text{DET},\\text{NOUN}) = \\max_{w \\in S_{6}} (\\pi(7,w,\\text{DET}) \\cdot q(\\text{NOUN} | w, \\text{DET}) \\cdot e(x_{8} | \\text{NOUN}))\n",
    "\\end{equation}\n",
    "\n",
    "donde $x_{8}$ es la octava palabra de la oraci√≥n `the man is pouring sauce on the pasta`, es decir, $x_{8} = \\text{pasta}$ y $S_{6} = \\{ \\text{DET}, \\text{NOUN}, \\text{VERB},  \\text{ADP} \\}$.\n",
    "\n",
    "Ahora, los valores para la expresi√≥n $\\pi(7,w,\\text{DET}) \\cdot q(\\text{NOUN} | w, \\text{DET}) \\cdot e(x_{8} | \\text{NOUN})$ en funci√≥n de los posibles valores para $w$ son los siguientes:\n",
    "\n",
    "- $w=\\text{DET}$: \n",
    "\\begin{equation}\n",
    "\\pi(7,\\text{DET},\\text{DET}) \\cdot q(\\text{NOUN} | \\text{DET}, \\text{DET}) \\cdot e(\\text{pasta} | \\text{NOUN}) = 0.1 \\cdot 0 \\cdot 0.6 = 0\n",
    "\\end{equation}\n",
    "\n",
    "- $w=\\text{NOUN}$: \n",
    "\\begin{equation}\n",
    "\\pi(7,\\text{NOUN},\\text{DET}) \\cdot q(\\text{NOUN} | \\text{NOUN}, \\text{DET}) \\cdot e(\\text{pasta} | \\text{NOUN}) = 0.2 \\cdot 0 \\cdot 0.6 = 0\n",
    "\\end{equation}\n",
    "\n",
    "- $w=\\text{VERB}$: \n",
    "\\begin{equation} \n",
    "\\pi(7,\\text{VERB},\\text{DET}) \\cdot q(\\text{NOUN} | \\text{VERB}, \\text{DET}) \\cdot e(\\text{pasta} | \\text{NOUN}) = 0.01 \\cdot 0.3 \\cdot 0.6 = 0.018\n",
    "\\end{equation}\n",
    "\n",
    "- $w=\\text{ADP}$: \n",
    "\\begin{equation} \n",
    "\\pi(7,\\text{ADP},\\text{DET}) \\cdot q(\\text{NOUN} | \\text{ADP}, \\text{DET}) \\cdot e(\\text{pasta} | \\text{NOUN}) = 0.5 \\cdot 0 \\cdot 0.6 = 0\n",
    "\\end{equation}\n",
    "\n",
    "Luego, se tiene que \n",
    "\\begin{equation}\n",
    "\\pi(8,\\text{DET},\\text{NOUN}) = 0.018\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiwJb_vmkKLZ"
   },
   "source": [
    "### Pregunta 2 (0.5 pts)\n",
    "Comente  sobre las similitudes o diferencias entre los HMMs, MEMMs y CRFs. Para esto, responda las siguientes preguntas.\n",
    "\n",
    "#### 2.1. ¬øPara qu√© tipo de tarea sirven? D√© dos ejemplo de este tipo de tarea y descr√≠balos brevemente. (0.1 pts)\n",
    "\n",
    "**Respuesta:** \n",
    "\n",
    "Los modelos HMMS, MEMMs y CRFs sirven para etiquetar textos o, m√°s general, asignar etiquetas discretas a elementos discretos. Por ejemplo, tareas de etiquetado como *part-of-speech tagging (POS)* o *Named Entity Recognition (NER)* son tareas que pueden realizar los modelos HMMS, MEMMs y CRF. En particular, respecto al objetivo de las tareas mencionadas, se tiene que *part-of-speech tagging (POS)* busca determinar a que categor√≠a gramatical pertenece cada palabra en un texto y *Named Entity Recognition (NER)* que busca reconcer *entidades* dentro de una oraci√≥n.\n",
    "\n",
    "#### 2.2. ¬øQu√© modelos usan features? ¬øQu√© ventajas conlleva esto? (0.1 pts)\n",
    "\n",
    "**Respuesta:** \n",
    "\n",
    "Los modelos MEMMs y CRFs usan features. La ventaja de los vectores features es que permiten realizar una representaci√≥n m√°s completa del texto ya que los vectores features permiten *agregar* conocimiento experto, es decir, los vectores features pertimen codificar *conocimiento* que no est√° presente en el texto.\n",
    "\n",
    "\n",
    "#### 2.3. ¬øC√≥mo maneja cada uno de los modelos las palabras con baja frecuencia en el set de train? (0.1 pts)\n",
    "\n",
    "**Respuesta:** \n",
    "\n",
    "Reemplazar las palabras poco frecuentes (palabras que ocurren, por ejemplo, menos de 5 veces) por ciertas categor√≠as permite manejar el problema. Por ejemplo, sup√≥ngase que se tiene un texto donde aparecen distintos a√±os. Dichos a√±os ocurren infrecuentes y tiene el formato *XXXX* (por ejemplo: 1969, 1984 y 1991). Los a√±os mencionados pueden entrar a una categor√≠a *Four digit year* y manejar el problema de las palabras infrecuentes.\n",
    "\n",
    "#### 2.4. ¬øQu√© le permite a los CRF realizar decisiones globales? ¬øQu√© diferencia con respecto a los MEMMs permite lograr esto? ¬øPor qu√© los HMMs tampoco son capaces de tomar decisiones globales? (0.1 pts)\n",
    "\n",
    "**Respuesta:** \n",
    "\n",
    "La probabilidad estimada por el modelo MEMM viene dada por:\n",
    "\\begin{equation}\n",
    "P(s_{i} | s_{i-1}, x_{1}, ..., x_{m} ; \\vec{W}) = \\frac{exp(\\vec{W} \\cdot \\vec{\\Phi}(x_{1}, ..., x_{m}, i, s_{i-1}, s_{i}))}{\\sum_{\\hat{s} \\in S} exp(\\vec{W} \\cdot \\vec{\\Phi}(x_{1}, ..., x_{m}, i, s_{i-1}, \\hat{s}))}\n",
    "\\end{equation}\n",
    "\n",
    "Por el otro lado, la probabilidad estimada por el modelo CRF viene dada por:\n",
    "\\begin{equation}\n",
    "P(s_{1:m} | x_{1:m} ; \\vec{W}) = \\frac{exp(\\vec{W} \\cdot \\vec{\\Phi}(x_{1:m}, s_{1:m}))}{\\sum_{\\hat{s_{1:m}} \\in S^{m}} exp(\\vec{W} \\cdot \\vec{\\Phi}(x_{1:m}, \\hat{s_{1:m}}))}\n",
    "\\end{equation}\n",
    "\n",
    "N√≥tese que el denominador de la expresi√≥n asociada al modelo MEMM es local (la suma presente solo considera una etiquetas *anteriror* a la etiqueta acutal). En cambio, el denominador de la expresi√≥n asociada al modelo CRF es global (la suma presente considera todas las posibles sequencias de etiquetas $S_{m}$). Dicha diferencia es la que permite al modelo CRF tomar decisiones globales.\n",
    "\n",
    "\n",
    "Los modelos HMMs no son capaces de tomar decisiones globales ya que realizan un supuesto *markoviano* de segundo orden y, por ende, la etiqueta *actual* solo depende de dos etiquetas anteriores (y no de todas las etiquetas anteriores).\n",
    "#### 2.5 Dado una secuencia de $x_1, ..., x_m$ ¬øCu√°ntas posibles secuencias de etiquetas se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ ? ¬øAnalizarlas todas ser√≠a computacionalmente tratable? (0.1 pts)\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Existen $k^{m}$ posibles secuencias dado una secuencia $x_1, ..., x_m$ y un conjunto de etiquetas $S$ con $|S|=k$. N√≥tese que el problema es de tiempo exponencial y, por tanto, analizar todas las posibles secuencias de etiquetas no es tratable computacionalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44ACHHZIWGF1"
   },
   "source": [
    "# Convolutional Neural Networks (0,5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClRAHR95Y8aB"
   },
   "source": [
    "### Pregunta 3 (0,5 puntos)\n",
    "\n",
    "Considere la frase $w_{1..7}=$ `El agua moja y el fuego quema` $=[El, agua, moja, y, el, fuego, quema]$.\n",
    "\n",
    "La siguiente matriz de embeddings, donde la i-√©sima fila corresponde al vector de embedding de la i-√©sima palabra, ordenadas seg√∫n aparecen en la frase. (vectores de largo 2).\n",
    "\\begin{equation}\n",
    "E = \\begin{pmatrix}\n",
    "2 & 2\\\\\n",
    "0 & -2\\\\\n",
    "0 & 1\\\\\n",
    "-2 & 1\\\\\n",
    "1 & 0\\\\\n",
    "-1 & 1\\\\\n",
    "1 & 1\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Los siguientes 3 filtros\n",
    "\\begin{equation}\n",
    "U = \\begin{pmatrix}\n",
    "-1 & 1 & 0\\\\\n",
    "1 & 1 & 0\\\\\n",
    "0 & 0 & -1\\\\\n",
    "1 & -1 & -1\\\\\n",
    "-1 & -1 & 1\\\\\n",
    "1 & 0 & -1\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Y la funci√≥n de activaci√≥n\n",
    "\\begin{equation}\n",
    "tanh = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
    "\\end{equation}\n",
    "\n",
    "Usando estos param√°tros escriba los pasos para calcular la representaci√≥n (vector) resultante de aplicar la operaci√≥n de convoluci√≥n (sin padding) + max pooling. ¬øDe qu√© tama√±o ser√≠a la ventana que debemos usar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlQ30Arkq0u4"
   },
   "source": [
    "**Respuesta**\n",
    "\n",
    "- Dada la matriz $E$, se tiene que crear los vectores embedding $\\vec{v}$ para las siguientes frases:\n",
    " - el agua moja\n",
    " - agua moja y\n",
    " - moja y el \n",
    " - y el fuego\n",
    " - el fuego quema\n",
    "- Por ejemplo, para la frase `el agua moja`, su vector embedding asociado se crea concatenando los embedding para las palabras: `el`: $(2, 2)$, `agua`: $(0, -2)$ y `moja`: $(0, 1)$. As√≠, se tiene que el vector embedding $\\vec{v}$ para esta frase es: $(2, 2, 0, -2, 0, 1)^{T}$\n",
    "- Con los vectores embedding creados, para cada vector se debe multiplicar dicho vector por la matriz $U$ y luego aplicar la funci√≥n de activaci√≥n, es decir, se debe realizar la siguiente operacion:\n",
    "\\begin{equation}\n",
    "\\vec{p} = tanh(\\vec{v}^{T} \\cdot U)\n",
    "\\end{equation}\n",
    "- Luego, con todos los vectores $\\vec{p}$ asociados a cada frase, se debe elegir el vector m√°ximo, es decir, para cada posici√≥n (dimensi√≥n) de los vectores $\\vec{p}$, se debe escoger valor m√°ximo de todos los vectores $\\vec{p}$ para la posici√≥n (dimensi√≥n) mencionada.\n",
    "\n",
    "N√≥tese que, en este caso, el tama√±o de la ventana a usar a 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0rCwen3WREC"
   },
   "source": [
    "# Recurrent Neural Networks (1 punto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0et78Z4oKIq"
   },
   "source": [
    "### Pregunta 4 (0,5 puntos)\n",
    "Usando los embeddings de dos dimensiones de la pregunta anteror, la oraci√≥n `el fuego quema` la podemos representar por una secuencia de vectores $(\\vec{x}_1,\\vec{x}_2,\\vec{x}_3)$, con $\\vec{x}_i \\in \\mathbb{R}^{d_x}$ y $d_x=2$.\n",
    "\n",
    "Tenemos una red recurrente *Elman* definidad como: \n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\vec{s}_i &= R_{SRNN}\\left (\\vec{x}_i, \\vec{s}_{i-1}\\right ) = g \\left (\\vec{s}_{i-1}W^s + \\vec{x}_i W^x + \\vec{b}\\right ) \\\\\n",
    "\\vec{y}_i &= O_{SRNN}\\left(\\vec{s}_i\\right) = \\vec{s}_i \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "donde\n",
    "\\begin{equation}\n",
    "\\vec{s}_i, \\vec{y}_i \\in \\mathbb{R}^{d_s}, \\quad W^x \\in \\mathbb{R}^{d_x \\times d_s}, \\quad W^s \\in \\mathbb{R}^{d_s \\times d_s}, \\quad \\vec{b} \\in \\mathbb{R}^{d_s},\n",
    "\\end{equation}\n",
    "y los vectores de estado $s_i$ son de tres dimensiones, $ds= 3$.\n",
    "\n",
    "Sea\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\vec{s}_0 &= [0,0,0]\\\\\n",
    "W^x &= \\begin{pmatrix}\n",
    "0 &  0 & 1\\\\\n",
    "1 & -1 & 0\n",
    "\\end{pmatrix} \\\\\n",
    "W^s &= \\begin{pmatrix}\n",
    "1 & 0 &  1\\\\\n",
    "0 & 1 & -1\\\\\n",
    "1 & 1 &  1\n",
    "\\end{pmatrix} \\\\\n",
    "\\vec{b} &= [0, 0, 0] \\\\\n",
    "g(x) &= ReLu(x) = max(0, x)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "<br>\n",
    "\n",
    "Calcule manualmente los valores de los vectores $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ y de $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fim2W8JioPhL"
   },
   "source": [
    "**Respuesta**\n",
    "\n",
    "El embedding para la frase `el fuego quema` es $(1, 0, -1, 1, 1, 1)$, es decir, se tiene que $\\vec{x}_1 = (1, 0)$, $\\vec{x}_2 = (-1, 1)$ y $\\vec{x}_3 = (1, 1)$. Luego, se tiene que los vectores $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ vienen dados por:\n",
    "- $\\vec{s}_1 = g(\\vec{s}_0 W^{s} + \\vec{x}_{1}W^{x} + \\vec{b}) = g((0,0,0) + (0, 0, 1)) = g((0,0,1))= (0,0,1) $\n",
    "- $\\vec{s}_2 = g(\\vec{s}_1 W^{s} + \\vec{x}_{2}W^{x} + \\vec{b}) = g((1,1,1) + (1,-1,-1)) = g((2,0,0)) = (2,0,0)$\n",
    "- $\\vec{s}_3 = g(\\vec{s}_2 W^{s} + \\vec{x}_{3}W^{x} + \\vec{b}) = g((2,0,2) + (1,-1,1)) = g((2,-1,2)) = (2,0,2)$\n",
    "\n",
    "Ahora, los vectores $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$ vienen dados por:\n",
    "- $\\vec{y}_1 = O_{SRNN}\\left(\\vec{s}_1\\right) = \\vec{s}_1 = (0,0,1)$\n",
    "- $\\vec{y}_2 = O_{SRNN}\\left(\\vec{s}_2\\right) = \\vec{s}_2 = (2,0,0)$\n",
    "- $\\vec{y}_3 = O_{SRNN}\\left(\\vec{s}_3\\right) = \\vec{s}_3 = (2,0,2)$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4rAT6ELxRZW"
   },
   "source": [
    "### Pregunta 5 (0.5 puntos)\n",
    "¬øDe qu√© forma las RNN y las CNN logran aprender representaciones espec√≠ficas\n",
    "para la tarea objetivo? Compare la forma en que las RNN y las CNN aprenden con los modelos que usan *features* dise√±adas manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6AXbQSgA_t8"
   },
   "source": [
    "**Respuesta**\n",
    "\n",
    "En t√©rminos generales, ambos modelos aprenden representaciones espec√≠ficas para la tarea objetivo *pasando* el input por las capas de su red, generando un ouput y ajustando los par√°metros para *minimizar* una funci√≥n p√©rdida. M√°s en particular, una CNN aprende representaciones espec√≠ficas para la tarea objetivo mediante capas con filtro de convolusi√≥n que permiten encontrar *patrones* locales. Por el otro, una RNN aprende representaciones espec√≠ficas para la tarea objetivo mediante capas con *estados recursivos* que permiten *almacenar* informaci√≥n global.\n",
    "\n",
    "La gran diferencia entre la forma en que las RNN y CNN aprenden en comparaci√≥n a modelos que usan features dise√±adas manualmente es que las RNN y CNN aprenden de forma *aut√≥noma* los features √≥ptimos para la tarea objetivo. En cambio, un modelo que usa features dise√±adas manualmente necesita un *experto* que dise√±e las features √≥ptimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRJkBpjWyHnb"
   },
   "source": [
    "# Pregunta 6: Redes Neuronales con Pytorch (3 puntos) üí¨\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.anda.cl/wp-content/uploads/2021/03/0_5vNAtimPjYQr4W72.gif\" alt=\"chatbot\" width=\"400\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEla92bUymrQ"
   },
   "source": [
    "En esta secci√≥n de la tarea deber√°n implementar un Chatbot que sea capaz de generar una conversaci√≥n *‚Äúb√°sica‚Äù* utilizando un dataset de *Star Wars*. **El objetivo** de esta pregunta es que puedan aplicar lo aprendido sobre redes neuronales utilizando Pytorch en un ejemplo pr√°ctico.  Durante el desarrollo, se espera que puedan dise√±ar un bot (que tendr√° por atr√°s un clasificador) que sea capaz de clasificar diferentes etiquetas, cosa que una vez identificada la etiqueta entregue una respuesta acorde a lo preguntado.\n",
    "\n",
    "**Aviso:** Antes de comenzar con una descripci√≥n mas profunda de esta secci√≥n, les recomendamos que visualicen y se familiaricen con el dataset entregado, de esta forma comprender√°n mejor la descripci√≥n del enunciado (aqu√≠ una peque√±a ayudita üÜò)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eKOGlMs3Dx-",
    "outputId": "376ced9d-b74d-499a-feb1-67e9574e77ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de tags:  16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_data = pd.read_json('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json')\n",
    "print(\"Cantidad de tags: \", example_data['intents'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-6fCE5fHkNS"
   },
   "source": [
    "A continuaci√≥n, ejemplos del contenido del primer registro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axsi27BpHGOx",
    "outputId": "883da5bd-7f10-4a3c-da8d-6e50357413ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'Hey',\n",
       " 'How are you',\n",
       " 'Is anyone there?',\n",
       " 'Hello',\n",
       " 'Good day',\n",
       " \"What's up\",\n",
       " 'Yo!',\n",
       " 'Howdy',\n",
       " 'Nice to meet you.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data['intents'][0]['patterns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OV0vGdwoHeg3",
    "outputId": "327fc95d-7dd8-4fa2-a410-1a2225661bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'Hello, thanks for visiting.',\n",
       " 'Hi there, what can I do for you?',\n",
       " 'Hi there, how can I help?',\n",
       " 'Hello, there.',\n",
       " 'Hello Dear',\n",
       " 'Ooooo Hello, looking for someone or something?',\n",
       " 'Yes, I am here.',\n",
       " 'Listening carefully.',\n",
       " 'Ok, I am with you.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data['intents'][0]['responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0BnYez1oGtx3",
    "outputId": "dd0e649f-cdad-4f57-f848-384c688d38fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'greeting'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data['intents'][0]['tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6BvAWCw3zPM"
   },
   "source": [
    "Del dataset cargado podemos notar que este viene en un formato `JSON`, por lo que sus datos est√°n almacenados en diccionarios. Las llaves de los diccionarios no son aleatorias y estos nos sirven para identificar puntos relevantes en el desarrollo del bot. A continuaci√≥n, se realiza una peque√±a descripci√≥n de las llaves:\n",
    "\n",
    "- `patterns`: Almacena los patrones con los que entrenaremos el modelo üòÆ, en otras palabras, es el corpus de entrenamiento que contiene solo preguntas o expresiones que deber√° responder el bot.\n",
    "- `responses`: Son las respuestas üôã relacionadas a los `patterns`, estas las utilizaremos en una etapa posterior a la clasificaci√≥n, para dar una respuesta aleator√≠a al usuario.\n",
    "- `tag`: Son las labels con las que entrenaremos nuestro modelo üíª. \n",
    "\n",
    "En s√≠ntesis, las `keys` relevantes para el entrenamiento de nuestra red neuronal ser√°n `patterns` (corpus) y `tag` (etiquetas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlOAdMjSSzNN"
   },
   "source": [
    "#### Explicaci√≥n de la tarea a realizar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yGApnWVI4cO"
   },
   "source": [
    "**Explicaci√≥n de la tarea a realizar**: Implemente una Class llamada `CNNClassifier` que sea capaz de entrenar un modelo de texto a trav√©s de una red neuronal Feed Forward y una arquitectura convolucional (CNN 1D) [`torch.nn.Conv1d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#conv1d) . Para el dise√±o de las redes tienen completa libertad, pero se le aconseja que se gu√≠en de la √∫ltima auxiliar para la construcci√≥n. Es **important√≠simo** que el modelo a crear posea una capa de `Embedding` que se genere en base al entrenamiento del modelo. Creado el modelo, construya una funci√≥n batch para cargar los datos de entrenamiento del modelo.\n",
    "\n",
    "Construido el modelo, compare los resultados obtenidos para una red feed forward y una cnn. Para la comprobaci√≥n de sus resultados ejecute el chatbot y pruebelo, ¬øqu√© configuraci√≥n tiene mejores resultados?, ¬øa qu√© se deberan estos resultados?\n",
    "\n",
    "Ojo que un ejemplo de prueba con el chatbot puede ser (agregue mas preguntas ud):\n",
    "\n",
    "```\n",
    "Let's chat! (type 'finish_chat' to finish the chat)\n",
    "You: hi\n",
    "GA-97: Yes, I am here.\n",
    "You: can you tell me a joke?\n",
    "GA-97: Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.\n",
    "```\n",
    "\n",
    "El resto del c√≥digo referido a la ejecuci√≥n del chat se los entregamos, por lo que no deber√≠an tener mayores problemas üò∏ (en caso de tener problemas con su c√≥digo, puede modificar cualquier parte sugerida siempre y cuando cumpla lo solicitado).\n",
    "\n",
    "**Igual [mucho texto](https://i0.wp.com/elgeneracionalpost.com/wp-content/uploads/2020/07/mucho-texto.jpg?fit=1280%2C720&ssl=1).... En resumen, ¬øQu√© se solicita?:**\n",
    "\n",
    "- [ ] Dise√±ar una red neuronal Feed Forward.\n",
    "- [ ] Dise√±ar un red convolucional.\n",
    "- [ ] Utilizar una capa de embeddings para generar representaciones vectoriales del corpus.\n",
    "- [ ] Crear el m√©todo forward de la clase `CNNClassifier`.\n",
    "- [ ] Crear la funci√≥n BATCH.\n",
    "- [ ] Probar el modelo y comparar los resultados obtenidos con la red Feed Forward y la red CNN. Comente sus resultados de forma cualitativa, se√±alando con qu√© tipo de red obtuvo mejores resultados con el chatbot.\n",
    "\n",
    "**Nota-1:** El modelo creado debe tener la opci√≥n de entrenar a traves de una feed forward y una CNN. Esto no significa que entrenar√° una FF y una CN, el modelo deber√° recibir un booleano que especifique que tipo de red utilizar√°.\n",
    "\n",
    "**Nota-2:** El dataset se descargar√° autom√°ticamente en la secci√≥n `Carga de Dataset üìö`, no os preocup√©is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4bKfAdEy3oD"
   },
   "source": [
    "#### Pasemos al C√≥digo ü¶æ\n",
    "\n",
    "Esqueleto propuesto (se **RECOMIENDA** que cambien **SOLO** la red neuronal y la funci√≥n Batch) ü¶¥:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUwxivx2MpMV"
   },
   "source": [
    "##### Instalamos librerias necesarias e importamos üòÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "TjSZkBsk1H4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.8.0+cu111 in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (1.8.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from torch==1.8.0+cu111) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from torch==1.8.0+cu111) (1.22.3)\n",
      "Requirement already satisfied: torchtext==0.9.0 in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from torchtext==0.9.0) (1.22.3)\n",
      "Requirement already satisfied: torch==1.8.0 in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from torchtext==0.9.0) (1.8.0+cu111)\n",
      "Requirement already satisfied: requests in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from torchtext==0.9.0) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from torchtext==0.9.0) (4.63.1)\n",
      "Requirement already satisfied: typing-extensions in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from torch==1.8.0->torchtext==0.9.0) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tridimensional/u/dcc/noveno/nlp/nlp/lib/python3.8/site-packages (from requests->torchtext==0.9.0) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "# Esto toma su tiempo en ejecutarse\n",
    "!pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "RfZ6SL-Q1Kwd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from random import choice\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from itertools import zip_longest\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habemus GPU? False\n"
     ]
    }
   ],
   "source": [
    "# Verificar si cuda esta disponible en el entorno\n",
    "print(\"Habemus GPU?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available(): # Usar esto para codigo agnostico\n",
    "    print(\"Cuantas GPUs me regala Google?\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oj-Epe7XJLrL"
   },
   "source": [
    "##### Carga de Dataset üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvlLqYRrVN6l",
    "outputId": "e6817cb7-ac85-471a-f426-f07537f357b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-20 22:27:21--  https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14469 (14K) [text/plain]\n",
      "Saving to: ‚Äòstar_wars_chatbot.json.1‚Äô\n",
      "\n",
      "star_wars_chatbot.j 100%[===================>]  14,13K  --.-KB/s    in 0,003s  \n",
      "\n",
      "2022-06-20 22:27:21 (4,14 MB/s) - ‚Äòstar_wars_chatbot.json.1‚Äô saved [14469/14469]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we obtain the dataset\n",
    "!wget 'https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbbIsFUG1TXW",
    "outputId": "7ad12487-4295-4f5f-a3b2-c9e50729f680"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97lines [00:00, 83989.99lines/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using json\n",
    "with open('star_wars_chatbot.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Create a vocab with the dataset and get the number of classes that have\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab_from_iterator(tokenizer(x) for list_words in dataset['intents'] for x in list_words['patterns'])\n",
    "num_classes = len(dataset['intents'])\n",
    "\n",
    "# Define a list with the labels\n",
    "labels = sorted(set([tag for tag in [intents['tag'] for intents in dataset['intents']]]))\n",
    "# Define a train_list where we can find the info in the format: [(tag_0, text_0)...,(tag_n-1, text_n-1)]\n",
    "train_list = [(labels.index(intents['tag']), text) for intents in dataset['intents'] for text in intents['patterns']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a52SUNKPJQxi"
   },
   "source": [
    "##### Creaci√≥n del modelo (2 puntos en total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "n-vQ24tMJG5H"
   },
   "outputs": [],
   "source": [
    "# Construya el modelo\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=32, num_classes=10, \n",
    "                 use_cnn=False, cnn_pool_channels=24, cnn_kernel_size=3):\n",
    "      super().__init__()\n",
    "    \n",
    "      self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "      self.use_cnn = use_cnn\n",
    "\n",
    "      if self.use_cnn:\n",
    "        # capa de convoluci√≥n\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=cnn_pool_channels,\n",
    "            kernel_size=cnn_kernel_size * embed_dim,\n",
    "            stride=embed_dim,\n",
    "            )\n",
    "        fc_in_size = cnn_pool_channels\n",
    "        \n",
    "        # capa lineal\n",
    "        self.fc = nn.Linear(fc_in_size, num_classes)\n",
    "        self.init_weights()\n",
    "      else:\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def init_weights(self):\n",
    "      # Esto puede ser util para inicializar los pesos\n",
    "      initrange = 0.5\n",
    "      self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "      self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "      self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "      text = torch.tensor(\n",
    "          list(\n",
    "              zip(\n",
    "                  *zip_longest(\n",
    "                      *([text[o:offsets[i+1]] for i, o in enumerate(offsets[:-1])] + [text[offsets[-1]:len(texts)]]), \n",
    "                      fillvalue=vocab[\"<pad>\"]\n",
    "                  )\n",
    "              )\n",
    "          )\n",
    "      ).to(text.device)\n",
    "\n",
    "      h = self.embedding(text)\n",
    "      if self.use_cnn:\n",
    "        # (N x longest_text x embed_dim)\n",
    "\n",
    "\n",
    "        # (N x pool_channels)\n",
    "        h = h.view(h.size(0), 1, -1)\n",
    "        h = torch.relu(self.conv(h))\n",
    "        h = h.mean(dim=2)\n",
    "\n",
    "        # (N x num_classes)\n",
    "        return h\n",
    "      else:\n",
    "        h = h.mean(dim=1)\n",
    "        return self.fc(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGN-T0JoJtmS"
   },
   "source": [
    "##### Funci√≥n Batch üë∑ (0,5 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "K1AZpXc7JxTa"
   },
   "outputs": [],
   "source": [
    "# Defina su funci√≥n de BATCH\n",
    "def generate_batch(batch):\n",
    "  label = torch.tensor([entry[0] for entry in batch])\n",
    "  texts = [tokenizer(entry[1]) for entry in batch]\n",
    "  offsets = [0] + [len(text) for text in texts]\n",
    "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "  big_text = torch.cat([torch.tensor([vocab.stoi[t] for t in text]) for text in texts])\n",
    "  return big_text, offsets, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YChwpNrrNRBe"
   },
   "source": [
    "##### Entrenamiento ü•ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5eRWRD_J0Km",
    "outputId": "89f923fd-8f1d-4258-ad74-4e5915c3d53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is avaible: cpu\n",
      "train: 97 elements\n",
      "Epoch: 1000 \t iter-Loss: 0.001final loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"GPU is avaible: {device}\")\n",
    "\n",
    "# Define the different inputs in our model\n",
    "num_epochs = 1000\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-1\n",
    "INPUT_SIZE = len(vocab)\n",
    "OUTPUT_SIZE = num_classes\n",
    "USE_CNN = False\n",
    "\n",
    "# Define model, optimizer, loss and scheduler (Q: ¬øWhat is it?)\n",
    "model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n",
    "optimizer = SGD(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n",
    "\n",
    "print(f'train: {len(train_list)} elements')\n",
    "\n",
    "# We train the model using the intents\n",
    "loss_list= []\n",
    "for epoch in range(1, num_epochs):\n",
    "  train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  for i, (texts, offsets, cls) in enumerate(train_loader):\n",
    "    texts = texts.to(device)\n",
    "    offsets = offsets.to(device)\n",
    "    cls = cls.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(texts, offsets)\n",
    "    loss = criterion(output, cls)\n",
    "    total_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  loss_list.append(loss.item())\n",
    "  sys.stdout.write('\\rEpoch: {0:03d} \\t iter-Loss: {1:.3f}'.format(epoch+1, loss.item()))\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dlS4_X-L3DN"
   },
   "source": [
    "##### A probar! üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "6IhhAKFXL3eH",
    "outputId": "6a28628b-d2d0-4bf0-9479-ccabbef085e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'funny'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is working?, Try the next example!\n",
    "qText = \"'Do you know any joke?'\" # this must classify the label \"funny\"\n",
    "\n",
    "X = torch.tensor([vocab.stoi[t] for t in tokenizer(qText)]).to(device)\n",
    "\n",
    "model.eval()\n",
    "output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n",
    "_, predicted = torch.max(output, dim=1)\n",
    "labels[predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udemze3zL549"
   },
   "source": [
    "Ya pero prometiste hacer un chatbot, no una simple clasificaci√≥n.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpSYGx2tL0tC"
   },
   "source": [
    "##### Guardamos modelo ü¶∫ (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBC4TyiqLzDv",
    "outputId": "0a743164-69aa-4b6e-a219-37da8ea699bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "# We save de model using pytorch (this is optional, just to learn how to do this in pytorch)\n",
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": INPUT_SIZE,\n",
    "\"output_size\": OUTPUT_SIZE,\n",
    "\"use_cnn\": USE_CNN,\n",
    "\"labels\": labels\n",
    "        }\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYClbTtsMCjE"
   },
   "source": [
    "##### Chatbot üí¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c249zUwiMBxb",
    "outputId": "03d5c400-9860-4ea1-b8c6-f711067d2727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'finish_chat' to finish the chat)\n",
      "You: Hi\n",
      "GA-97: Hello Dear\n",
      "You: Do you know any joke?\n",
      "GA-97: Which program do Jedi use to open PDF files? Adobe-Wan Kenobi\n",
      "You: can you tell me a joke?\n",
      "GA-97: Which program do Jedi use to open PDF files? Adobe-Wan Kenobi\n",
      "You: exit\n",
      "GA-97: Here is top 10 bounti hounter you are looking for: Jango Fett, Boba Fett, Cad Bane, Durge, Embo, Dengar, Black Krrsantan, IG-88, Aurra Sing, Sabine Wren.\n",
      "You: finish_chat\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('star_wars_chatbot.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "INPUT_SIZE = data[\"input_size\"]\n",
    "OUTPUT_SIZE = data[\"output_size\"]\n",
    "USE_CNN = data[\"use_cnn\"]\n",
    "labels = data['labels']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "# Dictionary with the answers\n",
    "responses = {key['tag']: key['responses'] for key in dataset['intents']}\n",
    "\n",
    "bot_name = \"GA-97\"\n",
    "print(\"Let's chat! (type 'finish_chat' to finish the chat)\")\n",
    "while True:\n",
    "    q_text = input(\"You: \")\n",
    "    if USE_CNN:\n",
    "        q_text = \"'\"+q_text+\"'\"\n",
    "        finish_chat = \"finish_chat\"\n",
    "        if q_text == \"'\"+finish_chat+\"'\":\n",
    "            break\n",
    "    else:\n",
    "        q_text = q_text\n",
    "        if q_text == 'finish_chat':\n",
    "            break\n",
    "\n",
    "    X = torch.tensor([vocab.stoi[t] for t in tokenizer(q_text)]).to(device)\n",
    "    output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = labels[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.50:\n",
    "      print(f\"{bot_name}: {random.choice(responses[tag])}\")\n",
    "    else:\n",
    "      print(f\"{bot_name}: My model can't understand you...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hu2QTuSURCt"
   },
   "source": [
    "#### Comente los resultados aqu√≠ (0,5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdFV63WVUX32"
   },
   "source": [
    "Cualitativamente, es decir, probando el chat y observando los resultados, se tiene que la red feed forward obtiene mejores resultados que el modelo CNN. En particular, la red feed forward, la mayor parte de las veces, responde correctamente a los textos `Hi`, `can you tell me a joke` y `Do you know a joke`. Por el otro lado, la CNN responde correctamente pocas veces al texto `Hi` y responde, aproximadamente, la mitad de las veces correctamente a los textos `can you tell me a joke` y `Do you know a joke`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea 4 - enunciado.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
